Se han truncado las últimas 5000 líneas del flujo de salida.
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 13x128
[DEBUG] Encoder sample values: -0.537 1.906 -1.116 -0.436 -0.703 
[DECODER] Starting decode with 17 tokens
[EMBEDDING] Forward pass - seq_len=17, d_model=128
[EMBEDDING] 2176/2176 non-zero, sum=4.143, range=[-0.115, 4.157]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2176/2176 non-zero, sum=4.143
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2112/2176 non-zero, sum=109.615685
[DECODER] SCALED EMBEDS before add: 2176/2176 non-zero, sum=46.870136
[DECODER] After pos encoding: 2176/2176 non-zero, sum=156.485840
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2176/2176 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2176/2176 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 17x128
[DEBUG] Decoder sample values: -0.163 0.974 6.182 -0.694 -2.167 
[DEBUG] Output projection - shape: 17x2000
[DEBUG] Output range: [-2.519, 5.019]
[DEBUG] Output sample values: 0.740 4.198 4.898 4.913 2.022 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.782
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.208
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 17 tokens with lr=0.050
[EMBEDDING] Gradient stats: 2176/2176 non-zero, sum=-0.040, range=[-0.053, 0.003]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 17 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.495, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.495
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-5.604771
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=52.211670
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.520 1.899 -1.103 -0.414 -0.677 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.962, range=[-0.115, 4.160]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.962
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=33.515751
[DECODER] After pos encoding: 1152/1152 non-zero, sum=91.332253
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.118 0.966 6.116 -0.763 -2.111 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.219, 5.734]
[DEBUG] Output sample values: 0.703 4.339 4.943 4.891 2.043 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.776
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.032, range=[-0.095, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.802, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=2.802
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=31.703804
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=95.974228
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000012
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.518 1.842 -1.090 -0.418 -0.678 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.636, range=[-0.115, 4.165]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.636
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=29.821457
[DECODER] After pos encoding: 1152/1152 non-zero, sum=87.637794
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 1.186 -1.039 5.051 0.293 -0.746 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.606, 5.561]
[DEBUG] Output sample values: -0.249 4.776 5.561 4.921 2.840 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.766
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.029, range=[-0.091, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.535, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.535
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=17.367733
[ENCODER] After pos encoding: 768/768 non-zero, sum=55.857983
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.520 1.889 -1.133 -0.446 -0.652 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.811, range=[-0.115, 4.169]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.811
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=43.111870
[DECODER] After pos encoding: 640/640 non-zero, sum=75.172028
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.846 -0.271 4.924 -1.988 -0.934 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.351, 5.069]
[DEBUG] Output sample values: 0.146 4.560 4.642 5.069 2.879 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.764
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.009, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.088, range=[-0.173, 0.011]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.597, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.597
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=18.070816
[ENCODER] After pos encoding: 768/768 non-zero, sum=56.561069
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.530 1.888 -1.102 -0.422 -0.682 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=4.821, range=[-0.115, 4.178]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=4.821
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=54.540684
[DECODER] After pos encoding: 768/768 non-zero, sum=93.030968
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000018
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.359 0.950 5.878 -0.313 -1.254 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.212, 5.209]
[DEBUG] Output sample values: 0.418 4.129 4.327 5.179 2.228 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.765
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.014, bias: 0.267
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.067, range=[-0.146, 0.010]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.442, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=-0.442
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-4.998470
[ENCODER] After pos encoding: 768/768 non-zero, sum=33.491764
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.531 1.898 -1.106 -0.436 -0.659 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=7.003, range=[-0.116, 4.185]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=7.003
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=79.226410
[DECODER] After pos encoding: 768/768 non-zero, sum=117.716675
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.710 0.716 6.063 -0.619 0.235 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.192, 5.148]
[DEBUG] Output sample values: 0.909 4.820 4.887 4.954 1.586 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.769
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.066, range=[-0.142, 0.008]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 17 tokens, target: 18 tokens
[ENCODER] Starting encode with 17 tokens
[EMBEDDING] Forward pass - seq_len=17, d_model=128
[EMBEDDING] 2176/2176 non-zero, sum=0.975, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 2176/2176 non-zero, sum=0.975
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2112/2176 non-zero, sum=109.615685
[ENCODER] SCALED EMBEDS before add: 2176/2176 non-zero, sum=11.028700
[ENCODER] After pos encoding: 2176/2176 non-zero, sum=120.644333
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2176/2176 non-zero
[ENCODER_LAYER] After self-attention: 2176/2176 non-zero
[ENCODER_LAYER] After norm1: 2176/2176 non-zero
[ENCODER_LAYER] After feedforward: 2176/2176 non-zero
[ENCODER_LAYER] Final output: 2176/2176 non-zero
[ENCODER] Layer 0 output: 2176/2176 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2176/2176 non-zero
[ENCODER_LAYER] After self-attention: 2176/2176 non-zero
[ENCODER_LAYER] After norm1: 2176/2176 non-zero
[ENCODER_LAYER] After feedforward: 2176/2176 non-zero
[ENCODER_LAYER] Final output: 2176/2176 non-zero
[ENCODER] Layer 1 output: 2176/2176 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 17x128
[DEBUG] Encoder sample values: -0.498 1.892 -1.096 -0.420 -0.654 
[DECODER] Starting decode with 18 tokens
[EMBEDDING] Forward pass - seq_len=18, d_model=128
[EMBEDDING] 2304/2304 non-zero, sum=2.840, range=[-0.116, 4.192]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2304/2304 non-zero, sum=2.840
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2240/2304 non-zero, sum=116.117348
[DECODER] SCALED EMBEDS before add: 2304/2304 non-zero, sum=32.129269
[DECODER] After pos encoding: 2304/2304 non-zero, sum=148.246658
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2304/2304 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2304/2304 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 18x128
[DEBUG] Decoder sample values: 0.535 -0.301 7.454 0.150 -0.383 
[DEBUG] Output projection - shape: 18x2000
[DEBUG] Output range: [-2.258, 5.534]
[DEBUG] Output sample values: 0.563 4.348 4.828 4.931 2.620 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.784
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.136
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 18 tokens with lr=0.050
[EMBEDDING] Gradient stats: 2304/2304 non-zero, sum=-0.031, range=[-0.050, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 18 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.847, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.847
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9.580351
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=67.396797
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.545 1.903 -1.105 -0.426 -0.639 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.494, range=[-0.116, 4.195]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.494
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=50.838192
[DECODER] After pos encoding: 1152/1152 non-zero, sum=108.654716
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.661 0.387 6.004 -0.628 0.621 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.224, 5.306]
[DEBUG] Output sample values: 0.780 3.943 4.928 4.394 2.970 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.775
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.033, range=[-0.095, 0.003]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 10 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.841, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=2.841
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=32.140320
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=96.410797
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.522 1.867 -1.096 -0.434 -0.670 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=5.482, range=[-0.116, 4.199]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=5.482
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=62.024521
[DECODER] After pos encoding: 1280/1280 non-zero, sum=126.294998
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: 0.908 -0.026 6.212 -0.472 0.558 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.449, 5.392]
[DEBUG] Output sample values: 0.699 4.211 5.392 4.343 3.099 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.765
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.011, bias: 0.244
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.025, range=[-0.082, 0.003]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.149, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.149
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12.993855
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=70.810295
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.525 1.890 -1.104 -0.430 -0.654 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=6.154, range=[-0.116, 4.203]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=6.154
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=69.619705
[DECODER] After pos encoding: 1024/1024 non-zero, sum=120.988091
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.611 0.278 5.627 -1.353 0.708 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.250, 5.050]
[DEBUG] Output sample values: 0.667 4.780 4.697 4.571 2.459 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.771
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.111
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.041, range=[-0.108, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.864, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.864
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=21.092239
[ENCODER] After pos encoding: 768/768 non-zero, sum=59.582500
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.551 1.894 -1.099 -0.427 -0.675 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=5.651, range=[-0.116, 4.209]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=5.651
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=63.938251
[DECODER] After pos encoding: 768/768 non-zero, sum=102.428444
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.488 0.391 5.369 -0.524 -0.771 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.359, 5.502]
[DEBUG] Output sample values: 0.607 4.003 4.767 5.361 2.432 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.763
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.067, range=[-0.143, 0.012]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 11 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.904, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=1.904
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=21.545162
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=85.815521
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.569 1.909 -1.063 -0.428 -0.660 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.750, range=[-0.116, 4.216]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=3.750
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=42.428646
[DECODER] After pos encoding: 1408/1408 non-zero, sum=113.159111
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -0.009 0.893 6.693 -0.459 -0.565 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.382, 5.386]
[DEBUG] Output sample values: 0.247 4.517 4.866 4.911 1.904 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.778
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.081
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 11 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.018, range=[-0.078, 0.004]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 10 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.412, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.412
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-4.657403
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=53.159031
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.558 1.881 -1.145 -0.412 -0.676 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.518, range=[-0.116, 4.220]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.518
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=39.806942
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.077454
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.126 0.988 5.944 -0.801 -2.070 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.206, 5.342]
[DEBUG] Output sample values: 0.708 4.256 5.022 4.770 1.927 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.779
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.089
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.024, range=[-0.085, 0.004]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.482, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=2.482
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.075157
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=85.891579
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.530 1.881 -1.142 -0.440 -0.662 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.230, range=[-0.116, 4.224]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.230
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=36.542843
[DECODER] After pos encoding: 1024/1024 non-zero, sum=87.911087
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.076 0.938 5.686 -0.773 -2.149 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.138, 6.386]
[DEBUG] Output sample values: 0.695 4.308 4.950 4.903 2.027 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.764
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.040, range=[-0.106, 0.006]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 4 tokens, target: 4 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=2.293, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=2.293
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=25.945221
[ENCODER] After pos encoding: 512/512 non-zero, sum=51.581360
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.543 1.892 -1.112 -0.416 -0.667 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=4.499, range=[-0.116, 4.229]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=4.499
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=50.894844
[DECODER] After pos encoding: 512/512 non-zero, sum=76.530968
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.610 0.735 5.198 -0.114 -0.842 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.213, 5.196]
[DEBUG] Output sample values: 0.213 4.199 5.032 4.895 2.109 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.747
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.011, bias: 0.221
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 4 tokens with lr=0.050
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.124, range=[-0.212, 0.012]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000

Época 49/50
[DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.148, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.148
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.985186
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.383183
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.529 1.895 -1.126 -0.447 -0.651 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.933, range=[-0.116, 4.240]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=2.933
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=33.180653
[DECODER] After pos encoding: 1024/1024 non-zero, sum=84.549065
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 1.109 -0.525 5.574 -1.299 -0.686 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.311, 5.121]
[DEBUG] Output sample values: 0.358 4.459 5.121 4.836 2.604 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.766
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.039, range=[-0.105, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 13 tokens, target: 17 tokens
[ENCODER] Starting encode with 13 tokens
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.522, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1664/1664 non-zero, sum=0.522
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=5.907016
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.575356
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 13x128
[DEBUG] Encoder sample values: -0.538 1.906 -1.116 -0.436 -0.703 
[DECODER] Starting decode with 17 tokens
[EMBEDDING] Forward pass - seq_len=17, d_model=128
[EMBEDDING] 2176/2176 non-zero, sum=4.193, range=[-0.116, 4.245]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2176/2176 non-zero, sum=4.193
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2112/2176 non-zero, sum=109.615685
[DECODER] SCALED EMBEDS before add: 2176/2176 non-zero, sum=47.440311
[DECODER] After pos encoding: 2176/2176 non-zero, sum=157.055786
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2176/2176 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2176/2176 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 17x128
[DEBUG] Decoder sample values: -0.154 0.961 6.167 -0.699 -2.168 
[DEBUG] Output projection - shape: 17x2000
[DEBUG] Output range: [-2.520, 5.079]
[DEBUG] Output sample values: 0.734 4.234 4.906 4.988 2.061 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.782
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.208
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 17 tokens with lr=0.050
[EMBEDDING] Gradient stats: 2176/2176 non-zero, sum=-0.040, range=[-0.053, 0.003]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 17 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.495, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.495
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-5.604771
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=52.211670
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.521 1.899 -1.103 -0.414 -0.677 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.020, range=[-0.116, 4.248]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=3.020
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=34.167461
[DECODER] After pos encoding: 1152/1152 non-zero, sum=91.983749
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.126 0.952 6.100 -0.768 -2.112 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.226, 5.738]
[DEBUG] Output sample values: 0.696 4.352 4.950 4.985 2.082 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.777
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.032, range=[-0.095, 0.006]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.802, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=2.802
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=31.703804
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=95.974228
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.518 1.842 -1.091 -0.418 -0.678 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.695, range=[-0.116, 4.253]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.695
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=30.488140
[DECODER] After pos encoding: 1152/1152 non-zero, sum=88.304604
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 1.188 -1.048 5.044 0.286 -0.749 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.605, 5.557]
[DEBUG] Output sample values: -0.254 4.825 5.557 4.986 2.904 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.766
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.029, range=[-0.091, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.535, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.535
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=17.367733
[ENCODER] After pos encoding: 768/768 non-zero, sum=55.857983
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.521 1.889 -1.134 -0.446 -0.651 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.870, range=[-0.116, 4.257]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.870
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=43.779907
[DECODER] After pos encoding: 640/640 non-zero, sum=75.840096
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.856 -0.288 4.905 -1.988 -0.938 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.354, 5.074]
[DEBUG] Output sample values: 0.135 4.627 4.646 5.074 2.903 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.765
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.009, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.087, range=[-0.173, 0.011]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.597, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.597
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=18.070816
[ENCODER] After pos encoding: 768/768 non-zero, sum=56.561069
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.530 1.888 -1.103 -0.422 -0.681 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=4.876, range=[-0.117, 4.266]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=4.876
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=55.162327
[DECODER] After pos encoding: 768/768 non-zero, sum=93.652649
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.371 0.936 5.870 -0.318 -1.260 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.213, 5.263]
[DEBUG] Output sample values: 0.409 4.206 4.286 5.201 2.248 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.766
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.013, bias: 0.266
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.067, range=[-0.146, 0.011]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.442, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=-0.442
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-4.998470
[ENCODER] After pos encoding: 768/768 non-zero, sum=33.491764
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.531 1.898 -1.107 -0.436 -0.659 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=7.061, range=[-0.117, 4.273]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=7.061
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=79.886154
[DECODER] After pos encoding: 768/768 non-zero, sum=118.376472
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.719 0.702 6.047 -0.623 0.227 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.200, 5.190]
[DEBUG] Output sample values: 0.899 4.827 4.939 5.042 1.621 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.769
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.065, range=[-0.142, 0.009]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 17 tokens, target: 18 tokens
[ENCODER] Starting encode with 17 tokens
[EMBEDDING] Forward pass - seq_len=17, d_model=128
[EMBEDDING] 2176/2176 non-zero, sum=0.975, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 2176/2176 non-zero, sum=0.975
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2112/2176 non-zero, sum=109.615685
[ENCODER] SCALED EMBEDS before add: 2176/2176 non-zero, sum=11.028700
[ENCODER] After pos encoding: 2176/2176 non-zero, sum=120.644333
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2176/2176 non-zero
[ENCODER_LAYER] After self-attention: 2176/2176 non-zero
[ENCODER_LAYER] After norm1: 2176/2176 non-zero
[ENCODER_LAYER] After feedforward: 2176/2176 non-zero
[ENCODER_LAYER] Final output: 2176/2176 non-zero
[ENCODER] Layer 0 output: 2176/2176 non-zero, sum=0.000019
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2176/2176 non-zero
[ENCODER_LAYER] After self-attention: 2176/2176 non-zero
[ENCODER_LAYER] After norm1: 2176/2176 non-zero
[ENCODER_LAYER] After feedforward: 2176/2176 non-zero
[ENCODER_LAYER] Final output: 2176/2176 non-zero
[ENCODER] Layer 1 output: 2176/2176 non-zero, sum=0.000025
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 17x128
[DEBUG] Encoder sample values: -0.498 1.892 -1.097 -0.420 -0.654 
[DECODER] Starting decode with 18 tokens
[EMBEDDING] Forward pass - seq_len=18, d_model=128
[EMBEDDING] 2304/2304 non-zero, sum=2.898, range=[-0.117, 4.280]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2304/2304 non-zero, sum=2.898
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2240/2304 non-zero, sum=116.117348
[DECODER] SCALED EMBEDS before add: 2304/2304 non-zero, sum=32.782627
[DECODER] After pos encoding: 2304/2304 non-zero, sum=148.899841
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2304/2304 non-zero, sum=0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2304/2304 non-zero, sum=-0.000013
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 18x128
[DEBUG] Decoder sample values: 0.542 -0.315 7.439 0.140 -0.385 
[DEBUG] Output projection - shape: 18x2000
[DEBUG] Output range: [-2.262, 5.529]
[DEBUG] Output sample values: 0.556 4.338 4.825 5.005 2.645 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.784
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.136
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 18 tokens with lr=0.050
[EMBEDDING] Gradient stats: 2304/2304 non-zero, sum=-0.031, range=[-0.050, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 18 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.847, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.847
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9.580351
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=67.396797
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.546 1.903 -1.106 -0.426 -0.639 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.550, range=[-0.117, 4.282]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.550
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=51.474003
[DECODER] After pos encoding: 1152/1152 non-zero, sum=109.290405
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.670 0.373 5.992 -0.635 0.615 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.226, 5.338]
[DEBUG] Output sample values: 0.772 3.958 4.915 4.454 3.012 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.775
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.033, range=[-0.095, 0.003]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 10 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.841, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=2.841
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=32.140320
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=96.410797
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.523 1.867 -1.096 -0.434 -0.670 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=5.536, range=[-0.117, 4.287]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=5.536
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=62.629295
[DECODER] After pos encoding: 1280/1280 non-zero, sum=126.899635
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000015
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: 0.918 -0.039 6.199 -0.479 0.555 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.450, 5.381]
[DEBUG] Output sample values: 0.692 4.216 5.381 4.414 3.139 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.765
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.012, bias: 0.244
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.025, range=[-0.083, 0.003]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.149, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.149
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12.993855
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=70.810295
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.526 1.890 -1.105 -0.431 -0.654 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=6.209, range=[-0.117, 4.291]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=6.209
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=70.251778
[DECODER] After pos encoding: 1024/1024 non-zero, sum=121.620163
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.618 0.267 5.613 -1.356 0.701 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.248, 5.030]
[DEBUG] Output sample values: 0.659 4.774 4.687 4.616 2.485 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.771
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.111
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.041, range=[-0.108, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.864, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.864
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=21.092239
[ENCODER] After pos encoding: 768/768 non-zero, sum=59.582500
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.551 1.894 -1.100 -0.428 -0.675 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=5.709, range=[-0.117, 4.297]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=5.709
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=64.585381
[DECODER] After pos encoding: 768/768 non-zero, sum=103.075645
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.496 0.377 5.358 -0.527 -0.777 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.358, 5.496]
[DEBUG] Output sample values: 0.599 3.959 4.755 5.401 2.450 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.764
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.066, range=[-0.143, 0.013]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 11 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.904, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=1.904
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=21.545162
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=85.815521
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.569 1.909 -1.064 -0.428 -0.660 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.807, range=[-0.117, 4.304]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=3.807
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=43.074512
[DECODER] After pos encoding: 1408/1408 non-zero, sum=113.804832
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: 0.000 0.876 6.683 -0.465 -0.568 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.375, 5.392]
[DEBUG] Output sample values: 0.237 4.519 4.845 4.975 1.929 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.778
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.081
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 11 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1407/1408 non-zero, sum=-0.018, range=[-0.078, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 10 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.412, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.412
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-4.657403
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=53.159031
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.558 1.881 -1.146 -0.412 -0.676 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.576, range=[-0.117, 4.308]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.576
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.460213
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.730606
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.117 0.974 5.929 -0.805 -2.072 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.202, 5.395]
[DEBUG] Output sample values: 0.700 4.288 4.980 4.795 1.955 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.779
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.089
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.024, range=[-0.085, 0.004]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.482, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=2.482
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.075157
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=85.891579
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.530 1.881 -1.142 -0.440 -0.662 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.286, range=[-0.117, 4.312]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.286
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=37.177406
[DECODER] After pos encoding: 1024/1024 non-zero, sum=88.545845
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.084 0.924 5.671 -0.777 -2.150 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.139, 6.420]
[DEBUG] Output sample values: 0.688 4.337 4.922 4.923 2.056 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.763
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.040, range=[-0.107, 0.006]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 4 tokens, target: 4 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=2.293, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=2.293
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=25.945221
[ENCODER] After pos encoding: 512/512 non-zero, sum=51.581360
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.543 1.891 -1.113 -0.417 -0.667 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=4.556, range=[-0.117, 4.317]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=4.556
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=51.547436
[DECODER] After pos encoding: 512/512 non-zero, sum=77.183578
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.603 0.695 5.209 -0.094 -0.837 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.214, 5.195]
[DEBUG] Output sample values: 0.189 4.190 5.012 4.962 2.139 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.747
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.011, bias: 0.221
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 4 tokens with lr=0.050
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.123, range=[-0.212, 0.012]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000

Época 50/50
[DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.148, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.148
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.985186
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.383183
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.529 1.895 -1.126 -0.447 -0.651 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.990, range=[-0.117, 4.328]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=2.990
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=33.829739
[DECODER] After pos encoding: 1024/1024 non-zero, sum=85.198036
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 1.126 -0.550 5.547 -1.303 -0.687 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.312, 5.135]
[DEBUG] Output sample values: 0.343 4.436 5.117 4.882 2.638 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.766
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.039, range=[-0.105, 0.006]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 13 tokens, target: 17 tokens
[ENCODER] Starting encode with 13 tokens
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.522, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1664/1664 non-zero, sum=0.522
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=5.907016
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.575356
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 13x128
[DEBUG] Encoder sample values: -0.538 1.906 -1.117 -0.436 -0.703 
[DECODER] Starting decode with 17 tokens
[EMBEDDING] Forward pass - seq_len=17, d_model=128
[EMBEDDING] 2176/2176 non-zero, sum=4.243, range=[-0.117, 4.333]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2176/2176 non-zero, sum=4.243
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2112/2176 non-zero, sum=109.615685
[DECODER] SCALED EMBEDS before add: 2176/2176 non-zero, sum=48.006947
[DECODER] After pos encoding: 2176/2176 non-zero, sum=157.622437
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2176/2176 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2176/2176 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 17x128
[DEBUG] Decoder sample values: -0.147 0.948 6.153 -0.706 -2.167 
[DEBUG] Output projection - shape: 17x2000
[DEBUG] Output range: [-2.520, 5.094]
[DEBUG] Output sample values: 0.727 4.247 4.913 4.984 2.087 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.782
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.009, bias: 0.208
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 17 tokens with lr=0.050
[EMBEDDING] Gradient stats: 2176/2176 non-zero, sum=-0.040, range=[-0.053, 0.003]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 17 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.495, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.495
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-5.604771
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=52.211670
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.521 1.898 -1.104 -0.414 -0.677 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.077, range=[-0.117, 4.336]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=3.077
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=34.815163
[DECODER] After pos encoding: 1152/1152 non-zero, sum=92.631622
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.133 0.938 6.084 -0.774 -2.112 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.231, 5.750]
[DEBUG] Output sample values: 0.688 4.364 4.951 4.977 2.108 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.777
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.032, range=[-0.095, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.802, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=2.802
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=31.703804
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=95.974228
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000023
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.518 1.842 -1.092 -0.418 -0.678 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.753, range=[-0.118, 4.340]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.753
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=31.151173
[DECODER] After pos encoding: 1152/1152 non-zero, sum=88.967499
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 1.191 -1.057 5.035 0.279 -0.750 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.603, 5.498]
[DEBUG] Output sample values: -0.259 4.814 5.498 5.045 2.925 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.766
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.029, range=[-0.091, 0.006]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.535, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.535
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=17.367733
[ENCODER] After pos encoding: 768/768 non-zero, sum=55.857983
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.521 1.888 -1.135 -0.446 -0.652 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.928, range=[-0.118, 4.345]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.928
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=44.444504
[DECODER] After pos encoding: 640/640 non-zero, sum=76.504730
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.864 -0.304 4.886 -1.990 -0.941 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.358, 5.103]
[DEBUG] Output sample values: 0.124 4.592 4.669 5.103 2.918 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.764
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.009, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.087, range=[-0.173, 0.011]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.597, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.597
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=18.070816
[ENCODER] After pos encoding: 768/768 non-zero, sum=56.561069
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.530 1.888 -1.103 -0.422 -0.682 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=4.930, range=[-0.118, 4.354]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=4.930
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=55.780941
[DECODER] After pos encoding: 768/768 non-zero, sum=94.271118
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.383 0.922 5.863 -0.324 -1.265 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.215, 5.248]
[DEBUG] Output sample values: 0.400 4.191 4.273 5.238 2.276 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.766
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.014, bias: 0.266
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.066, range=[-0.146, 0.011]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.442, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=-0.442
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-4.998470
[ENCODER] After pos encoding: 768/768 non-zero, sum=33.491764
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.531 1.897 -1.108 -0.436 -0.659 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=7.119, range=[-0.118, 4.361]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=7.119
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=80.542892
[DECODER] After pos encoding: 768/768 non-zero, sum=119.033089
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.728 0.687 6.030 -0.628 0.221 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.207, 5.168]
[DEBUG] Output sample values: 0.889 4.848 4.953 5.081 1.650 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.768
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.064, range=[-0.142, 0.009]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 17 tokens, target: 18 tokens
[ENCODER] Starting encode with 17 tokens
[EMBEDDING] Forward pass - seq_len=17, d_model=128
[EMBEDDING] 2176/2176 non-zero, sum=0.975, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 2176/2176 non-zero, sum=0.975
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2112/2176 non-zero, sum=109.615685
[ENCODER] SCALED EMBEDS before add: 2176/2176 non-zero, sum=11.028700
[ENCODER] After pos encoding: 2176/2176 non-zero, sum=120.644333
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2176/2176 non-zero
[ENCODER_LAYER] After self-attention: 2176/2176 non-zero
[ENCODER_LAYER] After norm1: 2176/2176 non-zero
[ENCODER_LAYER] After feedforward: 2176/2176 non-zero
[ENCODER_LAYER] Final output: 2176/2176 non-zero
[ENCODER] Layer 0 output: 2176/2176 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2176/2176 non-zero
[ENCODER_LAYER] After self-attention: 2176/2176 non-zero
[ENCODER_LAYER] After norm1: 2176/2176 non-zero
[ENCODER_LAYER] After feedforward: 2176/2176 non-zero
[ENCODER_LAYER] Final output: 2176/2176 non-zero
[ENCODER] Layer 1 output: 2176/2176 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 17x128
[DEBUG] Encoder sample values: -0.498 1.892 -1.097 -0.420 -0.654 
[DECODER] Starting decode with 18 tokens
[EMBEDDING] Forward pass - seq_len=18, d_model=128
[EMBEDDING] 2304/2304 non-zero, sum=2.955, range=[-0.118, 4.368]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2304/2304 non-zero, sum=2.955
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2240/2304 non-zero, sum=116.117348
[DECODER] SCALED EMBEDS before add: 2304/2304 non-zero, sum=33.432968
[DECODER] After pos encoding: 2304/2304 non-zero, sum=149.550156
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2304/2304 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2304/2304 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 18x128
[DEBUG] Decoder sample values: 0.549 -0.326 7.423 0.129 -0.388 
[DEBUG] Output projection - shape: 18x2000
[DEBUG] Output range: [-2.266, 5.626]
[DEBUG] Output sample values: 0.549 4.325 4.792 5.071 2.666 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.784
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.136
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 18 tokens with lr=0.050
[EMBEDDING] Gradient stats: 2304/2304 non-zero, sum=-0.030, range=[-0.050, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 18 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.847, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.847
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9.580351
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=67.396797
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.546 1.903 -1.106 -0.426 -0.639 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.606, range=[-0.118, 4.370]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.606
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=52.106960
[DECODER] After pos encoding: 1152/1152 non-zero, sum=109.923401
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.677 0.361 5.981 -0.642 0.609 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.228, 5.415]
[DEBUG] Output sample values: 0.764 3.953 4.878 4.532 3.032 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.776
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.099
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.033, range=[-0.095, 0.004]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 10 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.841, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=2.841
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=32.140320
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=96.410797
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.522 1.866 -1.097 -0.434 -0.671 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=5.589, range=[-0.118, 4.375]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=5.589
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=63.231258
[DECODER] After pos encoding: 1280/1280 non-zero, sum=127.501808
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: 0.927 -0.050 6.186 -0.487 0.553 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.452, 5.359]
[DEBUG] Output sample values: 0.686 4.206 5.359 4.455 3.157 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.766
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.011, bias: 0.245
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.025, range=[-0.083, 0.003]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.149, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.149
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12.993855
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=70.810295
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.525 1.890 -1.106 -0.431 -0.654 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=6.265, range=[-0.118, 4.379]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=6.265
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=70.881241
[DECODER] After pos encoding: 1024/1024 non-zero, sum=122.249680
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.623 0.256 5.600 -1.361 0.694 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.246, 5.051]
[DEBUG] Output sample values: 0.653 4.774 4.668 4.702 2.506 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.771
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.111
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.040, range=[-0.108, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.864, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.864
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=21.092239
[ENCODER] After pos encoding: 768/768 non-zero, sum=59.582500
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.551 1.894 -1.100 -0.428 -0.675 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=5.766, range=[-0.118, 4.385]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=5.766
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=65.229622
[DECODER] After pos encoding: 768/768 non-zero, sum=103.719879
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.502 0.364 5.346 -0.532 -0.782 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.358, 5.566]
[DEBUG] Output sample values: 0.593 3.965 4.732 5.463 2.472 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.764
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.066, range=[-0.144, 0.013]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 10 tokens, target: 11 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.904, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=1.904
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=21.545162
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=85.815521
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.569 1.909 -1.064 -0.428 -0.660 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.864, range=[-0.118, 4.392]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=3.864
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=43.717121
[DECODER] After pos encoding: 1408/1408 non-zero, sum=114.447479
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: 0.009 0.858 6.670 -0.473 -0.571 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.370, 5.354]
[DEBUG] Output sample values: 0.228 4.547 4.802 5.005 1.962 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.779
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.081
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 11 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.018, range=[-0.078, 0.005]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 10 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.412, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.412
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-4.657403
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=53.159031
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.558 1.881 -1.147 -0.412 -0.676 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.634, range=[-0.118, 4.396]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.634
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=41.110374
[DECODER] After pos encoding: 1280/1280 non-zero, sum=105.380890
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.108 0.960 5.913 -0.810 -2.072 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.199, 5.410]
[DEBUG] Output sample values: 0.695 4.318 4.985 4.840 1.973 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.779
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.089
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.024, range=[-0.085, 0.004]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.482, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=2.482
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.075157
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=85.891579
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.530 1.881 -1.143 -0.440 -0.662 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.342, range=[-0.118, 4.400]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.342
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=37.808956
[DECODER] After pos encoding: 1024/1024 non-zero, sum=89.177353
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.092 0.911 5.656 -0.782 -2.149 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.141, 6.388]
[DEBUG] Output sample values: 0.682 4.360 4.920 4.967 2.072 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.763
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.040, range=[-0.107, 0.006]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[DEBUG] Forward - source: 4 tokens, target: 4 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=2.293, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=2.293
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=25.945221
[ENCODER] After pos encoding: 512/512 non-zero, sum=51.581360
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.543 1.891 -1.113 -0.417 -0.667 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=4.614, range=[-0.118, 4.405]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=4.614
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=52.196869
[DECODER] After pos encoding: 512/512 non-zero, sum=77.833038
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.596 0.657 5.214 -0.079 -0.832 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.216, 5.156]
[DEBUG] Output sample values: 0.170 4.223 4.985 4.992 2.168 
[DEBUG] Forward completed!
[LOSS] Gradient sum: 1.748
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.011, bias: 0.221
[LINEAR] Output projection - using 5x learning rate: 0.250
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 4 tokens with lr=0.050
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.123, range=[-0.212, 0.013]
[EMBEDDING] Sample weights after update: -0.09231399 -0.01930349 0.01556114 -0.01644287 0.00668259 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
  Loss: 5.13635874
[DEBUG] Forward - source: 8 tokens, target: 1 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.148, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.148
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.985186
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.383183
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.529 1.895 -1.127 -0.448 -0.650 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=4.205, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=4.205
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=47.577587
[DECODER] After pos encoding: 128/128 non-zero, sum=53.977570
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.224 1.379 2.536 -1.136 -0.789 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.315, 5.384]
[DEBUG] Output sample values: 0.624 4.602 5.384 4.166 2.079 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 30 (score: 3.1, target_len: 7) [Top scores: 31:3.9 7:3.4 30:3.1 6:3.1 1:3.1 ]
[DEBUG] Forward - source: 8 tokens, target: 2 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.148, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.148
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.985186
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.383183
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.529 1.895 -1.127 -0.448 -0.650 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=4.761, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=4.761
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=53.867996
[DECODER] After pos encoding: 256/256 non-zero, sum=66.673950
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.167 1.239 2.994 -1.257 -0.756 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.362, 5.396]
[DEBUG] Output sample values: 0.534 4.609 5.396 4.242 2.127 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 18 (score: 3.8, target_len: 7) [Top scores: 18:3.8 14:3.6 7:3.4 1:3.4 6:3.2 ]
[DEBUG] Forward - source: 8 tokens, target: 3 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.148, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.148
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.985186
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.383183
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.529 1.895 -1.127 -0.448 -0.650 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=5.752, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=5.752
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=65.079948
[DECODER] After pos encoding: 384/384 non-zero, sum=84.297943
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.202 1.376 3.480 -1.227 -0.740 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.288, 5.318]
[DEBUG] Output sample values: 0.530 4.595 5.318 4.282 2.125 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 7 (score: 4.3, target_len: 7) [Top scores: 7:4.3 14:3.5 31:3.3 11:3.0 1:2.9 ]
[DEBUG] Forward - source: 8 tokens, target: 4 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.148, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.148
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.985186
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.383183
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.529 1.895 -1.127 -0.448 -0.650 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=5.958, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=5.958
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=67.401817
[DECODER] After pos encoding: 512/512 non-zero, sum=93.037834
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.254 1.396 3.672 -1.225 -0.722 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.290, 5.297]
[DEBUG] Output sample values: 0.522 4.592 5.297 4.281 2.085 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 8 tokens, target: 5 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.148, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.148
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.985186
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.383183
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.529 1.895 -1.127 -0.448 -0.650 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=6.589, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=6.589
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=74.541077
[DECODER] After pos encoding: 640/640 non-zero, sum=106.601173
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.150 1.133 4.385 -1.292 -0.943 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.162, 5.178]
[DEBUG] Output sample values: 0.551 4.601 5.178 4.487 2.350 
[DEBUG] Forward completed!
  Test: <sos> qu est que <unk> hacer

¡Entrenamiento completado!

=== Pruebas de Traducción ===
[DEBUG] Forward - source: 3 tokens, target: 1 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.807, range=[-0.104, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-0.807
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-9.132109
[ENCODER] After pos encoding: 384/384 non-zero, sum=10.085964
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: -0.542 1.893 -1.114 -0.423 -0.654 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=4.205, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=4.205
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=47.577587
[DECODER] After pos encoding: 128/128 non-zero, sum=53.977570
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.232 1.371 2.546 -1.114 -0.793 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.305, 5.383]
[DEBUG] Output sample values: 0.636 4.604 5.383 4.175 2.076 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 30 (score: 3.1, target_len: 2) [Top scores: 31:3.9 7:3.4 30:3.1 6:3.1 1:3.1 ]
[DEBUG] Forward - source: 3 tokens, target: 2 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.807, range=[-0.104, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-0.807
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-9.132109
[ENCODER] After pos encoding: 384/384 non-zero, sum=10.085964
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: -0.542 1.893 -1.114 -0.423 -0.654 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=4.761, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=4.761
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=53.867996
[DECODER] After pos encoding: 256/256 non-zero, sum=66.673950
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.253 0.316 4.843 -0.076 -0.396 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.103, 4.718]
[DEBUG] Output sample values: 0.834 4.590 4.203 4.718 2.562 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 6 (score: 3.5, target_len: 2) [Top scores: 18:3.8 7:3.7 6:3.5 1:3.1 11:3.1 ]
ENG: <sos> hello <eos>
ESP: <sos> qu la <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.011, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.011
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=11.443428
[ENCODER] After pos encoding: 640/640 non-zero, sum=43.503609
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.548 1.890 -1.113 -0.432 -0.655 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=4.205, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=4.205
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=47.577587
[DECODER] After pos encoding: 128/128 non-zero, sum=53.977570
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.236 1.370 2.547 -1.121 -0.796 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.305, 5.382]
[DEBUG] Output sample values: 0.634 4.610 5.382 4.177 2.066 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 30 (score: 3.1, target_len: 4) [Top scores: 31:3.9 7:3.4 30:3.1 1:3.1 6:3.1 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.011, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.011
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=11.443428
[ENCODER] After pos encoding: 640/640 non-zero, sum=43.503609
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.548 1.890 -1.113 -0.432 -0.655 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=4.761, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=4.761
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=53.867996
[DECODER] After pos encoding: 256/256 non-zero, sum=66.673950
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.240 1.641 4.237 -1.209 -0.855 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.215, 5.082]
[DEBUG] Output sample values: 0.492 4.538 5.030 4.789 1.838 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 18 (score: 4.3, target_len: 4) [Top scores: 18:4.3 63:3.5 1:3.3 7:3.1 31:3.0 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.011, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.011
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=11.443428
[ENCODER] After pos encoding: 640/640 non-zero, sum=43.503609
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.548 1.890 -1.113 -0.432 -0.655 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=5.752, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=5.752
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=65.079948
[DECODER] After pos encoding: 384/384 non-zero, sum=84.297943
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.037 1.018 4.899 -1.319 -1.896 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.379, 5.184]
[DEBUG] Output sample values: 0.371 4.988 4.067 5.184 1.604 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 63 (score: 3.9, target_len: 4) [Top scores: 63:3.9 7:3.6 1:3.4 31:3.3 6:3.2 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.011, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.011
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=11.443428
[ENCODER] After pos encoding: 640/640 non-zero, sum=43.503609
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.548 1.890 -1.113 -0.432 -0.655 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=5.028, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=5.028
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=56.891045
[DECODER] After pos encoding: 512/512 non-zero, sum=82.527054
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.049 0.982 5.052 -1.302 -1.832 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.354, 5.239]
[DEBUG] Output sample values: 0.376 5.008 4.090 5.195 1.594 
[DEBUG] Forward completed!
ENG: <sos> how are you <eos>
ESP: <sos> qu est hacer para <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.861, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.861
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=21.059986
[ENCODER] After pos encoding: 512/512 non-zero, sum=46.696117
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.545 1.895 -1.121 -0.431 -0.650 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=4.205, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=4.205
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=47.577587
[DECODER] After pos encoding: 128/128 non-zero, sum=53.977570
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.236 1.374 2.539 -1.121 -0.790 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.310, 5.392]
[DEBUG] Output sample values: 0.630 4.604 5.392 4.166 2.080 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 31 (score: 3.9, target_len: 3) [Top scores: 31:3.9 7:3.4 30:3.1 6:3.1 1:3.1 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.861, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.861
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=21.059986
[ENCODER] After pos encoding: 512/512 non-zero, sum=46.696117
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.545 1.895 -1.121 -0.431 -0.650 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=5.444, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=5.444
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=61.590771
[DECODER] After pos encoding: 256/256 non-zero, sum=74.396767
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.248 1.471 3.497 -0.925 -0.648 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.332, 5.340]
[DEBUG] Output sample values: 0.600 4.649 5.340 4.034 2.272 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 7 (score: 3.5, target_len: 3) [Top scores: 7:3.5 1:3.3 30:3.2 77:2.9 14:2.7 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.861, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.861
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=21.059986
[ENCODER] After pos encoding: 512/512 non-zero, sum=46.696117
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.545 1.895 -1.121 -0.431 -0.650 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=5.649, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=5.649
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=63.912651
[DECODER] After pos encoding: 384/384 non-zero, sum=83.130653
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.279 1.330 3.892 -0.969 -0.636 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.441, 5.456]
[DEBUG] Output sample values: 0.611 4.685 5.456 4.049 2.311 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 1 (score: 3.9, target_len: 3) [Top scores: 1:3.9 11:3.4 26:3.0 162:2.8 30:2.7 ]
ENG: <sos> good morning <eos>
ESP: <sos> para que <unk> <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.114, range=[-0.106, 0.104]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.114
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=12.605040
[ENCODER] After pos encoding: 512/512 non-zero, sum=38.241169
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.527 1.894 -1.097 -0.424 -0.637 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=4.205, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=4.205
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=47.577587
[DECODER] After pos encoding: 128/128 non-zero, sum=53.977570
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.222 1.371 2.559 -1.114 -0.777 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.306, 5.382]
[DEBUG] Output sample values: 0.630 4.597 5.382 4.176 2.072 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 30 (score: 3.1, target_len: 3) [Top scores: 31:3.9 7:3.4 30:3.1 6:3.1 1:3.1 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.114, range=[-0.106, 0.104]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.114
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=12.605040
[ENCODER] After pos encoding: 512/512 non-zero, sum=38.241169
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.527 1.894 -1.097 -0.424 -0.637 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=4.761, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=4.761
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=53.867996
[DECODER] After pos encoding: 256/256 non-zero, sum=66.673950
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 1.057 1.021 4.907 -0.263 -0.421 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.166, 4.658]
[DEBUG] Output sample values: 0.292 3.727 4.299 4.658 2.246 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 18 (score: 3.5, target_len: 3) [Top scores: 6:3.8 18:3.5 424:3.4 51:3.3 31:3.3 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.114, range=[-0.106, 0.104]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.114
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=12.605040
[ENCODER] After pos encoding: 512/512 non-zero, sum=38.241169
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.527 1.894 -1.097 -0.424 -0.637 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=5.752, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=5.752
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=65.079948
[DECODER] After pos encoding: 384/384 non-zero, sum=84.297943
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 1.041 1.009 4.968 -0.265 -0.407 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.083, 4.771]
[DEBUG] Output sample values: 0.291 3.738 4.302 4.666 2.240 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 63 (score: 3.6, target_len: 3) [Top scores: 63:3.6 31:3.4 7:3.0 11:2.9 16:2.9 ]
ENG: <sos> thank you <eos>
ESP: <sos> qu est hacer <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.224, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=0.224
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.536046
[ENCODER] After pos encoding: 640/640 non-zero, sum=34.596214
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.514 1.854 -1.112 -0.405 -0.652 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=4.205, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=4.205
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=47.577587
[DECODER] After pos encoding: 128/128 non-zero, sum=53.977570
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.213 1.342 2.547 -1.103 -0.792 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.306, 5.403]
[DEBUG] Output sample values: 0.618 4.605 5.403 4.174 2.088 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 31 (score: 3.9, target_len: 4) [Top scores: 31:3.9 7:3.4 30:3.1 6:3.1 1:3.1 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.224, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=0.224
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.536046
[ENCODER] After pos encoding: 640/640 non-zero, sum=34.596214
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.514 1.854 -1.112 -0.405 -0.652 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=5.444, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=5.444
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=61.590771
[DECODER] After pos encoding: 256/256 non-zero, sum=74.396767
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 1.369 -0.941 4.133 0.199 -0.643 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.206, 5.624]
[DEBUG] Output sample values: -0.204 4.902 5.624 4.786 2.991 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 7 (score: 3.8, target_len: 4) [Top scores: 7:3.8 18:3.5 1:3.5 30:3.4 14:3.2 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.224, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=0.224
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.536046
[ENCODER] After pos encoding: 640/640 non-zero, sum=34.596214
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.514 1.854 -1.112 -0.405 -0.652 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=5.649, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=5.649
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=63.912651
[DECODER] After pos encoding: 384/384 non-zero, sum=83.130653
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 1.396 -0.930 4.491 0.228 -0.623 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.161, 5.641]
[DEBUG] Output sample values: -0.201 4.847 5.641 4.807 3.015 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 63 (score: 4.0, target_len: 4) [Top scores: 63:4.0 18:3.4 1:3.3 11:3.3 30:2.8 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.224, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=0.224
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.536046
[ENCODER] After pos encoding: 640/640 non-zero, sum=34.596214
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.514 1.854 -1.112 -0.405 -0.652 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=4.925, range=[-0.119, 4.416]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=4.925
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=55.723736
[DECODER] After pos encoding: 512/512 non-zero, sum=81.359756
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: 1.359 -0.942 4.582 0.234 -0.586 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.256, 5.639]
[DEBUG] Output sample values: -0.197 4.861 5.639 4.816 2.990 
[DEBUG] Forward completed!
ENG: <sos> i love you <eos>
ESP: <sos> para que hacer qu <eos>
---