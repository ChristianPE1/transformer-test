Se han truncado las últimas 5000 líneas del flujo de salida.
[EMBEDDING] 1024/1024 non-zero, sum=3.363, range=[-0.106, 0.843]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.363
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=38.052525
[DECODER] After pos encoding: 1024/1024 non-zero, sum=89.420967
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.564 -1.228 2.096 -1.460 0.664 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.083, 3.997]
[DEBUG] Output sample values: -0.024 2.830 3.311 3.334 1.299 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.083, 3.997] Var:0.371
[LOSS] Calculated loss: 6.314
[LOSS] Gradient sum: 1.791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.010, bias: 0.224
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.052, range=[-0.111, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 11 tokens, target: 12 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.926, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.926
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=10.475280
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=81.205734
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: -0.504 -1.371 -1.774 -1.258 -0.993 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.838, range=[-0.106, 0.844]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.838
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=9.475293
[DECODER] After pos encoding: 1536/1536 non-zero, sum=86.671616
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: 0.489 -2.213 3.439 -1.330 -0.898 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.234, 4.047]
[DEBUG] Output sample values: 0.827 2.686 3.621 3.475 1.469 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.234, 4.047] Var:0.374
[LOSS] Calculated loss: 6.593
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 12 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.016, range=[-0.074, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.767, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.767
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=19.990164
[ENCODER] After pos encoding: 768/768 non-zero, sum=58.480438
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.538 -0.539 -2.245 -1.345 -1.371 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.307, range=[-0.106, 0.845]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=2.307
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=26.101601
[DECODER] After pos encoding: 896/896 non-zero, sum=71.027962
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.451 -0.226 2.090 -1.804 -1.107 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.606, 4.009]
[DEBUG] Output sample values: 0.182 2.889 3.148 3.542 1.847 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.606, 4.009] Var:0.366
[LOSS] Calculated loss: 6.529
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.069, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.620, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.620
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-18.329863
[ENCODER] After pos encoding: 896/896 non-zero, sum=26.596470
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.611 -0.842 -1.861 -1.328 -1.275 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.304, range=[-0.106, 0.846]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.304
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.443780
[DECODER] After pos encoding: 896/896 non-zero, sum=41.482544
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.142 -0.923 3.207 -1.596 -1.529 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.531, 3.971]
[DEBUG] Output sample values: 0.296 3.056 3.237 3.714 1.147 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.531, 3.971] Var:0.380
[LOSS] Calculated loss: 6.788
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.067, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 6 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=5.102, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=5.102
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=57.720802
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=115.537254
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.673 -1.358 -2.193 -1.240 -0.856 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.124, range=[-0.106, 0.847]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-1.124
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.715258
[DECODER] After pos encoding: 768/768 non-zero, sum=25.774996
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.747 -2.065 2.881 -0.716 -0.599 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.519, 3.793]
[DEBUG] Output sample values: 0.997 3.223 3.092 3.010 1.365 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.519, 3.793] Var:0.384
[LOSS] Calculated loss: 6.052
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.087, range=[-0.148, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.261, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.261
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-2.947820
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=48.420589
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.309 -1.113 -1.996 -1.063 -1.358 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.543, range=[-0.106, 0.849]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.543
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=51.394028
[DECODER] After pos encoding: 896/896 non-zero, sum=96.320343
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.208 -1.159 3.712 -1.030 -1.331 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.119, 3.821]
[DEBUG] Output sample values: 0.132 3.037 3.074 3.239 1.858 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.119, 3.821] Var:0.373
[LOSS] Calculated loss: 6.670
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.067, range=[-0.127, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 12 tokens, target: 9 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.313, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=2.313
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=26.165476
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=103.361839
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: -0.528 -1.112 -2.188 -1.025 -1.080 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.441, range=[-0.106, 0.850]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.441
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=16.306517
[DECODER] After pos encoding: 1152/1152 non-zero, sum=74.122917
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.137 -1.661 3.264 -0.723 -0.884 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.614, 4.387]
[DEBUG] Output sample values: 0.500 3.294 3.901 3.152 1.686 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.614, 4.387] Var:0.376
[LOSS] Calculated loss: 6.883
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.122, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.122
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12.697701
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=70.514168
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.681 -1.370 -2.438 -1.257 -0.951 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.063, range=[-0.106, 0.851]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.063
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=34.656746
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.024963
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000013
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.479 -2.457 1.308 -1.386 -0.399 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.165, 4.036]
[DEBUG] Output sample values: 0.179 3.129 3.430 3.875 1.807 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.165, 4.036] Var:0.374
[LOSS] Calculated loss: 6.706
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.051, range=[-0.111, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 6 tokens, target: 8 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.974, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.974
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=22.335400
[ENCODER] After pos encoding: 768/768 non-zero, sum=60.825691
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.520 -1.807 -1.840 -1.328 -0.974 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.474, range=[-0.106, 0.852]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.474
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=39.301003
[DECODER] After pos encoding: 1024/1024 non-zero, sum=90.669388
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.254 -3.203 2.588 -1.201 -0.716 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.285, 4.156]
[DEBUG] Output sample values: 0.552 2.541 3.089 3.945 1.419 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.285, 4.156] Var:0.377
[LOSS] Calculated loss: 6.812
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.053, range=[-0.111, 0.003]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.418, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-1.418
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-16.037575
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=41.778893
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.319 -1.773 -2.052 -1.127 -1.322 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.876, range=[-0.106, 0.853]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-0.876
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-9.912925
[DECODER] After pos encoding: 1152/1152 non-zero, sum=47.903503
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.633 -2.753 2.708 -0.949 -1.431 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.080, 3.775]
[DEBUG] Output sample values: 1.076 2.741 3.528 3.536 1.674 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.080, 3.775] Var:0.376
[LOSS] Calculated loss: 6.376
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.010, bias: 0.191
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 4 tokens, target: 5 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.997, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-0.997
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-11.283584
[ENCODER] After pos encoding: 512/512 non-zero, sum=14.352555
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.220 -0.803 -1.900 -1.148 -1.150 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.034, range=[-0.106, 0.854]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.034
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=11.698930
[DECODER] After pos encoding: 640/640 non-zero, sum=43.759136
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.443 -0.700 2.456 -1.190 -1.137 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.517, 3.736]
[DEBUG] Output sample values: 0.561 2.951 3.271 3.310 1.567 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.517, 3.736] Var:0.375
[LOSS] Calculated loss: 6.033
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.009, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.116, range=[-0.178, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.885, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=0.885
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.011981
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.072182
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.230 -1.603 -1.576 -1.279 -1.207 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.856, range=[-0.106, 0.856]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.856
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=9.684860
[DECODER] After pos encoding: 768/768 non-zero, sum=48.175106
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.669 -3.128 2.885 -1.011 -0.993 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.259, 4.146]
[DEBUG] Output sample values: 1.049 2.678 3.347 4.038 1.384 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.259, 4.146] Var:0.380
[LOSS] Calculated loss: 5.782
[LOSS] Gradient sum: 1.786
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.014, bias: 0.292
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.087, range=[-0.148, 0.004]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.331, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.331
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=15.055869
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=66.424286
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.455 -0.701 -1.816 -1.298 -1.437 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.258, range=[-0.106, 0.857]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-0.258
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-2.917661
[DECODER] After pos encoding: 1280/1280 non-zero, sum=61.352772
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: 0.149 -0.756 2.955 -1.865 -1.835 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.140, 3.970]
[DEBUG] Output sample values: 0.595 3.285 3.502 3.243 1.948 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.140, 3.970] Var:0.368
[LOSS] Calculated loss: 6.618
[LOSS] Gradient sum: 1.791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 10 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.031, range=[-0.089, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 5 tokens, target: 7 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.104, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.104
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-1.174104
[ENCODER] After pos encoding: 640/640 non-zero, sum=30.886078
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.107 -1.175 -1.834 -1.422 -1.283 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.024, range=[-0.106, 0.858]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.024
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11.579734
[DECODER] After pos encoding: 896/896 non-zero, sum=56.506084
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
[LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 7.601
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.128, 0.000]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000

Época 49/50
[DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.225, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.225
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13.859140
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=65.227509
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.577 -1.224 -1.952 -1.521 -0.470 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.190, range=[-0.106, 0.860]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.190
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=2.145433
[DECODER] After pos encoding: 768/768 non-zero, sum=40.635662
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.295 -1.727 2.615 -1.549 0.765 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.549, 3.606]
[DEBUG] Output sample values: 0.408 3.282 2.841 3.068 1.496 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.549, 3.606] Var:0.378
[LOSS] Calculated loss: 6.287
[LOSS] Gradient sum: 1.791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.088, range=[-0.149, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.838, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=0.838
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=9.484003
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=60.852406
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.461 -0.970 -2.017 -1.044 -0.863 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.484, range=[-0.106, 0.861]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-1.484
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-16.787527
[DECODER] After pos encoding: 1280/1280 non-zero, sum=47.482876
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: 0.131 -1.418 3.560 -0.882 0.098 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.317, 4.256]
[DEBUG] Output sample values: 0.432 3.094 3.394 2.818 1.462 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.317, 4.256] Var:0.371
[LOSS] Calculated loss: 6.923
[LOSS] Gradient sum: 1.795
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 10 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.031, range=[-0.089, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.222, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-1.222
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.824454
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=43.991993
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000012
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.393 -1.145 -2.072 -1.343 -0.486 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.378, range=[-0.106, 0.862]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.378
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=38.220753
[DECODER] After pos encoding: 1024/1024 non-zero, sum=89.589142
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.582 -1.224 2.149 -1.460 0.678 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.084, 3.993]
[DEBUG] Output sample values: -0.019 2.837 3.320 3.337 1.299 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.084, 3.993] Var:0.372
[LOSS] Calculated loss: 6.309
[LOSS] Gradient sum: 1.791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.010, bias: 0.224
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.052, range=[-0.111, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 11 tokens, target: 12 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.926, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.926
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=10.475280
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=81.205734
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000017
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: -0.504 -1.371 -1.773 -1.258 -0.993 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.851, range=[-0.106, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.851
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=9.624275
[DECODER] After pos encoding: 1536/1536 non-zero, sum=86.820679
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: 0.500 -2.219 3.497 -1.329 -0.894 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.233, 4.050]
[DEBUG] Output sample values: 0.832 2.704 3.622 3.484 1.463 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.233, 4.050] Var:0.374
[LOSS] Calculated loss: 6.584
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 12 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.016, range=[-0.074, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.767, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.767
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=19.990164
[ENCODER] After pos encoding: 768/768 non-zero, sum=58.480438
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.538 -0.539 -2.245 -1.345 -1.371 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.323, range=[-0.106, 0.864]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=2.323
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=26.279114
[DECODER] After pos encoding: 896/896 non-zero, sum=71.205406
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.485 -0.211 2.181 -1.812 -1.089 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.604, 4.002]
[DEBUG] Output sample values: 0.190 2.895 3.158 3.570 1.845 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.604, 4.002] Var:0.366
[LOSS] Calculated loss: 6.518
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.069, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.620, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.620
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-18.329863
[ENCODER] After pos encoding: 896/896 non-zero, sum=26.596470
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.611 -0.842 -1.861 -1.328 -1.275 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.289, range=[-0.106, 0.865]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.289
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.268914
[DECODER] After pos encoding: 896/896 non-zero, sum=41.657455
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.131 -0.920 3.269 -1.591 -1.530 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.538, 3.988]
[DEBUG] Output sample values: 0.299 3.082 3.238 3.728 1.136 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.538, 3.988] Var:0.381
[LOSS] Calculated loss: 6.779
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.067, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 6 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=5.102, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=5.102
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=57.720802
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=115.537254
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.673 -1.358 -2.193 -1.240 -0.856 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.109, range=[-0.106, 0.866]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-1.109
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.546342
[DECODER] After pos encoding: 768/768 non-zero, sum=25.943916
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.741 -2.071 2.955 -0.700 -0.586 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.522, 3.801]
[DEBUG] Output sample values: 1.010 3.245 3.106 3.016 1.356 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.522, 3.801] Var:0.384
[LOSS] Calculated loss: 6.042
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.087, range=[-0.148, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.261, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.261
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-2.947820
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=48.420589
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.309 -1.113 -1.996 -1.063 -1.358 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.558, range=[-0.106, 0.868]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.558
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=51.572647
[DECODER] After pos encoding: 896/896 non-zero, sum=96.498940
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.216 -1.155 3.793 -1.025 -1.320 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.120, 3.825]
[DEBUG] Output sample values: 0.138 3.040 3.076 3.248 1.855 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.120, 3.825] Var:0.374
[LOSS] Calculated loss: 6.664
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.067, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 12 tokens, target: 9 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.313, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=2.313
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=26.165476
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=103.361839
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: -0.528 -1.112 -2.187 -1.025 -1.080 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.457, range=[-0.106, 0.869]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.457
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=16.482908
[DECODER] After pos encoding: 1152/1152 non-zero, sum=74.299309
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.129 -1.669 3.316 -0.715 -0.873 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.608, 4.382]
[DEBUG] Output sample values: 0.507 3.300 3.903 3.159 1.681 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.608, 4.382] Var:0.376
[LOSS] Calculated loss: 6.877
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.122, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.122
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12.697701
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=70.514168
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.681 -1.370 -2.438 -1.257 -0.951 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.079, range=[-0.106, 0.870]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.079
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=34.834427
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.202721
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.476 -2.471 1.358 -1.390 -0.386 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.165, 4.042]
[DEBUG] Output sample values: 0.183 3.139 3.440 3.887 1.806 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.165, 4.042] Var:0.374
[LOSS] Calculated loss: 6.699
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.051, range=[-0.111, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 6 tokens, target: 8 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.974, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.974
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=22.335400
[ENCODER] After pos encoding: 768/768 non-zero, sum=60.825691
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.520 -1.807 -1.840 -1.328 -0.974 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.488, range=[-0.106, 0.871]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.488
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=39.467453
[DECODER] After pos encoding: 1024/1024 non-zero, sum=90.835876
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.266 -3.213 2.636 -1.196 -0.712 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.283, 4.164]
[DEBUG] Output sample values: 0.558 2.552 3.095 3.957 1.416 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.283, 4.164] Var:0.377
[LOSS] Calculated loss: 6.804
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.053, range=[-0.111, 0.003]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.418, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-1.418
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-16.037575
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=41.778893
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.319 -1.773 -2.052 -1.127 -1.322 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.862, range=[-0.106, 0.872]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-0.862
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-9.755059
[DECODER] After pos encoding: 1152/1152 non-zero, sum=48.061371
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.645 -2.756 2.764 -0.940 -1.425 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.068, 3.779]
[DEBUG] Output sample values: 1.084 2.751 3.536 3.547 1.667 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.068, 3.779] Var:0.377
[LOSS] Calculated loss: 6.368
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.010, bias: 0.191
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 4 tokens, target: 5 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.997, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-0.997
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-11.283584
[ENCODER] After pos encoding: 512/512 non-zero, sum=14.352555
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.220 -0.803 -1.899 -1.148 -1.150 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.050, range=[-0.106, 0.873]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.050
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=11.875597
[DECODER] After pos encoding: 640/640 non-zero, sum=43.935757
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.459 -0.693 2.534 -1.187 -1.136 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.524, 3.742]
[DEBUG] Output sample values: 0.571 2.963 3.279 3.318 1.561 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.524, 3.742] Var:0.375
[LOSS] Calculated loss: 6.022
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.009, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.116, range=[-0.178, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.885, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=0.885
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.011981
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.072182
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.230 -1.603 -1.576 -1.279 -1.207 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.870, range=[-0.106, 0.875]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.870
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=9.845993
[DECODER] After pos encoding: 768/768 non-zero, sum=48.336269
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.681 -3.140 2.932 -1.006 -0.988 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.261, 4.148]
[DEBUG] Output sample values: 1.055 2.691 3.356 4.042 1.379 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.261, 4.148] Var:0.380
[LOSS] Calculated loss: 5.773
[LOSS] Gradient sum: 1.786
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.012, bias: 0.292
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.087, range=[-0.148, 0.004]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.331, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.331
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=15.055869
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=66.424286
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.455 -0.701 -1.816 -1.298 -1.437 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.243, range=[-0.106, 0.877]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-0.243
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-2.753310
[DECODER] After pos encoding: 1280/1280 non-zero, sum=61.517113
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: 0.168 -0.699 3.190 -1.869 -1.812 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.142, 3.966]
[DEBUG] Output sample values: 0.605 3.269 3.499 3.259 1.945 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.142, 3.966] Var:0.368
[LOSS] Calculated loss: 6.610
[LOSS] Gradient sum: 1.791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 10 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.031, range=[-0.089, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 5 tokens, target: 7 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.104, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.104
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-1.174104
[ENCODER] After pos encoding: 640/640 non-zero, sum=30.886078
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.107 -1.175 -1.834 -1.422 -1.283 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.038, range=[-0.106, 0.877]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.038
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11.746736
[DECODER] After pos encoding: 896/896 non-zero, sum=56.673065
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
[LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 7.601
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.128, 0.000]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000

Época 50/50
[DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.225, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.225
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13.859140
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=65.227509
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.577 -1.224 -1.951 -1.521 -0.470 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.205, range=[-0.106, 0.879]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.205
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=2.313985
[DECODER] After pos encoding: 768/768 non-zero, sum=40.804241
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.284 -1.734 2.673 -1.542 0.783 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.550, 3.620]
[DEBUG] Output sample values: 0.414 3.296 2.849 3.069 1.490 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.550, 3.620] Var:0.378
[LOSS] Calculated loss: 6.278
[LOSS] Gradient sum: 1.791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.088, range=[-0.149, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.838, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=0.838
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=9.484003
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=60.852406
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.461 -0.970 -2.017 -1.044 -0.863 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.469, range=[-0.106, 0.880]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-1.469
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-16.619314
[DECODER] After pos encoding: 1280/1280 non-zero, sum=47.651119
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: 0.139 -1.420 3.633 -0.876 0.118 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.321, 4.274]
[DEBUG] Output sample values: 0.438 3.105 3.417 2.817 1.452 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.321, 4.274] Var:0.372
[LOSS] Calculated loss: 6.913
[LOSS] Gradient sum: 1.795
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 10 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.031, range=[-0.089, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.222, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-1.222
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.824454
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=43.991993
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.393 -1.145 -2.072 -1.343 -0.486 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.393, range=[-0.106, 0.881]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.393
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=38.388760
[DECODER] After pos encoding: 1024/1024 non-zero, sum=89.757133
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.600 -1.220 2.201 -1.459 0.692 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.085, 3.997]
[DEBUG] Output sample values: -0.014 2.842 3.337 3.348 1.295 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.085, 3.997] Var:0.372
[LOSS] Calculated loss: 6.302
[LOSS] Gradient sum: 1.791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.010, bias: 0.224
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.052, range=[-0.111, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 11 tokens, target: 12 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.926, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.926
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=10.475280
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=81.205734
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: -0.504 -1.371 -1.773 -1.258 -0.993 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.864, range=[-0.106, 0.882]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.864
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=9.773177
[DECODER] After pos encoding: 1536/1536 non-zero, sum=86.969666
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: 0.511 -2.224 3.553 -1.327 -0.891 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.232, 4.055]
[DEBUG] Output sample values: 0.837 2.704 3.635 3.492 1.465 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.232, 4.055] Var:0.374
[LOSS] Calculated loss: 6.575
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 12 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.016, range=[-0.074, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.767, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.767
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=19.990164
[ENCODER] After pos encoding: 768/768 non-zero, sum=58.480438
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.538 -0.539 -2.245 -1.345 -1.371 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.338, range=[-0.106, 0.883]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=2.338
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=26.456486
[DECODER] After pos encoding: 896/896 non-zero, sum=71.382843
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.519 -0.197 2.269 -1.819 -1.070 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.603, 3.998]
[DEBUG] Output sample values: 0.197 2.887 3.168 3.584 1.846 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.603, 3.998] Var:0.367
[LOSS] Calculated loss: 6.509
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.069, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.620, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.620
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-18.329863
[ENCODER] After pos encoding: 896/896 non-zero, sum=26.596470
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.611 -0.843 -1.860 -1.328 -1.275 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.273, range=[-0.106, 0.884]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.273
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.094134
[DECODER] After pos encoding: 896/896 non-zero, sum=41.832165
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.121 -0.916 3.329 -1.587 -1.532 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.546, 4.002]
[DEBUG] Output sample values: 0.301 3.084 3.252 3.747 1.131 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.546, 4.002] Var:0.381
[LOSS] Calculated loss: 6.765
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.067, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 6 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=5.102, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=5.102
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=57.720802
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=115.537254
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.673 -1.358 -2.193 -1.240 -0.856 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.094, range=[-0.106, 0.885]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-1.094
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.377468
[DECODER] After pos encoding: 768/768 non-zero, sum=26.112799
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.736 -2.076 3.025 -0.682 -0.572 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.525, 3.799]
[DEBUG] Output sample values: 1.021 3.246 3.125 3.027 1.348 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.525, 3.799] Var:0.385
[LOSS] Calculated loss: 6.033
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.087, range=[-0.148, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.261, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.261
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-2.947820
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=48.420589
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.309 -1.113 -1.995 -1.063 -1.358 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.574, range=[-0.106, 0.887]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.574
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=51.751217
[DECODER] After pos encoding: 896/896 non-zero, sum=96.677498
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.224 -1.150 3.871 -1.020 -1.309 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.120, 3.838]
[DEBUG] Output sample values: 0.145 3.038 3.095 3.254 1.855 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.120, 3.838] Var:0.374
[LOSS] Calculated loss: 6.656
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.067, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 12 tokens, target: 9 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.313, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=2.313
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=26.165476
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=103.361839
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000013
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: -0.528 -1.112 -2.187 -1.025 -1.080 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.472, range=[-0.106, 0.888]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.472
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=16.659266
[DECODER] After pos encoding: 1152/1152 non-zero, sum=74.475685
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.122 -1.677 3.366 -0.707 -0.862 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.603, 4.395]
[DEBUG] Output sample values: 0.514 3.304 3.923 3.167 1.679 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.603, 4.395] Var:0.376
[LOSS] Calculated loss: 6.870
[LOSS] Gradient sum: 1.793
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.122, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.122
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12.697701
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=70.514168
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.681 -1.370 -2.438 -1.257 -0.951 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.095, range=[-0.106, 0.889]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.095
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=35.012005
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.380447
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.472 -2.484 1.406 -1.395 -0.373 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.165, 4.046]
[DEBUG] Output sample values: 0.187 3.138 3.461 3.898 1.810 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.165, 4.046] Var:0.375
[LOSS] Calculated loss: 6.691
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.051, range=[-0.111, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 6 tokens, target: 8 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.974, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.974
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=22.335400
[ENCODER] After pos encoding: 768/768 non-zero, sum=60.825691
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.520 -1.807 -1.840 -1.328 -0.974 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.503, range=[-0.106, 0.890]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.503
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=39.633797
[DECODER] After pos encoding: 1024/1024 non-zero, sum=91.002281
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: 0.278 -3.222 2.684 -1.192 -0.708 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.282, 4.180]
[DEBUG] Output sample values: 0.564 2.548 3.106 3.976 1.419 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.282, 4.180] Var:0.377
[LOSS] Calculated loss: 6.796
[LOSS] Gradient sum: 1.792
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.112
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1023/1024 non-zero, sum=-0.053, range=[-0.111, 0.003]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.418, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-1.418
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-16.037575
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=41.778893
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.318 -1.773 -2.052 -1.127 -1.322 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.848, range=[-0.106, 0.891]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-0.848
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-9.597302
[DECODER] After pos encoding: 1152/1152 non-zero, sum=48.219128
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.657 -2.758 2.817 -0.930 -1.419 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.057, 3.791]
[DEBUG] Output sample values: 1.091 2.759 3.556 3.556 1.670 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.057, 3.791] Var:0.377
[LOSS] Calculated loss: 6.358
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.009, bias: 0.191
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 4 tokens, target: 5 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.997, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-0.997
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-11.283584
[ENCODER] After pos encoding: 512/512 non-zero, sum=14.352555
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.220 -0.804 -1.899 -1.148 -1.150 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.065, range=[-0.106, 0.892]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.065
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=12.052141
[DECODER] After pos encoding: 640/640 non-zero, sum=44.112309
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.473 -0.687 2.611 -1.184 -1.134 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.530, 3.754]
[DEBUG] Output sample values: 0.580 2.972 3.299 3.328 1.560 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.530, 3.754] Var:0.376
[LOSS] Calculated loss: 6.007
[LOSS] Gradient sum: 1.789
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.009, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.116, range=[-0.178, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.885, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=0.885
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.011981
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.072182
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.230 -1.603 -1.576 -1.279 -1.207 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.885, range=[-0.106, 0.894]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.885
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=10.007018
[DECODER] After pos encoding: 768/768 non-zero, sum=48.497231
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 0.693 -3.152 2.978 -1.001 -0.982 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.262, 4.166]
[DEBUG] Output sample values: 1.060 2.699 3.368 4.062 1.382 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.262, 4.166] Var:0.380
[LOSS] Calculated loss: 5.763
[LOSS] Gradient sum: 1.786
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.015, bias: 0.292
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.087, range=[-0.148, 0.004]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.331, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.331
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=15.055869
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=66.424286
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.455 -0.701 -1.816 -1.298 -1.437 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.229, range=[-0.106, 0.896]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-0.229
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-2.589049
[DECODER] After pos encoding: 1280/1280 non-zero, sum=61.681423
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: 0.170 -0.754 3.088 -1.876 -1.826 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.138, 3.991]
[DEBUG] Output sample values: 0.603 3.297 3.526 3.270 1.955 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.138, 3.991] Var:0.369
[LOSS] Calculated loss: 6.601
[LOSS] Gradient sum: 1.791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 10 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.031, range=[-0.089, 0.001]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[DEBUG] Forward - source: 5 tokens, target: 7 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.104, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.104
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-1.174104
[ENCODER] After pos encoding: 640/640 non-zero, sum=30.886078
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.107 -1.175 -1.834 -1.422 -1.283 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.053, range=[-0.106, 0.897]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.053
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11.913589
[DECODER] After pos encoding: 896/896 non-zero, sum=56.839878
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.864 -1.800 2.361 -1.636 -1.401 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.168, 3.934]
[DEBUG] Output sample values: 1.010 3.209 3.176 3.319 1.631 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.168, 3.934] Var:0.369
[LOSS] Calculated loss: 6.161
[LOSS] Gradient sum: 1.790
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.128
[LINEAR] Output projection - using 5x learning rate: 0.050
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 7 tokens with lr=0.010
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.067, range=[-0.127, 0.002]
[EMBEDDING] Sample weights after update: 0.09535987 -0.03296344 0.10096312 0.08238330 -0.09767666 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
  Loss: 6.46099234
[DEBUG] Forward - source: 8 tokens, target: 1 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.225, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.225
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13.859140
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=65.227509
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.577 -1.225 -1.951 -1.521 -0.470 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1.518, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1.518
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=17.176836
[DECODER] After pos encoding: 128/128 non-zero, sum=23.576834
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.314 -1.511 0.430 -1.451 -0.668 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.335, 3.295]
[DEBUG] Output sample values: 0.166 2.707 2.855 3.295 1.847 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 265 (score: 2.0, target_len: 7) [Top scores: 265:2.0 4:1.8 100:1.8 377:1.7 362:1.6 ]
[DEBUG] Forward - source: 8 tokens, target: 2 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.225, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.225
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13.859140
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=65.227509
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.577 -1.225 -1.951 -1.521 -0.470 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.950, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.950
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=10.746708
[DECODER] After pos encoding: 256/256 non-zero, sum=23.552732
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.043 -1.873 2.453 -0.986 0.139 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.368, 3.364]
[DEBUG] Output sample values: 0.925 3.290 3.225 3.124 1.549 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 1 (score: 1.8, target_len: 7) [Top scores: 4:2.0 1:1.8 971:1.7 171:1.5 116:1.5 ]
[DEBUG] Forward - source: 8 tokens, target: 3 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.225, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.225
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13.859140
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=65.227509
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.577 -1.225 -1.951 -1.521 -0.470 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.955, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=0.955
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=10.808747
[DECODER] After pos encoding: 384/384 non-zero, sum=30.026827
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.294 -1.799 2.672 -1.377 0.691 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.339, 3.459]
[DEBUG] Output sample values: 0.434 3.411 2.950 3.135 1.504 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 116 (score: 1.9, target_len: 7) [Top scores: 116:1.9 60:1.8 9:1.7 4:1.7 971:1.6 ]
[DEBUG] Forward - source: 8 tokens, target: 4 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.225, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.225
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13.859140
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=65.227509
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.577 -1.225 -1.951 -1.521 -0.470 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.340, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1.340
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.154904
[DECODER] After pos encoding: 512/512 non-zero, sum=40.791039
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.343 -1.779 2.625 -1.444 0.731 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.364, 3.701]
[DEBUG] Output sample values: 0.422 3.378 2.890 3.152 1.562 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 8 tokens, target: 5 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.225, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=1.225
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13.859140
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=65.227509
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.577 -1.225 -1.951 -1.521 -0.470 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.011, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.011
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.752480
[DECODER] After pos encoding: 640/640 non-zero, sum=54.812687
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.298 -1.764 2.682 -1.434 0.738 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.350, 3.665]
[DEBUG] Output sample values: 0.429 3.360 2.904 3.130 1.546 
[DEBUG] Forward completed!
  Test: <sos> leer <unk> hoy el camisa

¡Entrenamiento completado!

=== Pruebas de Traducción ===
[DEBUG] Forward - source: 3 tokens, target: 1 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.141, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-0.141
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-1.599958
[ENCODER] After pos encoding: 384/384 non-zero, sum=17.618109
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: -0.279 -0.855 -1.793 -1.437 -0.882 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1.518, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1.518
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=17.176836
[DECODER] After pos encoding: 128/128 non-zero, sum=23.576834
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.103 -1.177 0.577 -1.411 -0.923 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.297, 3.505]
[DEBUG] Output sample values: 0.138 2.786 3.092 3.505 1.667 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 265 (score: 1.9, target_len: 2) [Top scores: 265:1.9 362:1.8 100:1.8 377:1.7 163:1.7 ]
[DEBUG] Forward - source: 3 tokens, target: 2 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.141, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-0.141
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-1.599958
[ENCODER] After pos encoding: 384/384 non-zero, sum=17.618109
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: -0.279 -0.855 -1.793 -1.437 -0.882 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.950, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.950
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=10.746708
[DECODER] After pos encoding: 256/256 non-zero, sum=23.552732
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 1.001 -0.538 2.676 -1.900 -0.103 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.233, 3.915]
[DEBUG] Output sample values: 0.378 3.365 3.419 3.915 0.681 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 362 (score: 1.8, target_len: 2) [Top scores: 1:1.8 362:1.8 377:1.6 952:1.6 100:1.4 ]
ENG: <sos> hello <eos>
ESP: <sos> leer necesita <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.986, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.986
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.470894
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.531082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000017
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.539 -1.775 -1.768 -1.390 -0.812 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1.518, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1.518
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=17.176836
[DECODER] After pos encoding: 128/128 non-zero, sum=23.576834
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.292 -2.096 0.656 -1.297 -0.819 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.260, 3.408]
[DEBUG] Output sample values: 0.027 2.666 3.055 3.408 1.783 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 377 (score: 1.8, target_len: 4) [Top scores: 377:1.8 100:1.8 4:1.8 9:1.7 265:1.7 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.986, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.986
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.470894
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.531082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000017
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.539 -1.775 -1.768 -1.390 -0.812 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.502, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.502
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=28.306637
[DECODER] After pos encoding: 256/256 non-zero, sum=41.112656
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.139 -2.446 1.474 -1.353 -0.386 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-1.928, 3.580]
[DEBUG] Output sample values: 0.176 2.761 3.580 3.129 1.614 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 9 (score: 2.0, target_len: 4) [Top scores: 9:2.0 442:1.7 1:1.7 263:1.6 678:1.6 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.986, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.986
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.470894
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.531082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000017
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.539 -1.775 -1.768 -1.390 -0.812 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=3.174, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=3.174
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=35.904217
[DECODER] After pos encoding: 384/384 non-zero, sum=55.122261
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 0.117 -3.091 2.424 -1.091 -0.574 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-1.963, 3.964]
[DEBUG] Output sample values: 0.472 2.742 3.533 3.866 1.355 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 31 (score: 1.7, target_len: 4) [Top scores: 31:1.7 276:1.7 566:1.6 100:1.5 678:1.5 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.986, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.986
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.470894
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.531082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000017
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.539 -1.775 -1.768 -1.390 -0.812 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=3.102, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=3.102
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=35.100231
[DECODER] After pos encoding: 512/512 non-zero, sum=60.736328
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: 0.044 -3.081 2.389 -1.213 -0.398 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-1.956, 3.710]
[DEBUG] Output sample values: 0.331 2.788 3.447 3.710 1.373 
[DEBUG] Forward completed!
ENG: <sos> how are you <eos>
ESP: <sos> camino el para un <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.733, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.733
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-19.608101
[ENCODER] After pos encoding: 512/512 non-zero, sum=6.028023
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.215 -0.993 -2.224 -1.500 -0.944 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1.518, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1.518
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=17.176836
[DECODER] After pos encoding: 128/128 non-zero, sum=23.576834
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.038 -1.377 0.217 -1.485 -1.033 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.380, 3.345]
[DEBUG] Output sample values: 0.060 2.723 3.037 3.345 1.894 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 750 (score: 1.7, target_len: 3) [Top scores: 265:2.0 4:1.9 750:1.7 100:1.7 902:1.6 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.733, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.733
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-19.608101
[ENCODER] After pos encoding: 512/512 non-zero, sum=6.028023
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.215 -0.993 -2.224 -1.500 -0.944 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1.366, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1.366
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=15.451341
[DECODER] After pos encoding: 256/256 non-zero, sum=28.257360
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.337 -1.784 0.486 -2.041 -0.960 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.471, 3.678]
[DEBUG] Output sample values: -0.061 2.867 3.037 3.346 1.976 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 4 (score: 1.9, target_len: 3) [Top scores: 4:1.9 952:1.9 935:1.8 791:1.8 1:1.7 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.733, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.733
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-19.608101
[ENCODER] After pos encoding: 512/512 non-zero, sum=6.028023
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.215 -0.993 -2.224 -1.500 -0.944 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1.689, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1.689
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=19.103552
[DECODER] After pos encoding: 384/384 non-zero, sum=38.321606
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 0.622 -1.448 1.131 -2.057 -1.000 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.313, 4.217]
[DEBUG] Output sample values: -0.036 2.831 3.242 3.234 1.869 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 171 (score: 2.0, target_len: 3) [Top scores: 171:2.0 468:1.8 9:1.7 452:1.5 962:1.5 ]
ENG: <sos> good morning <eos>
ESP: <sos> partido a coche <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.407, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.407
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.914655
[ENCODER] After pos encoding: 512/512 non-zero, sum=41.550808
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.463 -1.423 -1.943 -1.315 -0.853 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1.518, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1.518
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=17.176836
[DECODER] After pos encoding: 128/128 non-zero, sum=23.576834
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.247 -1.752 0.460 -1.306 -0.911 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.321, 3.289]
[DEBUG] Output sample values: -0.114 2.788 2.895 3.289 1.842 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 4 (score: 1.8, target_len: 3) [Top scores: 265:1.9 4:1.8 100:1.8 377:1.7 163:1.6 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.407, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.407
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.914655
[ENCODER] After pos encoding: 512/512 non-zero, sum=41.550808
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.463 -1.423 -1.943 -1.315 -0.853 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1.841, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1.841
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=20.829046
[DECODER] After pos encoding: 256/256 non-zero, sum=33.635052
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 1.090 -2.662 2.634 -0.587 -1.136 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.162, 3.487]
[DEBUG] Output sample values: 0.276 3.390 3.339 3.009 1.563 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 9 (score: 1.9, target_len: 3) [Top scores: 9:1.9 668:1.6 902:1.5 932:1.4 750:1.4 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.407, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=1.407
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.914655
[ENCODER] After pos encoding: 512/512 non-zero, sum=41.550808
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -0.463 -1.423 -1.943 -1.315 -0.853 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=2.513, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=2.513
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=28.426620
[DECODER] After pos encoding: 384/384 non-zero, sum=47.644661
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 0.779 -2.660 2.455 -0.913 -0.806 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.185, 3.371]
[DEBUG] Output sample values: 0.039 3.353 3.158 2.959 1.580 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 31 (score: 2.0, target_len: 3) [Top scores: 31:2.0 637:1.9 1:1.7 971:1.6 846:1.5 ]
ENG: <sos> thank you <eos>
ESP: <sos> a el para <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.219, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.219
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-2.478531
[ENCODER] After pos encoding: 640/640 non-zero, sum=29.581657
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.695 -1.337 -1.988 -1.284 -0.733 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1.518, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1.518
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=17.176836
[DECODER] After pos encoding: 128/128 non-zero, sum=23.576834
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.404 -1.629 0.387 -1.208 -0.822 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.375, 3.353]
[DEBUG] Output sample values: -0.035 2.837 2.988 3.353 1.856 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 265 (score: 2.0, target_len: 4) [Top scores: 265:2.0 4:1.9 100:1.7 362:1.7 377:1.7 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.219, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.219
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-2.478531
[ENCODER] After pos encoding: 640/640 non-zero, sum=29.581657
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.695 -1.337 -1.988 -1.284 -0.733 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.950, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.950
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=10.746708
[DECODER] After pos encoding: 256/256 non-zero, sum=23.552732
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.072 -1.894 2.090 -0.600 -0.423 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.432, 3.665]
[DEBUG] Output sample values: 0.661 3.455 3.479 3.290 1.709 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 4 (score: 2.1, target_len: 4) [Top scores: 1:2.1 4:2.1 971:1.8 938:1.7 15:1.6 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.219, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.219
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-2.478531
[ENCODER] After pos encoding: 640/640 non-zero, sum=29.581657
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.695 -1.337 -1.988 -1.284 -0.733 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1.273, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1.273
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=14.398916
[DECODER] After pos encoding: 384/384 non-zero, sum=33.616974
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.029 -1.915 2.219 -0.538 -0.390 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.339, 3.979]
[DEBUG] Output sample values: 0.611 3.602 3.584 3.365 1.725 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 1 (score: 2.2, target_len: 4) [Top scores: 1:2.2 562:1.8 171:1.7 10:1.6 935:1.5 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.219, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.219
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-2.478531
[ENCODER] After pos encoding: 640/640 non-zero, sum=29.581657
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -0.695 -1.337 -1.988 -1.284 -0.733 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.278, range=[-0.106, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1.278
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=14.460961
[DECODER] After pos encoding: 512/512 non-zero, sum=40.097095
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.169 -2.070 2.155 -0.846 -0.137 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.307, 3.769]
[DEBUG] Output sample values: 0.277 3.506 3.366 3.223 1.725 
[DEBUG] Forward completed!
ENG: <sos> i love you <eos>
ESP: <sos> leer a <unk> vac <eos>
---