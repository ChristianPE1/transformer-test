Se han truncado las últimas 5000 líneas del flujo de salida.
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[UPDATE] Gradientes aplicados con lr=0.00065610 [Updated]
    Muestra 16/16: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.485, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.485
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=39.424728
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=97.241173
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.691 -0.492 -0.389 1.323 -0.906 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.045, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=2.045
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=23.140249
[DECODER] After pos encoding: 896/896 non-zero, sum=68.066566
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.731 -0.536 -0.069 1.213 -0.789 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.138, 2.156]
[DEBUG] Output sample values: -1.016 0.780 0.402 -0.398 -0.293 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.138, 2.156] Var:0.376
[LOSS] Calculated loss: 7.685
 [EOS penalty: 0.000] Loss: 7.685 (LR: 0.0007)[LOSS] Gradient sum: 1.7988
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0115, bias: 0.2562
[LINEAR] Output projection - using 5x learning rate: 0.0033
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0007
[ATTENTION] Weights updated with lr=0.0007
[FEEDFORWARD] Weights updated with lr=0.0007
[ATTENTION] Weights updated with lr=0.0007
[ATTENTION] Weights updated with lr=0.0007
[FEEDFORWARD] Weights updated with lr=0.0007
[ATTENTION] Weights updated with lr=0.0007
[FEEDFORWARD] Weights updated with lr=0.0007
[ATTENTION] Weights updated with lr=0.0007
[FEEDFORWARD] Weights updated with lr=0.0007
[EMBEDDING] Updating weights for 7 tokens with lr=0.0007
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0701, range=[-0.1285, 0.0004]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[UPDATE] Gradientes aplicados con lr=0.00065610 [Updated]
  Promedio de loss: 7.698

Época 32/50 [LR: 0.001]
[DEBUG] Forward - source: 7 tokens, target: 6 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.430, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=0.430
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.862417
[ENCODER] After pos encoding: 896/896 non-zero, sum=49.788780
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.832 -0.200 -0.571 1.175 -0.701 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.236, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.236
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-2.665118
[DECODER] After pos encoding: 768/768 non-zero, sum=35.825134
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.748 -0.095 -0.290 1.130 -0.457 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.294, 2.354]
[DEBUG] Output sample values: -0.925 0.297 0.617 0.355 -0.254 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.294, 2.354] Var:0.354
[LOSS] Calculated loss: 7.629
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.091, range=[-0.150, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.108, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.108
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.532437
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.835953
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.459 -0.160 -0.755 1.478 -0.732 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.697, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.697
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=7.885087
[DECODER] After pos encoding: 768/768 non-zero, sum=46.375328
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.275 -0.113 -0.539 1.451 -0.516 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.382, 1.996]
[DEBUG] Output sample values: -0.956 0.570 0.702 -0.349 -0.694 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.382, 1.996] Var:0.362
[LOSS] Calculated loss: 7.551
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.092, range=[-0.150, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=0.145
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=1.635700
[ENCODER] After pos encoding: 896/896 non-zero, sum=46.562042
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.601 -0.481 -0.746 1.736 -0.799 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.478, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.478
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.039682
[DECODER] After pos encoding: 1152/1152 non-zero, sum=85.856102
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.413 -0.567 -0.528 1.789 -0.662 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.387, 2.326]
[DEBUG] Output sample values: -0.873 0.373 0.510 -0.536 -0.481 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.387, 2.326] Var:0.356
[LOSS] Calculated loss: 8.086
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 12 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.244, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.244
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.763582
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.580059
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000021
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.714 -0.157 -0.656 1.590 -1.246 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.083, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=2.083
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.564690
[DECODER] After pos encoding: 1536/1536 non-zero, sum=100.761070
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -0.748 -0.193 -0.453 1.729 -1.346 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.220, 2.285]
[DEBUG] Output sample values: -0.704 0.434 0.550 -0.179 -0.102 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.220, 2.285] Var:0.349
[LOSS] Calculated loss: 7.357
[LOSS] Gradient sum: 1.798
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.006, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 12 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 14 tokens, target: 12 tokens
[ENCODER] Starting encode with 14 tokens
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=-1.791, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1792/1792 non-zero, sum=-1.791
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[ENCODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=-20.257500
[ENCODER] After pos encoding: 1792/1792 non-zero, sum=69.888725
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1792/1792 non-zero
[ENCODER_LAYER] After self-attention: 1792/1792 non-zero
[ENCODER_LAYER] After norm1: 1792/1792 non-zero
[ENCODER_LAYER] After feedforward: 1792/1792 non-zero
[ENCODER_LAYER] Final output: 1792/1792 non-zero
[ENCODER] Layer 0 output: 1792/1792 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1792/1792 non-zero
[ENCODER_LAYER] After self-attention: 1792/1792 non-zero
[ENCODER_LAYER] After norm1: 1792/1792 non-zero
[ENCODER_LAYER] After feedforward: 1792/1792 non-zero
[ENCODER_LAYER] Final output: 1792/1792 non-zero
[ENCODER] Layer 1 output: 1792/1792 non-zero, sum=-0.000014
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 14x128
[DEBUG] Encoder sample values: -1.184 -0.221 -1.025 1.290 -0.962 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.052, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.052
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=0.592632
[DECODER] After pos encoding: 1536/1536 non-zero, sum=77.789001
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.242 -0.111 -0.937 1.204 -0.882 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.275, 2.475]
[DEBUG] Output sample values: -0.741 0.430 0.531 -0.122 0.249 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.275, 2.475] Var:0.370
[LOSS] Calculated loss: 7.635
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.075
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 12 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.411, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.411
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=15.966298
[ENCODER] After pos encoding: 768/768 non-zero, sum=54.456566
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.491 0.054 -0.594 1.287 -0.609 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.582, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.582
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.902266
[DECODER] After pos encoding: 640/640 non-zero, sum=49.962479
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.286 0.133 -0.296 1.238 -0.315 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.009, 2.305]
[DEBUG] Output sample values: -0.737 0.400 0.443 0.184 -0.199 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.009, 2.305] Var:0.352
[LOSS] Calculated loss: 7.433
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.017, bias: 0.359
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.122, range=[-0.180, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.909, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=1.909
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.599136
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=92.329445
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: -0.957 -0.424 -0.722 1.424 -0.443 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.152
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=1.716175
[DECODER] After pos encoding: 1280/1280 non-zero, sum=65.986603
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -1.012 -0.354 -0.458 1.344 -0.040 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.248, 2.504]
[DEBUG] Output sample values: -0.835 0.625 0.519 -0.164 -0.326 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.248, 2.504] Var:0.356
[LOSS] Calculated loss: 7.909
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.158, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-2.158
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-24.410313
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=26.958076
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.510 -0.212 -0.980 1.629 -0.648 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.804, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.804
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=20.413334
[DECODER] After pos encoding: 1280/1280 non-zero, sum=84.683762
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.462 0.048 -0.795 1.718 -0.434 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.508, 2.640]
[DEBUG] Output sample values: -0.598 0.175 0.572 0.032 -0.414 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.508, 2.640] Var:0.356
[LOSS] Calculated loss: 7.633
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.807, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.807
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.439247
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.487083
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.612 -0.011 -0.590 1.127 -1.366 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.339, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.339
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-15.153368
[DECODER] After pos encoding: 1152/1152 non-zero, sum=42.662998
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000018
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.521 0.073 -0.353 1.063 -1.369 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.246, 2.247]
[DEBUG] Output sample values: -0.617 0.119 0.405 -0.221 0.101 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.246, 2.247] Var:0.349
[LOSS] Calculated loss: 7.861
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 11 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.126, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=0.126
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=1.422940
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=52.791340
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.943 0.340 -0.540 1.454 -1.184 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.398, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.398
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=4.498436
[DECODER] After pos encoding: 1408/1408 non-zero, sum=75.228859
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.034 0.452 -0.219 1.398 -1.204 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.240, 2.688]
[DEBUG] Output sample values: -0.583 0.864 0.400 -0.627 -0.264 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.240, 2.688] Var:0.359
[LOSS] Calculated loss: 7.776
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.082
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 8 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.228, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.228
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=13.892781
[ENCODER] After pos encoding: 896/896 non-zero, sum=58.819092
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.873 -0.358 -0.760 1.431 -1.224 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.627, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.627
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=18.402420
[DECODER] After pos encoding: 1024/1024 non-zero, sum=69.770782
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.960 -0.308 -0.526 1.301 -1.193 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.039, 2.168]
[DEBUG] Output sample values: -0.472 1.091 0.316 -0.536 -0.353 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.039, 2.168] Var:0.351
[LOSS] Calculated loss: 7.360
[LOSS] Gradient sum: 1.798
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.015, bias: 0.449
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 9 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.778, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.778
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-8.799493
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=42.568935
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.813 -0.137 -0.477 1.286 -0.551 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.029, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.029
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11.640886
[DECODER] After pos encoding: 1152/1152 non-zero, sum=69.457336
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.671 -0.146 -0.311 1.187 -0.481 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.078, 2.382]
[DEBUG] Output sample values: -0.844 0.425 0.441 -0.509 -0.061 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.078, 2.382] Var:0.365
[LOSS] Calculated loss: 8.045
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 10 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.907, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.907
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-10.256135
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=47.560295
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.046 -0.163 -0.491 1.714 -1.268 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.629, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-0.629
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-7.115640
[DECODER] After pos encoding: 1280/1280 non-zero, sum=57.154831
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -1.164 -0.051 -0.232 1.774 -1.154 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.354, 2.336]
[DEBUG] Output sample values: -1.134 -0.017 0.698 0.166 -0.288 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.354, 2.336] Var:0.363
[LOSS] Calculated loss: 7.688
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 13 tokens, target: 10 tokens
[ENCODER] Starting encode with 13 tokens
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=1.924, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1664/1664 non-zero, sum=1.924
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=21.766949
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=105.435219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 13x128
[DEBUG] Encoder sample values: -0.680 -0.542 -1.369 1.606 -0.972 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.238, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.238
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=14.003726
[DECODER] After pos encoding: 1280/1280 non-zero, sum=78.274162
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.573 -0.677 -1.416 1.570 -0.799 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.252, 2.553]
[DEBUG] Output sample values: -1.213 0.305 0.978 0.067 -0.225 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.252, 2.553] Var:0.355
[LOSS] Calculated loss: 7.774
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.392, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=-1.392
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-15.750283
[ENCODER] After pos encoding: 768/768 non-zero, sum=22.739971
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.775 -0.482 -0.758 1.280 -0.831 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.789, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1.789
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=20.242117
[DECODER] After pos encoding: 768/768 non-zero, sum=58.732422
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.683 -0.421 -0.636 1.259 -0.678 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.159, 2.470]
[DEBUG] Output sample values: -1.157 0.342 0.611 0.212 -0.481 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.159, 2.470] Var:0.355
[LOSS] Calculated loss: 7.704
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.091, range=[-0.150, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.485, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.485
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=39.424728
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=97.241173
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.691 -0.492 -0.389 1.323 -0.906 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.046, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=2.046
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=23.149475
[DECODER] After pos encoding: 896/896 non-zero, sum=68.075806
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.731 -0.537 -0.064 1.213 -0.789 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.138, 2.156]
[DEBUG] Output sample values: -1.016 0.787 0.407 -0.393 -0.293 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.138, 2.156] Var:0.376
[LOSS] Calculated loss: 7.681
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.012, bias: 0.256
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.070, range=[-0.128, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610

Época 33/50 [LR: 0.00065610]
[DEBUG] Forward - source: 7 tokens, target: 6 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.430, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=0.430
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.862417
[ENCODER] After pos encoding: 896/896 non-zero, sum=49.788780
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.832 -0.200 -0.571 1.175 -0.701 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.235, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.235
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-2.654056
[DECODER] After pos encoding: 768/768 non-zero, sum=35.836197
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.748 -0.095 -0.285 1.130 -0.457 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.294, 2.354]
[DEBUG] Output sample values: -0.925 0.304 0.623 0.360 -0.253 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.294, 2.354] Var:0.354
[LOSS] Calculated loss: 7.627
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.091, range=[-0.150, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.108, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.108
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.532437
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.835953
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.459 -0.160 -0.755 1.478 -0.732 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.698, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.698
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=7.895196
[DECODER] After pos encoding: 768/768 non-zero, sum=46.385426
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.275 -0.113 -0.534 1.451 -0.516 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.382, 1.996]
[DEBUG] Output sample values: -0.956 0.577 0.708 -0.344 -0.693 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.382, 1.996] Var:0.362
[LOSS] Calculated loss: 7.548
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.092, range=[-0.150, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=0.145
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=1.635700
[ENCODER] After pos encoding: 896/896 non-zero, sum=46.562042
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.601 -0.481 -0.746 1.736 -0.799 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.479, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.479
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.049469
[DECODER] After pos encoding: 1152/1152 non-zero, sum=85.865891
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.413 -0.567 -0.523 1.789 -0.662 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.388, 2.326]
[DEBUG] Output sample values: -0.873 0.380 0.516 -0.530 -0.480 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.388, 2.326] Var:0.356
[LOSS] Calculated loss: 8.084
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 12 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.244, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.244
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.763582
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.580059
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.714 -0.157 -0.656 1.590 -1.246 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.084, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=2.084
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.574419
[DECODER] After pos encoding: 1536/1536 non-zero, sum=100.770874
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -0.749 -0.194 -0.447 1.729 -1.346 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.220, 2.285]
[DEBUG] Output sample values: -0.703 0.440 0.556 -0.174 -0.101 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.220, 2.285] Var:0.349
[LOSS] Calculated loss: 7.356
[LOSS] Gradient sum: 1.798
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 12 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 14 tokens, target: 12 tokens
[ENCODER] Starting encode with 14 tokens
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=-1.791, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1792/1792 non-zero, sum=-1.791
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[ENCODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=-20.257500
[ENCODER] After pos encoding: 1792/1792 non-zero, sum=69.888725
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1792/1792 non-zero
[ENCODER_LAYER] After self-attention: 1792/1792 non-zero
[ENCODER_LAYER] After norm1: 1792/1792 non-zero
[ENCODER_LAYER] After feedforward: 1792/1792 non-zero
[ENCODER_LAYER] Final output: 1792/1792 non-zero
[ENCODER] Layer 0 output: 1792/1792 non-zero, sum=0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1792/1792 non-zero
[ENCODER_LAYER] After self-attention: 1792/1792 non-zero
[ENCODER_LAYER] After norm1: 1792/1792 non-zero
[ENCODER_LAYER] After feedforward: 1792/1792 non-zero
[ENCODER_LAYER] Final output: 1792/1792 non-zero
[ENCODER] Layer 1 output: 1792/1792 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 14x128
[DEBUG] Encoder sample values: -1.184 -0.221 -1.025 1.290 -0.962 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.053, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.053
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=0.602472
[DECODER] After pos encoding: 1536/1536 non-zero, sum=77.798882
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.243 -0.112 -0.932 1.204 -0.882 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.275, 2.475]
[DEBUG] Output sample values: -0.740 0.437 0.536 -0.117 0.250 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.275, 2.475] Var:0.370
[LOSS] Calculated loss: 7.634
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.075
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 12 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.411, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.411
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=15.966298
[ENCODER] After pos encoding: 768/768 non-zero, sum=54.456566
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.491 0.054 -0.594 1.287 -0.609 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.583, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.583
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.911573
[DECODER] After pos encoding: 640/640 non-zero, sum=49.971771
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.286 0.133 -0.291 1.238 -0.314 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.009, 2.305]
[DEBUG] Output sample values: -0.737 0.407 0.449 0.190 -0.199 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.009, 2.305] Var:0.352
[LOSS] Calculated loss: 7.429
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.017, bias: 0.359
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.122, range=[-0.180, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.909, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=1.909
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.599136
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=92.329445
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: -0.957 -0.424 -0.722 1.424 -0.443 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.152
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=1.725307
[DECODER] After pos encoding: 1280/1280 non-zero, sum=65.995705
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -1.012 -0.354 -0.453 1.344 -0.040 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.248, 2.504]
[DEBUG] Output sample values: -0.835 0.631 0.524 -0.159 -0.325 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.248, 2.504] Var:0.356
[LOSS] Calculated loss: 7.906
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.158, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-2.158
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-24.410313
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=26.958076
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.510 -0.212 -0.980 1.629 -0.648 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.805, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.805
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=20.424109
[DECODER] After pos encoding: 1280/1280 non-zero, sum=84.694504
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.462 0.048 -0.789 1.718 -0.434 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.508, 2.640]
[DEBUG] Output sample values: -0.598 0.181 0.577 0.037 -0.414 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.508, 2.640] Var:0.356
[LOSS] Calculated loss: 7.632
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.807, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.807
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.439247
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.487083
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.612 -0.011 -0.590 1.127 -1.366 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.339, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.339
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-15.143469
[DECODER] After pos encoding: 1152/1152 non-zero, sum=42.672989
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.521 0.073 -0.348 1.063 -1.370 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.246, 2.247]
[DEBUG] Output sample values: -0.617 0.125 0.411 -0.215 0.102 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.246, 2.247] Var:0.349
[LOSS] Calculated loss: 7.859
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 11 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.126, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=0.126
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=1.422940
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=52.791340
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.943 0.340 -0.540 1.454 -1.184 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.399, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.399
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=4.509305
[DECODER] After pos encoding: 1408/1408 non-zero, sum=75.239746
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.035 0.451 -0.213 1.398 -1.204 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.240, 2.688]
[DEBUG] Output sample values: -0.583 0.871 0.405 -0.622 -0.264 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.240, 2.688] Var:0.359
[LOSS] Calculated loss: 7.775
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.082
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 8 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.228, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.228
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=13.892781
[ENCODER] After pos encoding: 896/896 non-zero, sum=58.819092
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.873 -0.358 -0.760 1.431 -1.224 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.627, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.627
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=18.409798
[DECODER] After pos encoding: 1024/1024 non-zero, sum=69.778259
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.961 -0.309 -0.521 1.301 -1.193 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.039, 2.168]
[DEBUG] Output sample values: -0.471 1.098 0.321 -0.530 -0.353 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.039, 2.168] Var:0.351
[LOSS] Calculated loss: 7.355
[LOSS] Gradient sum: 1.798
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.015, bias: 0.449
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 9 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.778, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.778
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-8.799493
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=42.568935
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.813 -0.137 -0.477 1.286 -0.551 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.030, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.030
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11.651780
[DECODER] After pos encoding: 1152/1152 non-zero, sum=69.468224
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.671 -0.147 -0.306 1.186 -0.481 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.078, 2.382]
[DEBUG] Output sample values: -0.844 0.432 0.446 -0.503 -0.061 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.078, 2.382] Var:0.365
[LOSS] Calculated loss: 8.043
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 10 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.907, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.907
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-10.256135
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=47.560295
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.046 -0.163 -0.491 1.714 -1.268 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.628, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-0.628
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-7.105790
[DECODER] After pos encoding: 1280/1280 non-zero, sum=57.164639
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -1.165 -0.052 -0.227 1.774 -1.154 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.354, 2.335]
[DEBUG] Output sample values: -1.134 -0.010 0.704 0.173 -0.288 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.354, 2.335] Var:0.363
[LOSS] Calculated loss: 7.686
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 13 tokens, target: 10 tokens
[ENCODER] Starting encode with 13 tokens
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=1.924, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1664/1664 non-zero, sum=1.924
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=21.766949
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=105.435219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000021
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 13x128
[DEBUG] Encoder sample values: -0.680 -0.542 -1.369 1.606 -0.972 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.239, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.239
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=14.014667
[DECODER] After pos encoding: 1280/1280 non-zero, sum=78.285118
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.574 -0.677 -1.411 1.570 -0.799 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.252, 2.553]
[DEBUG] Output sample values: -1.213 0.312 0.983 0.073 -0.224 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.252, 2.553] Var:0.355
[LOSS] Calculated loss: 7.773
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.392, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=-1.392
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-15.750283
[ENCODER] After pos encoding: 768/768 non-zero, sum=22.739971
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.775 -0.482 -0.758 1.280 -0.831 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.790, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1.790
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=20.252352
[DECODER] After pos encoding: 768/768 non-zero, sum=58.742577
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.684 -0.421 -0.631 1.259 -0.678 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.159, 2.470]
[DEBUG] Output sample values: -1.157 0.348 0.618 0.218 -0.481 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.159, 2.470] Var:0.355
[LOSS] Calculated loss: 7.701
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.091, range=[-0.150, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.485, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.485
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=39.424728
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=97.241173
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.691 -0.492 -0.389 1.323 -0.906 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.047, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=2.047
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=23.158674
[DECODER] After pos encoding: 896/896 non-zero, sum=68.084953
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.732 -0.537 -0.059 1.213 -0.789 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.138, 2.156]
[DEBUG] Output sample values: -1.016 0.795 0.414 -0.387 -0.292 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.138, 2.156] Var:0.376
[LOSS] Calculated loss: 7.677
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.012, bias: 0.256
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.070, range=[-0.128, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610

Época 34/50 [LR: 0.00065610]
[DEBUG] Forward - source: 7 tokens, target: 6 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.430, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=0.430
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.862417
[ENCODER] After pos encoding: 896/896 non-zero, sum=49.788780
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.832 -0.200 -0.571 1.175 -0.701 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.234, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.234
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-2.643004
[DECODER] After pos encoding: 768/768 non-zero, sum=35.847294
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.748 -0.096 -0.280 1.129 -0.457 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.294, 2.354]
[DEBUG] Output sample values: -0.925 0.312 0.630 0.367 -0.252 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.294, 2.354] Var:0.354
[LOSS] Calculated loss: 7.624
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.091, range=[-0.150, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.108, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.108
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.532437
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.835953
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.459 -0.160 -0.755 1.478 -0.732 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.699, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.699
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=7.905299
[DECODER] After pos encoding: 768/768 non-zero, sum=46.395561
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.275 -0.113 -0.529 1.451 -0.516 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.381, 1.996]
[DEBUG] Output sample values: -0.956 0.585 0.714 -0.337 -0.692 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.381, 1.996] Var:0.362
[LOSS] Calculated loss: 7.544
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.092, range=[-0.150, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=0.145
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=1.635700
[ENCODER] After pos encoding: 896/896 non-zero, sum=46.562042
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.601 -0.481 -0.746 1.736 -0.799 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.480, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.480
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.059229
[DECODER] After pos encoding: 1152/1152 non-zero, sum=85.875610
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.413 -0.567 -0.517 1.790 -0.662 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.388, 2.326]
[DEBUG] Output sample values: -0.873 0.387 0.523 -0.524 -0.479 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.388, 2.326] Var:0.356
[LOSS] Calculated loss: 8.081
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 12 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.244, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.244
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.763582
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.580059
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.714 -0.157 -0.656 1.590 -1.246 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.085, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=2.085
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.584164
[DECODER] After pos encoding: 1536/1536 non-zero, sum=100.780647
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -0.749 -0.194 -0.441 1.729 -1.346 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.220, 2.284]
[DEBUG] Output sample values: -0.703 0.448 0.563 -0.167 -0.101 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.220, 2.284] Var:0.349
[LOSS] Calculated loss: 7.354
[LOSS] Gradient sum: 1.798
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 12 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 14 tokens, target: 12 tokens
[ENCODER] Starting encode with 14 tokens
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=-1.791, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1792/1792 non-zero, sum=-1.791
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[ENCODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=-20.257500
[ENCODER] After pos encoding: 1792/1792 non-zero, sum=69.888725
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1792/1792 non-zero
[ENCODER_LAYER] After self-attention: 1792/1792 non-zero
[ENCODER_LAYER] After norm1: 1792/1792 non-zero
[ENCODER_LAYER] After feedforward: 1792/1792 non-zero
[ENCODER_LAYER] Final output: 1792/1792 non-zero
[ENCODER] Layer 0 output: 1792/1792 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1792/1792 non-zero
[ENCODER_LAYER] After self-attention: 1792/1792 non-zero
[ENCODER_LAYER] After norm1: 1792/1792 non-zero
[ENCODER_LAYER] After feedforward: 1792/1792 non-zero
[ENCODER_LAYER] Final output: 1792/1792 non-zero
[ENCODER] Layer 1 output: 1792/1792 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 14x128
[DEBUG] Encoder sample values: -1.184 -0.221 -1.025 1.290 -0.962 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.054, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.054
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=0.612318
[DECODER] After pos encoding: 1536/1536 non-zero, sum=77.808739
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.243 -0.112 -0.926 1.204 -0.882 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.275, 2.475]
[DEBUG] Output sample values: -0.740 0.445 0.543 -0.111 0.251 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.275, 2.475] Var:0.370
[LOSS] Calculated loss: 7.632
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.075
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 12 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.411, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.411
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=15.966298
[ENCODER] After pos encoding: 768/768 non-zero, sum=54.456566
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.491 0.054 -0.594 1.287 -0.609 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.584, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.584
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.920885
[DECODER] After pos encoding: 640/640 non-zero, sum=49.981056
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.286 0.133 -0.286 1.238 -0.314 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.009, 2.305]
[DEBUG] Output sample values: -0.737 0.415 0.456 0.197 -0.198 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.009, 2.305] Var:0.352
[LOSS] Calculated loss: 7.423
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.017, bias: 0.359
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.122, range=[-0.180, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.909, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=1.909
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.599136
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=92.329445
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: -0.957 -0.424 -0.722 1.424 -0.443 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.153, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.153
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=1.734462
[DECODER] After pos encoding: 1280/1280 non-zero, sum=66.004921
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -1.013 -0.354 -0.448 1.344 -0.039 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.248, 2.504]
[DEBUG] Output sample values: -0.835 0.639 0.531 -0.152 -0.324 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.248, 2.504] Var:0.356
[LOSS] Calculated loss: 7.904
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.158, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-2.158
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-24.410313
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=26.958076
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000012
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.510 -0.212 -0.980 1.629 -0.648 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.806, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.806
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=20.434877
[DECODER] After pos encoding: 1280/1280 non-zero, sum=84.705299
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.463 0.047 -0.784 1.717 -0.434 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.508, 2.640]
[DEBUG] Output sample values: -0.598 0.189 0.585 0.043 -0.413 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.508, 2.640] Var:0.356
[LOSS] Calculated loss: 7.630
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.807, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.807
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.439247
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.487083
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.612 -0.011 -0.590 1.127 -1.366 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.338, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.338
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-15.133527
[DECODER] After pos encoding: 1152/1152 non-zero, sum=42.682915
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.521 0.072 -0.342 1.062 -1.370 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.246, 2.247]
[DEBUG] Output sample values: -0.617 0.133 0.418 -0.209 0.103 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.246, 2.247] Var:0.349
[LOSS] Calculated loss: 7.857
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 11 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.126, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=0.126
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=1.422940
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=52.791340
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.943 0.340 -0.540 1.454 -1.184 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.400, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.400
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=4.520179
[DECODER] After pos encoding: 1408/1408 non-zero, sum=75.250618
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.035 0.451 -0.207 1.398 -1.205 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.240, 2.688]
[DEBUG] Output sample values: -0.582 0.878 0.412 -0.615 -0.263 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.240, 2.688] Var:0.359
[LOSS] Calculated loss: 7.774
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.082
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 8 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.228, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.228
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=13.892781
[ENCODER] After pos encoding: 896/896 non-zero, sum=58.819092
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.873 -0.358 -0.760 1.431 -1.224 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.628, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.628
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=18.417202
[DECODER] After pos encoding: 1024/1024 non-zero, sum=69.785637
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.961 -0.309 -0.516 1.301 -1.193 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.039, 2.168]
[DEBUG] Output sample values: -0.471 1.106 0.329 -0.523 -0.352 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.039, 2.168] Var:0.351
[LOSS] Calculated loss: 7.350
[LOSS] Gradient sum: 1.798
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.017, bias: 0.449
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 9 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.778, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.778
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-8.799493
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=42.568935
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.813 -0.137 -0.477 1.286 -0.551 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.031, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.031
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11.662705
[DECODER] After pos encoding: 1152/1152 non-zero, sum=69.479164
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.671 -0.147 -0.300 1.186 -0.480 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.078, 2.382]
[DEBUG] Output sample values: -0.843 0.439 0.453 -0.497 -0.060 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.078, 2.382] Var:0.365
[LOSS] Calculated loss: 8.042
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 10 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.907, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-0.907
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-10.256135
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=47.560295
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.046 -0.163 -0.491 1.714 -1.268 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.627, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-0.627
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-7.095933
[DECODER] After pos encoding: 1280/1280 non-zero, sum=57.174549
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000012
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -1.165 -0.052 -0.222 1.774 -1.154 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.354, 2.335]
[DEBUG] Output sample values: -1.134 -0.003 0.711 0.179 -0.287 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.354, 2.335] Var:0.363
[LOSS] Calculated loss: 7.684
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 13 tokens, target: 10 tokens
[ENCODER] Starting encode with 13 tokens
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=1.924, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1664/1664 non-zero, sum=1.924
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=21.766949
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=105.435219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 13x128
[DEBUG] Encoder sample values: -0.680 -0.542 -1.369 1.606 -0.972 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.240, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.240
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=14.025600
[DECODER] After pos encoding: 1280/1280 non-zero, sum=78.296021
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.574 -0.677 -1.406 1.570 -0.799 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.252, 2.553]
[DEBUG] Output sample values: -1.212 0.319 0.990 0.079 -0.223 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.252, 2.553] Var:0.355
[LOSS] Calculated loss: 7.772
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 6 tokens, target: 6 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.392, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=-1.392
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-15.750283
[ENCODER] After pos encoding: 768/768 non-zero, sum=22.739971
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.775 -0.482 -0.758 1.280 -0.831 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.791, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1.791
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=20.262541
[DECODER] After pos encoding: 768/768 non-zero, sum=58.752811
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.684 -0.422 -0.626 1.259 -0.678 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.160, 2.470]
[DEBUG] Output sample values: -1.157 0.356 0.625 0.225 -0.480 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.160, 2.470] Var:0.355
[LOSS] Calculated loss: 7.698
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.091, range=[-0.150, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.485, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.485
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=39.424728
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=97.241173
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.691 -0.492 -0.389 1.323 -0.906 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.048, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=2.048
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=23.167826
[DECODER] After pos encoding: 896/896 non-zero, sum=68.094170
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.732 -0.538 -0.054 1.213 -0.789 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.138, 2.156]
[DEBUG] Output sample values: -1.016 0.802 0.421 -0.381 -0.292 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.138, 2.156] Var:0.376
[LOSS] Calculated loss: 7.673
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.012, bias: 0.256
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.070, range=[-0.128, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610

Época 35/50 [LR: 0.00065610]
[DEBUG] Forward - source: 7 tokens, target: 6 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.430, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=0.430
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.862417
[ENCODER] After pos encoding: 896/896 non-zero, sum=49.788780
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.832 -0.200 -0.571 1.175 -0.701 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.233, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.233
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-2.631950
[DECODER] After pos encoding: 768/768 non-zero, sum=35.858299
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.748 -0.096 -0.276 1.129 -0.457 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.295, 2.354]
[DEBUG] Output sample values: -0.925 0.319 0.636 0.373 -0.252 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.295, 2.354] Var:0.354
[LOSS] Calculated loss: 7.622
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.091, range=[-0.150, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.108, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.108
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.532437
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.835953
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.459 -0.160 -0.755 1.478 -0.732 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.700, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.700
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=7.915417
[DECODER] After pos encoding: 768/768 non-zero, sum=46.405666
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.276 -0.114 -0.524 1.451 -0.516 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.381, 1.996]
[DEBUG] Output sample values: -0.956 0.592 0.720 -0.332 -0.692 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.381, 1.996] Var:0.362
[LOSS] Calculated loss: 7.541
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.150
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.092, range=[-0.150, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=0.145
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=1.635700
[ENCODER] After pos encoding: 896/896 non-zero, sum=46.562042
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.601 -0.481 -0.746 1.736 -0.799 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.481, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.481
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.069036
[DECODER] After pos encoding: 1152/1152 non-zero, sum=85.885529
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.413 -0.568 -0.512 1.790 -0.662 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.388, 2.326]
[DEBUG] Output sample values: -0.873 0.394 0.529 -0.518 -0.479 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.388, 2.326] Var:0.356
[LOSS] Calculated loss: 8.079
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 9 tokens, target: 12 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.244, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.244
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.763582
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.580059
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.714 -0.157 -0.656 1.590 -1.246 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.085, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=2.085
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.593910
[DECODER] After pos encoding: 1536/1536 non-zero, sum=100.790276
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -0.775 -0.323 0.187 1.313 -0.769 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.410, 2.178]
[DEBUG] Output sample values: -0.708 0.456 0.400 0.196 0.054 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.410, 2.178] Var:0.355
[LOSS] Calculated loss: 7.534
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.007, bias: 0.149
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 12 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 14 tokens, target: 12 tokens
[ENCODER] Starting encode with 14 tokens
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=-1.791, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1792/1792 non-zero, sum=-1.791
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[ENCODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=-20.257500
[ENCODER] After pos encoding: 1792/1792 non-zero, sum=69.888725
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1792/1792 non-zero
[ENCODER_LAYER] After self-attention: 1792/1792 non-zero
[ENCODER_LAYER] After norm1: 1792/1792 non-zero
[ENCODER_LAYER] After feedforward: 1792/1792 non-zero
[ENCODER_LAYER] Final output: 1792/1792 non-zero
[ENCODER] Layer 0 output: 1792/1792 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1792/1792 non-zero
[ENCODER_LAYER] After self-attention: 1792/1792 non-zero
[ENCODER_LAYER] After norm1: 1792/1792 non-zero
[ENCODER_LAYER] After feedforward: 1792/1792 non-zero
[ENCODER_LAYER] Final output: 1792/1792 non-zero
[ENCODER] Layer 1 output: 1792/1792 non-zero, sum=-0.000015
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 14x128
[DEBUG] Encoder sample values: -1.184 -0.221 -1.025 1.290 -0.962 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.055, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.055
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=0.622151
[DECODER] After pos encoding: 1536/1536 non-zero, sum=77.818649
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.244 -0.112 -0.920 1.204 -0.882 
[DEBUG] Output projection - shape: 12x2000
[DEBUG] Output range: [-2.275, 2.475]
[DEBUG] Output sample values: -0.740 0.451 0.549 -0.104 0.251 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.275, 2.475] Var:0.370
[LOSS] Calculated loss: 7.630
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.075
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 12 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.411, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=1.411
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=15.966298
[ENCODER] After pos encoding: 768/768 non-zero, sum=54.456566
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: -0.491 0.054 -0.594 1.287 -0.609 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.585, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.585
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.930178
[DECODER] After pos encoding: 640/640 non-zero, sum=49.990433
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.286 0.133 -0.282 1.238 -0.314 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.008, 2.305]
[DEBUG] Output sample values: -0.736 0.421 0.462 0.203 -0.197 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.008, 2.305] Var:0.352
[LOSS] Calculated loss: 7.419
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.016, bias: 0.359
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.122, range=[-0.180, 0.001]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.909, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=1.909
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.599136
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=92.329445
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: -0.957 -0.424 -0.722 1.424 -0.443 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.154, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.154
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=1.743609
[DECODER] After pos encoding: 1280/1280 non-zero, sum=66.014046
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -1.013 -0.355 -0.442 1.344 -0.039 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.248, 2.504]
[DEBUG] Output sample values: -0.834 0.646 0.537 -0.147 -0.324 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.248, 2.504] Var:0.356
[LOSS] Calculated loss: 7.901
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.008, bias: 0.179
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.158, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-2.158
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-24.410313
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=26.958076
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.510 -0.212 -0.980 1.629 -0.648 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.807, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.807
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=20.445623
[DECODER] After pos encoding: 1280/1280 non-zero, sum=84.715958
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.463 0.047 -0.778 1.717 -0.434 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.508, 2.640]
[DEBUG] Output sample values: -0.598 0.197 0.590 0.049 -0.412 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.508, 2.640] Var:0.356
[LOSS] Calculated loss: 7.629
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.004, bias: 0.090
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.807, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.807
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.439247
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.487083
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.612 -0.011 -0.590 1.127 -1.366 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.337, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.337
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-15.123614
[DECODER] After pos encoding: 1152/1152 non-zero, sum=42.692825
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.505 0.055 -0.338 1.062 -1.370 
[DEBUG] Output projection - shape: 9x2000
[DEBUG] Output range: [-2.249, 2.250]
[DEBUG] Output sample values: -0.618 0.139 0.424 -0.203 0.100 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.249, 2.250] Var:0.349
[LOSS] Calculated loss: 7.858
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.005, bias: 0.100
[LINEAR] Output projection - using 5x learning rate: 0.003
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.06089116 -0.02918426 -0.02078349 0.00103693 -0.09686344 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00065610
[DEBUG] Forward - source: 8 tokens, target: 11 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.126, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=0.126
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=1.422940
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=52.791340
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.943 0.340 -0.540 1.454 -1.184 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.400, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.400
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=4.531042
[DECODER] After pos encoding: 1408/1408 non-zero, sum=75.261574
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.036 0.451 -0.201 1.398 -1.205 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.240, 2.688]
[DEBUG] Output sample values: -0.582 0.885 0.418 -0.609 -0.263 
[DEBUG] Forward completed!
[LOSS] Predictions range: [-2.240, 2.688] Var:0.359
[LOSS] Calculated loss: 7.772
^C