Se truncaron las últimas líneas 5000 del resultado de transmisión.
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0115, bias: 0.2426
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 11 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0347, range=[-0.0908, 0.0084]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 12 tokens, target: 12 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-1.948, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=-1.948
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-22.037470
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=55.158932
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: 0.743 -0.452 -1.779 -0.355 0.771 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.254, range=[-0.146, 2.341]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.254
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=2.874394
[DECODER] After pos encoding: 1536/1536 non-zero, sum=80.070847
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000017
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.945 1.421 5.289 -1.743 0.901 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-3.348, 5.332]
[DEBUG] Output sample values: -0.262 4.069 3.631 3.921 2.980 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.348, 5.332] Var:0.805
[LOSS] Calculated loss: 5.052
[TRAINER] Loss stagnant (improvement: -1.377), boosting LR to 0.050
 Loss: 5.052 (LR: 0.0500)[LOSS] Gradient sum: 1.9784
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0046, bias: 0.0819
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 12 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0317, range=[-0.0833, 0.0030]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.369, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=0.369
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=4.178301
[ENCODER] After pos encoding: 768/768 non-zero, sum=42.668591
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 0.705 -0.396 -1.839 -0.377 0.315 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.013, range=[-0.146, 2.345]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.013
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.778851
[DECODER] After pos encoding: 640/640 non-zero, sum=54.839024
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.641 1.045 2.950 -1.032 -0.811 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.593, 5.212]
[DEBUG] Output sample values: -0.767 3.637 4.714 5.165 2.231 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.593, 5.212] Var:0.780
[LOSS] Calculated loss: 4.376
 Loss: 4.376 (LR: 0.0200)[LOSS] Gradient sum: 1.9381
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0100, bias: 0.1972
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 5 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0495, range=[-0.1872, 0.0201]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
  Promedio de loss: 5.273

Época 95/100
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.289, range=[-0.146, 2.349]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.289
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=37.213844
[DECODER] After pos encoding: 896/896 non-zero, sum=82.140228
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000013
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.114 0.618 6.177 -1.661 0.605 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.134, 4.592]
[DEBUG] Output sample values: 0.371 3.675 4.442 4.542 3.108 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.134, 4.592] Var:0.827
[LOSS] Calculated loss: 4.915
 Loss: 4.915 (LR: 0.0180)[LOSS] Gradient sum: 1.9716
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0073, bias: 0.1388
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0112, range=[-0.1356, 0.0080]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.953, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.953
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=22.094217
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.910606
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.922 -0.433 -1.647 -0.205 0.317 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=6.812, range=[-0.146, 2.351]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=6.812
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=77.067825
[DECODER] After pos encoding: 896/896 non-zero, sum=121.994179
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.125 0.928 4.935 -0.469 -0.075 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.045, 5.443]
[DEBUG] Output sample values: -1.024 3.363 5.443 4.279 2.178 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.045, 5.443] Var:0.794
[LOSS] Calculated loss: 3.984
 Loss: 3.984 (LR: 0.0180)[LOSS] Gradient sum: 1.9346
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0080, bias: 0.1410
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0094, range=[-0.1248, 0.0056]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.307, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=4.307
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=48.727699
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=100.096130
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 0.741 -0.927 -1.683 -0.045 0.367 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=9.297, range=[-0.146, 2.353]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=9.297
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=105.178940
[DECODER] After pos encoding: 1024/1024 non-zero, sum=156.547180
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000022
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000014
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.126 -0.271 3.806 0.143 -0.832 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-2.551, 5.122]
[DEBUG] Output sample values: -0.531 2.831 4.541 4.136 2.247 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.551, 5.122] Var:0.800
[LOSS] Calculated loss: 5.014
 Loss: 5.014 (LR: 0.0180)[LOSS] Gradient sum: 1.9661
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0144, bias: 0.3615
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 8 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0961, range=[-0.1243, 0.0070]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.141, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=2.141
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.224123
[ENCODER] After pos encoding: 768/768 non-zero, sum=62.714378
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 1.002 -0.350 -1.561 -0.174 0.120 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.526, range=[-0.146, 2.355]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.526
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=17.260490
[DECODER] After pos encoding: 896/896 non-zero, sum=62.186756
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.224 0.388 5.039 -0.214 -1.026 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.348, 5.312]
[DEBUG] Output sample values: -0.091 3.499 5.099 3.946 1.560 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.348, 5.312] Var:0.828
[LOSS] Calculated loss: 5.034
 Loss: 5.034 (LR: 0.0180)[LOSS] Gradient sum: 1.9603
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0079, bias: 0.1410
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0109, range=[-0.1290, 0.0044]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.065, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.065
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-0.737344
[ENCODER] After pos encoding: 640/640 non-zero, sum=31.322886
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.903 -0.456 -1.925 -0.334 0.339 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.195, range=[-0.146, 2.358]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.195
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.837362
[DECODER] After pos encoding: 768/768 non-zero, sum=63.327618
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -1.031 -0.717 4.686 -0.904 -0.825 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] Output range: [-3.142, 5.160]
[DEBUG] Output sample values: -0.253 3.710 4.401 4.171 2.405 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.142, 5.160] Var:0.784
[LOSS] Calculated loss: 4.896
 Loss: 4.896 (LR: 0.0180)[LOSS] Gradient sum: 1.9677
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0089, bias: 0.1651
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 6 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0311, range=[-0.1582, 0.0067]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 9 tokens, target: 11 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.820, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.820
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=43.212814
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=101.029320
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.759 -0.463 -1.675 -0.151 0.135 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.843, range=[-0.146, 2.361]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.843
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=20.853178
[DECODER] After pos encoding: 1408/1408 non-zero, sum=91.583565
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.017 0.607 4.720 -0.500 -1.213 
[DEBUG] Output projection - shape: 11x1000
[DEBUG] Output range: [-2.653, 5.517]
[DEBUG] Output sample values: -0.705 3.295 5.091 4.431 2.666 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.653, 5.517] Var:0.796
[LOSS] Calculated loss: 4.983
 Loss: 4.983 (LR: 0.0200)[LOSS] Gradient sum: 1.9645
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0125, bias: 0.2428
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 11 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0346, range=[-0.0908, 0.0083]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 12 tokens, target: 12 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-1.948, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=-1.948
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-22.037470
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=55.158932
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: 0.743 -0.452 -1.779 -0.355 0.771 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.267, range=[-0.146, 2.362]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.267
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=3.021287
[DECODER] After pos encoding: 1536/1536 non-zero, sum=80.217728
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.949 1.429 5.294 -1.749 0.893 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-3.350, 5.341]
[DEBUG] Output sample values: -0.264 4.085 3.661 3.949 2.987 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.350, 5.341] Var:0.806
[LOSS] Calculated loss: 5.041
[TRAINER] Loss stagnant (improvement: -0.416), boosting LR to 0.050
 Loss: 5.041 (LR: 0.0500)[LOSS] Gradient sum: 1.9782
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0046, bias: 0.0819
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 12 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0316, range=[-0.0833, 0.0030]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.369, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=0.369
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=4.178301
[ENCODER] After pos encoding: 768/768 non-zero, sum=42.668591
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 0.705 -0.396 -1.839 -0.377 0.315 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.027, range=[-0.146, 2.366]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.027
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.934425
[DECODER] After pos encoding: 640/640 non-zero, sum=54.994625
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.646 1.053 2.958 -1.037 -0.818 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.598, 5.217]
[DEBUG] Output sample values: -0.770 3.645 4.729 5.176 2.237 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.598, 5.217] Var:0.782
[LOSS] Calculated loss: 4.368
 Loss: 4.368 (LR: 0.0200)[LOSS] Gradient sum: 1.9377
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0108, bias: 0.1972
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 5 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0493, range=[-0.1871, 0.0202]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
  Promedio de loss: 4.779
  === Progreso en época 95 ===
[DEBUG] Forward - source: 9 tokens, target: 1 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.632, range=[-0.146, 2.370]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.632
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=29.776066
[DECODER] After pos encoding: 128/128 non-zero, sum=36.176071
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.400 -0.044 1.600 -0.827 -0.267 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.145, 4.396]
[DEBUG] Output sample values: -0.322 3.074 3.984 4.396 2.525 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 5 (score: 3.7, target_len: 8) [Top scores: 3:4.4 5:3.7 16:3.6 8:3.3 33:3.2 ]
[DEBUG] Forward - source: 9 tokens, target: 2 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.156, range=[-0.146, 2.370]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.156
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=1.760861
[DECODER] After pos encoding: 256/256 non-zero, sum=14.566880
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.307 0.268 2.061 -0.799 -0.231 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.659, 5.501]
[DEBUG] Output sample values: -0.393 3.270 4.340 4.290 2.626 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 1 (score: 4.8, target_len: 8) [Top scores: 1:4.8 3:4.1 111:3.2 16:3.2 8:3.1 ]
[DEBUG] Forward - source: 9 tokens, target: 3 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1.062, range=[-0.146, 2.370]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1.062
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=12.010966
[DECODER] After pos encoding: 384/384 non-zero, sum=31.229019
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.999 -0.128 3.351 -0.866 0.630 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.800, 5.405]
[DEBUG] Output sample values: -0.074 2.945 4.007 3.475 2.333 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 3 (score: 3.9, target_len: 8) [Top scores: 3:3.9 33:3.9 8:3.6 61:3.6 16:2.9 ]
  ENG: <sos> i don t want to walk home <eos>
  ESP: <sos> de <unk> <eos>
  ================================

Época 96/100
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.303, range=[-0.146, 2.370]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.303
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=37.364311
[DECODER] After pos encoding: 896/896 non-zero, sum=82.290619
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.119 0.626 6.182 -1.666 0.598 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.135, 4.614]
[DEBUG] Output sample values: 0.369 3.706 4.451 4.557 3.115 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.135, 4.614] Var:0.829
[LOSS] Calculated loss: 4.911
[TRAINER] Loss stagnant (improvement: -0.094), boosting LR to 0.050
 Loss: 4.911 (LR: 0.0500)[LOSS] Gradient sum: 1.9714
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0073, bias: 0.1388
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0111, range=[-0.1356, 0.0081]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.953, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.953
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=22.094217
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.910606
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.922 -0.433 -1.647 -0.205 0.317 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=6.827, range=[-0.146, 2.377]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=6.827
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=77.239479
[DECODER] After pos encoding: 896/896 non-zero, sum=122.165825
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.133 0.932 4.940 -0.472 -0.080 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.045, 5.463]
[DEBUG] Output sample values: -1.028 3.388 5.463 4.321 2.223 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.045, 5.463] Var:0.796
[LOSS] Calculated loss: 3.972
 Loss: 3.972 (LR: 0.0180)[LOSS] Gradient sum: 1.9336
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0075, bias: 0.1410
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0093, range=[-0.1246, 0.0058]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.307, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=4.307
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=48.727699
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=100.096130
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 0.741 -0.927 -1.683 -0.045 0.367 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=9.312, range=[-0.146, 2.379]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=9.312
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=105.352646
[DECODER] After pos encoding: 1024/1024 non-zero, sum=156.721085
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.136 -0.263 3.818 0.139 -0.843 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-2.550, 5.127]
[DEBUG] Output sample values: -0.534 2.853 4.553 4.181 2.271 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.550, 5.127] Var:0.802
[LOSS] Calculated loss: 4.995
 Loss: 4.995 (LR: 0.0180)[LOSS] Gradient sum: 1.9655
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0152, bias: 0.3611
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 8 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0957, range=[-0.1242, 0.0069]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.141, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=2.141
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.224123
[ENCODER] After pos encoding: 768/768 non-zero, sum=62.714378
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 1.002 -0.349 -1.561 -0.174 0.120 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.541, range=[-0.146, 2.381]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.541
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=17.438475
[DECODER] After pos encoding: 896/896 non-zero, sum=62.364811
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.232 0.393 5.057 -0.218 -1.032 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.349, 5.323]
[DEBUG] Output sample values: -0.095 3.514 5.116 4.007 1.602 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.349, 5.323] Var:0.829
[LOSS] Calculated loss: 5.021
 Loss: 5.021 (LR: 0.0200)[LOSS] Gradient sum: 1.9597
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0071, bias: 0.1410
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 7 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0108, range=[-0.1289, 0.0046]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.065, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.065
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-0.737344
[ENCODER] After pos encoding: 640/640 non-zero, sum=31.322886
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.903 -0.455 -1.925 -0.333 0.338 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.212, range=[-0.146, 2.384]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.212
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.024630
[DECODER] After pos encoding: 768/768 non-zero, sum=63.514866
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: nan nan nan nan nan 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [nan, nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0200)[LOSS] Gradient sum: 1.9979
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0083, bias: 0.1657
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0387, range=[-0.1665, 0.0002]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 9 tokens, target: 11 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.820, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.820
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=43.212814
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=101.029320
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.759 -0.462 -1.675 -0.151 0.135 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.858, range=[-0.146, 2.387]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.858
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.020271
[DECODER] After pos encoding: 1408/1408 non-zero, sum=91.750710
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000021
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.025 0.613 4.733 -0.505 -1.221 
[DEBUG] Output projection - shape: 11x1000
[DEBUG] Output range: [-2.652, 5.544]
[DEBUG] Output sample values: -0.708 3.317 5.103 4.469 2.702 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.652, 5.544] Var:0.799
[LOSS] Calculated loss: 4.971
[TRAINER] Loss stagnant (improvement: -0.901), boosting LR to 0.050
 Loss: 4.971 (LR: 0.0500)[LOSS] Gradient sum: 1.9640
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0112, bias: 0.2423
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 11 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0342, range=[-0.0908, 0.0085]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 12 tokens, target: 12 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-1.948, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=-1.948
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-22.037470
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=55.158932
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: 0.743 -0.452 -1.779 -0.355 0.771 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.286, range=[-0.146, 2.391]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.286
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=3.235122
[DECODER] After pos encoding: 1536/1536 non-zero, sum=80.431473
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.956 1.438 5.301 -1.755 0.882 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-3.352, 5.383]
[DEBUG] Output sample values: -0.265 4.117 3.662 3.965 3.012 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.352, 5.383] Var:0.809
[LOSS] Calculated loss: 5.029
 Loss: 5.029 (LR: 0.0200)[LOSS] Gradient sum: 1.9777
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0050, bias: 0.0819
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0314, range=[-0.0833, 0.0031]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.369, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=0.369
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=4.178301
[ENCODER] After pos encoding: 768/768 non-zero, sum=42.668591
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 767/768 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 0.706 -0.396 -1.839 -0.376 0.315 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.046, range=[-0.146, 2.393]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.046
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.150457
[DECODER] After pos encoding: 640/640 non-zero, sum=55.210670
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.654 1.062 2.970 -1.041 -0.825 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.604, 5.217]
[DEBUG] Output sample values: -0.773 3.682 4.751 5.198 2.291 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.604, 5.217] Var:0.784
[LOSS] Calculated loss: 4.352
[TRAINER] Loss stagnant (improvement: -0.590), boosting LR to 0.050
 Loss: 4.352 (LR: 0.0500)[LOSS] Gradient sum: 1.9367
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0101, bias: 0.1972
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 5 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0490, range=[-0.1869, 0.0206]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.020

Época 97/100
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.320, range=[-0.146, 2.402]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.320
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=37.564796
[DECODER] After pos encoding: 896/896 non-zero, sum=82.491226
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.128 0.639 6.191 -1.672 0.589 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.138, 4.617]
[DEBUG] Output sample values: 0.365 3.745 4.475 4.572 3.145 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.138, 4.617] Var:0.831
[LOSS] Calculated loss: 4.898
 Loss: 4.898 (LR: 0.0180)[LOSS] Gradient sum: 1.9710
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0073, bias: 0.1387
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0111, range=[-0.1354, 0.0082]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.953, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.953
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=22.094217
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.910606
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.922 -0.433 -1.647 -0.205 0.317 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=6.845, range=[-0.146, 2.405]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=6.845
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=77.445694
[DECODER] After pos encoding: 896/896 non-zero, sum=122.371986
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.141 0.942 4.943 -0.475 -0.086 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.044, 5.463]
[DEBUG] Output sample values: -1.033 3.422 5.463 4.335 2.228 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.044, 5.463] Var:0.798
[LOSS] Calculated loss: 3.961
 Loss: 3.961 (LR: 0.0180)[LOSS] Gradient sum: 1.9332
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0076, bias: 0.1410
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0093, range=[-0.1246, 0.0059]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.307, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=4.307
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=48.727699
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=100.096130
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000015
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 0.741 -0.927 -1.683 -0.045 0.367 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=9.333, range=[-0.146, 2.407]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=9.333
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=105.586586
[DECODER] After pos encoding: 1024/1024 non-zero, sum=156.954819
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.147 -0.249 3.829 0.135 -0.855 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-2.551, 5.129]
[DEBUG] Output sample values: -0.539 2.904 4.599 4.173 2.273 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.551, 5.129] Var:0.804
[LOSS] Calculated loss: 4.969
 Loss: 4.969 (LR: 0.0180)[LOSS] Gradient sum: 1.9644
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0155, bias: 0.3606
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 8 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0954, range=[-0.1242, 0.0069]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.141, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=2.141
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.224123
[ENCODER] After pos encoding: 768/768 non-zero, sum=62.714378
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 1.002 -0.349 -1.561 -0.174 0.120 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.557, range=[-0.146, 2.409]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.557
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=17.616814
[DECODER] After pos encoding: 896/896 non-zero, sum=62.543140
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: nan nan nan nan nan 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [nan, nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0180)[LOSS] Gradient sum: 1.9978
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0071, bias: 0.1419
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0149, range=[-0.1427, 0.0001]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.065, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.065
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-0.737344
[ENCODER] After pos encoding: 640/640 non-zero, sum=31.322886
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.903 -0.455 -1.925 -0.333 0.338 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.229, range=[-0.146, 2.412]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.229
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.220669
[DECODER] After pos encoding: 768/768 non-zero, sum=63.710907
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: nan nan nan nan nan 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [nan, nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0200)[LOSS] Gradient sum: 1.9979
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0083, bias: 0.1657
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0387, range=[-0.1665, 0.0002]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 9 tokens, target: 11 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.820, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.820
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=43.212814
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=101.029320
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.759 -0.462 -1.675 -0.151 0.135 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.876, range=[-0.146, 2.415]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.876
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.219215
[DECODER] After pos encoding: 1408/1408 non-zero, sum=91.949646
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.033 0.623 4.744 -0.510 -1.230 
[DEBUG] Output projection - shape: 11x1000
[DEBUG] Output range: [-2.655, 5.525]
[DEBUG] Output sample values: -0.712 3.372 5.109 4.472 2.709 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.655, 5.525] Var:0.801
[LOSS] Calculated loss: 4.943
[TRAINER] Loss stagnant (improvement: -1.372), boosting LR to 0.050
 Loss: 4.943 (LR: 0.0500)[LOSS] Gradient sum: 1.9634
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0118, bias: 0.2408
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 11 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0341, range=[-0.0908, 0.0084]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 12 tokens, target: 12 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-1.948, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=-1.948
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-22.037470
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=55.158932
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000012
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: 0.743 -0.452 -1.779 -0.355 0.771 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.304, range=[-0.146, 2.419]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.304
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=3.444509
[DECODER] After pos encoding: 1536/1536 non-zero, sum=80.640938
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.963 1.451 5.303 -1.761 0.873 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-3.353, 5.403]
[DEBUG] Output sample values: -0.267 4.172 3.684 3.944 3.024 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.353, 5.403] Var:0.810
[LOSS] Calculated loss: 5.023
 Loss: 5.023 (LR: 0.0200)[LOSS] Gradient sum: 1.9775
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0050, bias: 0.0819
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0313, range=[-0.0833, 0.0033]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.369, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=0.369
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=4.178301
[ENCODER] After pos encoding: 768/768 non-zero, sum=42.668591
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 0.705 -0.396 -1.839 -0.377 0.315 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.064, range=[-0.146, 2.421]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.064
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.354324
[DECODER] After pos encoding: 640/640 non-zero, sum=55.414566
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.661 1.076 2.978 -1.046 -0.832 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.611, 5.217]
[DEBUG] Output sample values: -0.777 3.734 4.770 5.193 2.295 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.611, 5.217] Var:0.786
[LOSS] Calculated loss: 4.320
[TRAINER] Loss stagnant (improvement: -0.114), boosting LR to 0.050
 Loss: 4.320 (LR: 0.0500)[LOSS] Gradient sum: 1.9360
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0105, bias: 0.1969
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 5 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0488, range=[-0.1866, 0.0204]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.241

Época 98/100
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.338, range=[-0.146, 2.430]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.338
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=37.763195
[DECODER] After pos encoding: 896/896 non-zero, sum=82.689461
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.136 0.652 6.195 -1.677 0.581 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.140, 4.626]
[DEBUG] Output sample values: 0.362 3.778 4.505 4.574 3.158 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.140, 4.626] Var:0.832
[LOSS] Calculated loss: 4.895
 Loss: 4.895 (LR: 0.0180)[LOSS] Gradient sum: 1.9707
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0073, bias: 0.1387
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0110, range=[-0.1352, 0.0082]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.953, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.953
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=22.094217
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.910606
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.922 -0.433 -1.647 -0.205 0.317 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=6.864, range=[-0.146, 2.432]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=6.864
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=77.653938
[DECODER] After pos encoding: 896/896 non-zero, sum=122.580200
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.150 0.952 4.944 -0.478 -0.090 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.043, 5.489]
[DEBUG] Output sample values: -1.036 3.443 5.489 4.352 2.234 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.043, 5.489] Var:0.801
[LOSS] Calculated loss: 3.951
 Loss: 3.951 (LR: 0.0180)[LOSS] Gradient sum: 1.9322
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0075, bias: 0.1410
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0092, range=[-0.1243, 0.0060]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.307, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=4.307
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=48.727699
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=100.096130
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 0.741 -0.927 -1.683 -0.045 0.367 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=9.353, range=[-0.147, 2.435]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=9.353
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=105.822166
[DECODER] After pos encoding: 1024/1024 non-zero, sum=157.190659
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.158 -0.235 3.839 0.132 -0.867 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-2.552, 5.115]
[DEBUG] Output sample values: -0.544 2.926 4.602 4.201 2.268 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.552, 5.115] Var:0.806
[LOSS] Calculated loss: 4.953
 Loss: 4.953 (LR: 0.0180)[LOSS] Gradient sum: 1.9640
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0152, bias: 0.3603
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 8 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0952, range=[-0.1242, 0.0068]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.141, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=2.141
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.224123
[ENCODER] After pos encoding: 768/768 non-zero, sum=62.714378
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 1.002 -0.349 -1.561 -0.174 0.120 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.573, range=[-0.146, 2.437]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.573
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=17.795090
[DECODER] After pos encoding: 896/896 non-zero, sum=62.721428
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: nan nan nan nan nan 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [nan, nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0180)[LOSS] Gradient sum: 1.9978
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0072, bias: 0.1419
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0149, range=[-0.1427, 0.0001]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.065, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.065
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-0.737344
[ENCODER] After pos encoding: 640/640 non-zero, sum=31.322886
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.903 -0.455 -1.925 -0.333 0.338 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.246, range=[-0.146, 2.439]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.246
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.416166
[DECODER] After pos encoding: 768/768 non-zero, sum=63.906414
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: nan nan nan nan nan 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [nan, nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0200)[LOSS] Gradient sum: 1.9979
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0083, bias: 0.1657
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0387, range=[-0.1665, 0.0002]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 9 tokens, target: 11 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.820, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.820
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=43.212814
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=101.029320
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000015
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.759 -0.462 -1.675 -0.151 0.135 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.893, range=[-0.147, 2.443]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.893
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.417894
[DECODER] After pos encoding: 1408/1408 non-zero, sum=92.148293
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.041 0.634 4.754 -0.514 -1.237 
[DEBUG] Output projection - shape: 11x1000
[DEBUG] Output range: [-2.659, 5.513]
[DEBUG] Output sample values: -0.715 3.415 5.138 4.490 2.710 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.659, 5.513] Var:0.803
[LOSS] Calculated loss: 4.920
[TRAINER] Loss stagnant (improvement: -1.375), boosting LR to 0.050
 Loss: 4.920 (LR: 0.0500)[LOSS] Gradient sum: 1.9625
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0116, bias: 0.2397
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 11 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0340, range=[-0.0908, 0.0085]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 12 tokens, target: 12 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-1.948, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=-1.948
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-22.037470
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=55.158932
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: 0.743 -0.452 -1.780 -0.355 0.771 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.323, range=[-0.147, 2.447]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.323
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=3.653358
[DECODER] After pos encoding: 1536/1536 non-zero, sum=80.849770
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.968 1.463 5.306 -1.766 0.864 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-3.354, 5.417]
[DEBUG] Output sample values: -0.270 4.185 3.695 3.960 3.029 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.354, 5.417] Var:0.812
[LOSS] Calculated loss: 5.018
 Loss: 5.018 (LR: 0.0200)[LOSS] Gradient sum: 1.9774
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0048, bias: 0.0818
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0312, range=[-0.0833, 0.0033]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.369, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=0.369
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=4.178301
[ENCODER] After pos encoding: 768/768 non-zero, sum=42.668591
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 0.705 -0.396 -1.839 -0.377 0.315 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.082, range=[-0.147, 2.448]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.082
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.557724
[DECODER] After pos encoding: 640/640 non-zero, sum=55.617897
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.668 1.088 2.986 -1.050 -0.839 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.617, 5.223]
[DEBUG] Output sample values: -0.781 3.739 4.789 5.219 2.293 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.617, 5.223] Var:0.787
[LOSS] Calculated loss: 4.291
[TRAINER] Loss stagnant (improvement: -0.107), boosting LR to 0.050
 Loss: 4.291 (LR: 0.0500)[LOSS] Gradient sum: 1.9350
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0103, bias: 0.1968
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 5 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0486, range=[-0.1865, 0.0208]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.230

Época 99/100
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.355, range=[-0.146, 2.458]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.355
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=37.960773
[DECODER] After pos encoding: 896/896 non-zero, sum=82.887123
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.142 0.664 6.200 -1.681 0.574 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.142, 4.631]
[DEBUG] Output sample values: 0.358 3.787 4.549 4.573 3.163 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.142, 4.631] Var:0.834
[LOSS] Calculated loss: 4.885
 Loss: 4.885 (LR: 0.0180)[LOSS] Gradient sum: 1.9699
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0075, bias: 0.1387
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0110, range=[-0.1349, 0.0081]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.953, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.953
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=22.094217
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.910606
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000012
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.922 -0.433 -1.647 -0.205 0.317 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=6.882, range=[-0.147, 2.460]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=6.882
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=77.861549
[DECODER] After pos encoding: 896/896 non-zero, sum=122.787857
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.158 0.960 4.945 -0.480 -0.096 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.042, 5.513]
[DEBUG] Output sample values: -1.042 3.427 5.513 4.364 2.240 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.042, 5.513] Var:0.802
[LOSS] Calculated loss: 3.945
 Loss: 3.945 (LR: 0.0180)[LOSS] Gradient sum: 1.9312
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0076, bias: 0.1410
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0092, range=[-0.1239, 0.0060]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.307, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=4.307
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=48.727699
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=100.096130
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 0.741 -0.927 -1.683 -0.045 0.367 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=9.374, range=[-0.147, 2.462]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=9.374
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=106.057777
[DECODER] After pos encoding: 1024/1024 non-zero, sum=157.426102
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.168 -0.222 3.848 0.129 -0.878 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-2.557, 5.112]
[DEBUG] Output sample values: -0.549 2.914 4.627 4.224 2.272 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.557, 5.112] Var:0.807
[LOSS] Calculated loss: 4.941
 Loss: 4.941 (LR: 0.0180)[LOSS] Gradient sum: 1.9635
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0160, bias: 0.3602
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 8 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0950, range=[-0.1242, 0.0067]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.141, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=2.141
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.224123
[ENCODER] After pos encoding: 768/768 non-zero, sum=62.714378
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000013
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 1.002 -0.349 -1.561 -0.174 0.120 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.589, range=[-0.146, 2.464]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.589
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=17.972633
[DECODER] After pos encoding: 896/896 non-zero, sum=62.898952
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: nan nan nan nan nan 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [nan, nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0180)[LOSS] Gradient sum: 1.9978
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0071, bias: 0.1419
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0149, range=[-0.1427, 0.0001]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.065, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.065
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-0.737344
[ENCODER] After pos encoding: 640/640 non-zero, sum=31.322886
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.903 -0.455 -1.925 -0.333 0.338 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.146, 2.467]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.264
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.610937
[DECODER] After pos encoding: 768/768 non-zero, sum=64.101143
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: nan nan nan nan nan 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [nan, nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0200)[LOSS] Gradient sum: 1.9979
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0083, bias: 0.1657
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0387, range=[-0.1665, 0.0002]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 9 tokens, target: 11 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.820, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.820
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=43.212814
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=101.029320
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.759 -0.462 -1.675 -0.151 0.135 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.911, range=[-0.147, 2.470]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.911
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.616289
[DECODER] After pos encoding: 1408/1408 non-zero, sum=92.346764
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.049 0.644 4.763 -0.518 -1.246 
[DEBUG] Output projection - shape: 11x1000
[DEBUG] Output range: [-2.663, 5.497]
[DEBUG] Output sample values: -0.719 3.426 5.160 4.486 2.720 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.663, 5.497] Var:0.804
[LOSS] Calculated loss: 4.907
[TRAINER] Loss stagnant (improvement: -1.381), boosting LR to 0.050
 Loss: 4.907 (LR: 0.0500)[LOSS] Gradient sum: 1.9621
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0117, bias: 0.2393
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 11 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0339, range=[-0.0908, 0.0084]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 12 tokens, target: 12 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-1.948, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=-1.948
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-22.037470
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=55.158932
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: 0.743 -0.451 -1.780 -0.355 0.771 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.341, range=[-0.147, 2.474]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.341
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=3.861647
[DECODER] After pos encoding: 1536/1536 non-zero, sum=81.058067
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.974 1.476 5.308 -1.770 0.853 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-3.354, 5.462]
[DEBUG] Output sample values: -0.273 4.181 3.748 4.008 3.034 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.354, 5.462] Var:0.814
[LOSS] Calculated loss: 5.012
 Loss: 5.012 (LR: 0.0200)[LOSS] Gradient sum: 1.9771
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0048, bias: 0.0818
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0311, range=[-0.0833, 0.0033]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.369, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=0.369
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=4.178301
[ENCODER] After pos encoding: 768/768 non-zero, sum=42.668591
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000014
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 0.705 -0.396 -1.839 -0.377 0.315 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.100, range=[-0.147, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.100
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.760645
[DECODER] After pos encoding: 640/640 non-zero, sum=55.820831
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.675 1.100 2.994 -1.053 -0.848 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.623, 5.248]
[DEBUG] Output sample values: -0.786 3.726 4.831 5.248 2.299 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.623, 5.248] Var:0.789
[LOSS] Calculated loss: 4.259
[TRAINER] Loss stagnant (improvement: -0.101), boosting LR to 0.050
 Loss: 4.259 (LR: 0.0500)[LOSS] Gradient sum: 1.9339
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0109, bias: 0.1965
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 5 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0482, range=[-0.1860, 0.0213]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.221

Época 100/100
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.373, range=[-0.146, 2.485]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.373
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=38.157688
[DECODER] After pos encoding: 896/896 non-zero, sum=83.084091
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.149 0.678 6.203 -1.686 0.565 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.144, 4.663]
[DEBUG] Output sample values: 0.354 3.788 4.570 4.584 3.175 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.144, 4.663] Var:0.836
[LOSS] Calculated loss: 4.880
 Loss: 4.880 (LR: 0.0180)[LOSS] Gradient sum: 1.9694
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0081, bias: 0.1387
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0109, range=[-0.1348, 0.0082]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 9 tokens, target: 7 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.953, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.953
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=22.094217
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.910606
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.922 -0.433 -1.647 -0.205 0.317 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=6.900, range=[-0.147, 2.488]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=6.900
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=78.068489
[DECODER] After pos encoding: 896/896 non-zero, sum=122.994926
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000019
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.166 0.970 4.946 -0.482 -0.101 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.041, 5.524]
[DEBUG] Output sample values: -1.046 3.452 5.524 4.373 2.249 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.041, 5.524] Var:0.805
[LOSS] Calculated loss: 3.932
 Loss: 3.932 (LR: 0.0180)[LOSS] Gradient sum: 1.9304
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0073, bias: 0.1410
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0092, range=[-0.1238, 0.0060]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.307, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=4.307
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=48.727699
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=100.096130
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 0.741 -0.927 -1.683 -0.045 0.367 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=9.395, range=[-0.147, 2.490]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=9.395
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=106.292915
[DECODER] After pos encoding: 1024/1024 non-zero, sum=157.661423
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000019
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.179 -0.207 3.857 0.126 -0.890 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-2.565, 5.104]
[DEBUG] Output sample values: -0.554 2.947 4.668 4.229 2.280 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.565, 5.104] Var:0.809
[LOSS] Calculated loss: 4.917
 Loss: 4.917 (LR: 0.0180)[LOSS] Gradient sum: 1.9624
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0142, bias: 0.3597
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 8 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0947, range=[-0.1242, 0.0067]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 6 tokens, target: 7 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.141, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=2.141
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.224123
[ENCODER] After pos encoding: 768/768 non-zero, sum=62.714378
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 1.002 -0.349 -1.561 -0.174 0.120 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.604, range=[-0.146, 2.492]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.604
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.149319
[DECODER] After pos encoding: 896/896 non-zero, sum=63.075573
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.267 0.438 5.111 -0.231 -1.058 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.351, 5.398]
[DEBUG] Output sample values: -0.115 3.587 5.210 4.080 1.619 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.351, 5.398] Var:0.837
[LOSS] Calculated loss: 4.959
 Loss: 4.959 (LR: 0.0180)[LOSS] Gradient sum: 1.9568
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0077, bias: 0.1409
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0106, range=[-0.1278, 0.0049]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 6 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.065, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.065
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-0.737344
[ENCODER] After pos encoding: 640/640 non-zero, sum=31.322886
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.903 -0.455 -1.926 -0.333 0.339 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.280, range=[-0.146, 2.494]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.280
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.800253
[DECODER] After pos encoding: 768/768 non-zero, sum=64.290535
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -1.084 -0.691 4.755 -0.927 -0.868 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] Output range: [-3.148, 5.206]
[DEBUG] Output sample values: -0.269 3.790 4.491 4.250 2.469 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.148, 5.206] Var:0.795
[LOSS] Calculated loss: 4.838
 Loss: 4.838 (LR: 0.0180)[LOSS] Gradient sum: 1.9655
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0088, bias: 0.1650
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 6 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0305, range=[-0.1576, 0.0071]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 9 tokens, target: 11 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=3.820, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=3.820
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=43.212814
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=101.029320
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.759 -0.462 -1.675 -0.151 0.135 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.927, range=[-0.147, 2.497]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.927
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=21.803213
[DECODER] After pos encoding: 1408/1408 non-zero, sum=92.533684
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000021
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.057 0.654 4.772 -0.522 -1.253 
[DEBUG] Output projection - shape: 11x1000
[DEBUG] Output range: [-2.666, 5.527]
[DEBUG] Output sample values: -0.722 3.429 5.184 4.498 2.730 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.666, 5.527] Var:0.806
[LOSS] Calculated loss: 4.885
 Loss: 4.885 (LR: 0.0200)[LOSS] Gradient sum: 1.9614
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0097, bias: 0.2389
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 11 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0337, range=[-0.0908, 0.0086]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 12 tokens, target: 12 tokens
[ENCODER] Starting encode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-1.948, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1536/1536 non-zero, sum=-1.948
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-22.037470
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=55.158932
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 12x128
[DEBUG] Encoder sample values: 0.743 -0.452 -1.780 -0.355 0.771 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.356, range=[-0.147, 2.499]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.356
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=4.024443
[DECODER] After pos encoding: 1536/1536 non-zero, sum=81.220894
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: -1.978 1.486 5.311 -1.774 0.846 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-3.354, 5.473]
[DEBUG] Output sample values: -0.274 4.179 3.754 4.049 3.034 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.354, 5.473] Var:0.815
[LOSS] Calculated loss: 5.006
[TRAINER] Loss stagnant (improvement: -0.425), boosting LR to 0.050
 Loss: 5.006 (LR: 0.0500)[LOSS] Gradient sum: 1.9769
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0049, bias: 0.0818
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 12 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0310, range=[-0.0833, 0.0033]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 6 tokens, target: 5 tokens
[ENCODER] Starting encode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.369, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 768/768 non-zero, sum=0.369
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=4.178301
[ENCODER] After pos encoding: 768/768 non-zero, sum=42.668591
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 6x128
[DEBUG] Encoder sample values: 0.705 -0.396 -1.839 -0.377 0.316 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.115, range=[-0.147, 2.503]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.115
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.929918
[DECODER] After pos encoding: 640/640 non-zero, sum=55.990063
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.680 1.111 3.002 -1.058 -0.855 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.629, 5.266]
[DEBUG] Output sample values: -0.789 3.764 4.850 5.260 2.303 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.629, 5.266] Var:0.791
[LOSS] Calculated loss: 4.231
 Loss: 4.231 (LR: 0.0200)[LOSS] Gradient sum: 1.9323
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0100, bias: 0.1964
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 5 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0479, range=[-0.1858, 0.0214]
[EMBEDDING] Sample weights after update: 0.13367274 -0.11343814 0.08181760 -0.07288253 -0.14538175 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
  Promedio de loss: 4.706
  === Progreso en época 100 ===
[DEBUG] Forward - source: 9 tokens, target: 1 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.186, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=1.186
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13.416639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=71.233101
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 0.925 -0.499 -1.622 -0.356 0.537 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.730, range=[-0.146, 2.507]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.730
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=30.891438
[DECODER] After pos encoding: 128/128 non-zero, sum=37.291439
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.378 -0.011 1.629 -0.842 -0.298 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.152, 4.496]
[DEBUG] Output sample values: -0.338 3.158 4.061 4.496 2.597 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 3 (score: 4.5, target_len: 8) [Top scores: 3:4.5 5:3.8 16:3.7 8:3.3 33:3.3 ]
  ENG: <sos> i don t want to walk home <eos>
  ESP: <sos> <eos>
  ================================

¡Entrenamiento completado!

=== Pruebas de Traducción ===
[DEBUG] Forward - source: 3 tokens, target: 1 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1.590, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=1.590
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17.988234
[ENCODER] After pos encoding: 384/384 non-zero, sum=37.206303
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: 0.795 -0.713 -1.689 -0.179 0.332 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.730, range=[-0.146, 2.507]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.730
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=30.891438
[DECODER] After pos encoding: 128/128 non-zero, sum=37.291439
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.286 -0.212 1.570 -0.698 -0.486 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.125, 4.624]
[DEBUG] Output sample values: -0.439 3.059 4.060 4.624 2.604 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 3 (score: 4.6, target_len: 2) [Top scores: 3:4.6 5:3.7 16:3.5 8:3.5 33:3.2 ]
ENG: <sos> hello <eos>
ESP: <sos> <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.132, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=0.132
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=1.497793
[ENCODER] After pos encoding: 640/640 non-zero, sum=33.558006
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.915 -0.451 -1.682 -0.235 0.306 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.730, range=[-0.146, 2.507]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.730
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=30.891438
[DECODER] After pos encoding: 128/128 non-zero, sum=37.291439
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.352 -0.015 1.510 -0.775 -0.531 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.150, 4.596]
[DEBUG] Output sample values: -0.381 3.223 4.088 4.596 2.667 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 3 (score: 4.6, target_len: 4) [Top scores: 3:4.6 5:3.7 16:3.6 8:3.3 1:3.2 ]
ENG: <sos> how are you <eos>
ESP: <sos> <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.160, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.160
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-24.432913
[ENCODER] After pos encoding: 512/512 non-zero, sum=1.203218
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.961 -0.642 -1.661 -0.353 0.415 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.730, range=[-0.146, 2.507]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.730
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=30.891438
[DECODER] After pos encoding: 128/128 non-zero, sum=37.291439
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.406 -0.219 1.567 -0.884 -0.465 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.178, 4.680]
[DEBUG] Output sample values: -0.349 3.057 3.952 4.680 2.770 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 16 (score: 3.6, target_len: 3) [Top scores: 3:4.7 5:3.8 16:3.6 8:3.5 33:3.2 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.160, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.160
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-24.432913
[ENCODER] After pos encoding: 512/512 non-zero, sum=1.203218
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.961 -0.642 -1.661 -0.353 0.415 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.527, range=[-0.146, 2.507]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.527
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=28.590319
[DECODER] After pos encoding: 256/256 non-zero, sum=41.396370
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.159 -0.977 2.612 -0.908 -0.221 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.571, 5.108]
[DEBUG] Output sample values: 0.051 3.104 3.794 4.712 3.297 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 3 (score: 5.1, target_len: 3) [Top scores: 3:5.1 8:4.5 1:4.0 5:3.3 49:3.2 ]
ENG: <sos> good morning <eos>
ESP: <sos> me <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.048, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.048
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-11.854761
[ENCODER] After pos encoding: 512/512 non-zero, sum=13.781359
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.956 -0.314 -1.733 -0.339 0.424 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.730, range=[-0.146, 2.507]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.730
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=30.891438
[DECODER] After pos encoding: 128/128 non-zero, sum=37.291439
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.407 0.120 1.508 -0.840 -0.415 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.223, 4.677]
[DEBUG] Output sample values: -0.368 3.152 4.214 4.677 2.547 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 3 (score: 4.7, target_len: 3) [Top scores: 3:4.7 5:3.7 16:3.6 33:3.3 8:3.2 ]
ENG: <sos> thank you <eos>
ESP: <sos> <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.530, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.530
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.994063
[ENCODER] After pos encoding: 640/640 non-zero, sum=26.066143
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.784 -0.293 -1.973 -0.233 0.306 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.730, range=[-0.146, 2.507]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.730
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=30.891438
[DECODER] After pos encoding: 128/128 non-zero, sum=37.291439
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.277 0.125 1.263 -0.792 -0.472 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.193, 4.560]
[DEBUG] Output sample values: -0.613 3.320 4.174 4.560 2.771 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 16 (score: 3.5, target_len: 4) [Top scores: 3:4.6 5:3.8 16:3.5 1:3.3 8:3.3 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.530, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.530
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.994063
[ENCODER] After pos encoding: 640/640 non-zero, sum=26.066143
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.784 -0.293 -1.973 -0.233 0.306 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.527, range=[-0.146, 2.507]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.527
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=28.590319
[DECODER] After pos encoding: 256/256 non-zero, sum=41.396370
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.141 0.456 1.604 -0.749 -0.446 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.644, 4.644]
[DEBUG] Output sample values: -0.763 3.566 4.505 4.447 2.900 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 3 (score: 4.6, target_len: 4) [Top scores: 1:4.6 3:4.6 5:3.3 6:3.2 8:3.1 ]
ENG: <sos> i love you <eos>
ESP: <sos> me <eos>
---