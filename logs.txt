Se truncaron las últimas líneas 5000 del resultado de transmisión.
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0045)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0060, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0135
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[EMBEDDING] Updating weights for 49 tokens with lr=0.0045
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00450000
[UPDATE] Gradientes aplicados con lr=0.00450000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.092 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.300, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.300
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.645927
[DECODER] After pos encoding: 1024/1024 non-zero, sum=2.722445
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.610 0.181 0.286 0.047 -1.163 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.088, 2.977]
[DEBUG] Output sample values: -0.286 -0.834 -0.453 0.450 -0.435 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.088, 2.977] Var:0.661
[LOSS] Calculated loss: 7.358
 Loss: 7.358 (LR: 0.0045)[LOSS] Gradient sum: 1.9984
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1248
[LINEAR] Output projection - using 3x learning rate: 0.0135
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[EMBEDDING] Updating weights for 8 tokens with lr=0.0045
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0026, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00450000
[UPDATE] Gradientes aplicados con lr=0.00450000 [Updated]
  Promedio de loss: 7.179

Época 12/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.825 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.533, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.533
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.596004
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.779663
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.353 -0.131 -0.277 -0.270 -0.817 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.014, 2.814]
[DEBUG] Output sample values: -0.077 -1.353 0.147 0.499 -0.919 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.014, 2.814] Var:0.669
[LOSS] Calculated loss: 7.275
 Loss: 7.275 (LR: 0.0045)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0056, bias: 0.1110
[LINEAR] Output projection - using 3x learning rate: 0.0135
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[EMBEDDING] Updating weights for 9 tokens with lr=0.0045
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0960, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00450000
[UPDATE] Gradientes aplicados con lr=0.00450000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000012
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.758 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-6.012, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-6.012
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-68.020981
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-10.204635
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.368 -0.323 -0.083 -0.787 -0.837 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.633, 3.088]
[DEBUG] Output sample values: -0.234 -1.251 0.284 0.741 -0.443 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.633, 3.088] Var:0.677
[LOSS] Calculated loss: 7.155
 Loss: 7.155 (LR: 0.0045)[LOSS] Gradient sum: 1.9980
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0126, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0135
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[ATTENTION] Weights updated with lr=0.0045
[FEEDFORWARD] Weights updated with lr=0.0045
[EMBEDDING] Updating weights for 9 tokens with lr=0.0045
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0944, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00450000
[UPDATE] Gradientes aplicados con lr=0.00450000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.358 -1.478 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-16.079, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-16.079
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-181.908630
[DECODER] After pos encoding: 6272/6272 non-zero, sum=138.671463
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0061, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.092 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.298, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.298
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.626835
[DECODER] After pos encoding: 1024/1024 non-zero, sum=2.741526
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.611 0.181 0.294 0.047 -1.161 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.088, 2.976]
[DEBUG] Output sample values: -0.287 -0.819 -0.448 0.456 -0.435 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.088, 2.976] Var:0.661
[LOSS] Calculated loss: 7.354
[TRAINER] Loss stagnant (improvement: 0.007), boosting LR to 0.015
 Loss: 7.354 (LR: 0.0150)[LOSS] Gradient sum: 1.9984
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1248
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0026, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.173

Época 13/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.825 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.530, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.530
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.567631
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.751171
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.355 -0.132 -0.263 -0.269 -0.815 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.014, 2.812]
[DEBUG] Output sample values: -0.079 -1.336 0.157 0.510 -0.918 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.014, 2.812] Var:0.669
[LOSS] Calculated loss: 7.269
 Loss: 7.269 (LR: 0.0050)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0055, bias: 0.1110
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 9 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0960, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.758 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-6.009, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-6.009
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-67.988754
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-10.172363
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.368 -0.325 -0.068 -0.787 -0.834 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.633, 3.087]
[DEBUG] Output sample values: -0.235 -1.233 0.295 0.752 -0.442 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.633, 3.087] Var:0.677
[LOSS] Calculated loss: 7.143
[TRAINER] Loss stagnant (improvement: 0.005), boosting LR to 0.015
 Loss: 7.143 (LR: 0.0150)[LOSS] Gradient sum: 1.9979
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0133, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 9 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0944, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.358 -1.478 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-16.063, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-16.063
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-181.735474
[DECODER] After pos encoding: 6272/6272 non-zero, sum=138.843933
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0054, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.091 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.295, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.295
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.588795
[DECODER] After pos encoding: 1024/1024 non-zero, sum=2.779611
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.612 0.179 0.313 0.048 -1.159 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.088, 2.975]
[DEBUG] Output sample values: -0.290 -0.788 -0.435 0.470 -0.435 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.088, 2.975] Var:0.660
[LOSS] Calculated loss: 7.341
[TRAINER] Loss stagnant (improvement: 0.007), boosting LR to 0.015
 Loss: 7.341 (LR: 0.0150)[LOSS] Gradient sum: 1.9984
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0063, bias: 0.1248
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0026, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.165

Época 14/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.825 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.526, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.526
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.520332
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.703868
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.358 -0.134 -0.244 -0.269 -0.812 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.015, 2.809]
[DEBUG] Output sample values: -0.082 -1.301 0.171 0.524 -0.918 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.015, 2.809] Var:0.669
[LOSS] Calculated loss: 7.261
 Loss: 7.261 (LR: 0.0050)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0055, bias: 0.1110
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 9 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0959, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.758 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-6.004, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-6.004
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-67.932159
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-10.115736
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.369 -0.328 -0.048 -0.787 -0.832 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.633, 3.087]
[DEBUG] Output sample values: -0.237 -1.197 0.306 0.766 -0.442 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.633, 3.087] Var:0.677
[LOSS] Calculated loss: 7.124
[TRAINER] Loss stagnant (improvement: 0.010), boosting LR to 0.015
 Loss: 7.124 (LR: 0.0150)[LOSS] Gradient sum: 1.9979
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0132, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 9 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0944, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.358 -1.478 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-16.048, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-16.048
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-181.562683
[DECODER] After pos encoding: 6272/6272 non-zero, sum=139.016510
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0055, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.091 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.291, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.291
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.550652
[DECODER] After pos encoding: 1024/1024 non-zero, sum=2.817685
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000015
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.614 0.177 0.332 0.048 -1.157 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.087, 2.974]
[DEBUG] Output sample values: -0.293 -0.754 -0.420 0.485 -0.434 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.087, 2.974] Var:0.660
[LOSS] Calculated loss: 7.329
[TRAINER] Loss stagnant (improvement: 0.010), boosting LR to 0.015
 Loss: 7.329 (LR: 0.0150)[LOSS] Gradient sum: 1.9983
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1248
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0026, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.155

Época 15/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.825 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.522, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.522
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.473053
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.656598
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.360 -0.136 -0.224 -0.268 -0.809 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.015, 2.805]
[DEBUG] Output sample values: -0.085 -1.264 0.189 0.540 -0.917 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.015, 2.805] Var:0.669
[LOSS] Calculated loss: 7.252
 Loss: 7.252 (LR: 0.0050)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0056, bias: 0.1110
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 9 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0959, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.757 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.999, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.999
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-67.875595
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-10.059137
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.370 -0.332 -0.027 -0.786 -0.829 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.632, 3.086]
[DEBUG] Output sample values: -0.238 -1.160 0.324 0.780 -0.442 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.632, 3.086] Var:0.677
[LOSS] Calculated loss: 7.104
[TRAINER] Loss stagnant (improvement: 0.010), boosting LR to 0.015
 Loss: 7.104 (LR: 0.0150)[LOSS] Gradient sum: 1.9979
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0135, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 9 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0944, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.358 -1.477 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-16.033, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-16.033
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-181.391144
[DECODER] After pos encoding: 6272/6272 non-zero, sum=139.189133
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0053, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.091 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.288, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.288
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.512585
[DECODER] After pos encoding: 1024/1024 non-zero, sum=2.855772
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.615 0.176 0.351 0.048 -1.154 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.087, 2.973]
[DEBUG] Output sample values: -0.296 -0.720 -0.407 0.500 -0.434 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.087, 2.973] Var:0.660
[LOSS] Calculated loss: 7.317
[TRAINER] Loss stagnant (improvement: 0.010), boosting LR to 0.015
 Loss: 7.317 (LR: 0.0150)[LOSS] Gradient sum: 1.9983
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1248
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0026, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.145
  === Progreso en época 15 ===
[DEBUG] Forward - source: 10 tokens, target: 1 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-1.856, range=[-0.143, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-1.856
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-20.999424
[DECODER] After pos encoding: 128/128 non-zero, sum=-14.599422
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.959 -0.124 0.055 0.094 -0.955 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.638, 2.954]
[DEBUG] Output sample values: -0.326 -0.812 -0.035 0.600 -0.931 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 25 (score: 2.4, target_len: 9) [Top scores: 819:3.0 158:2.8 25:2.4 258:2.3 112:2.3 ]
[DEBUG] Forward - source: 10 tokens, target: 2 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-2.454, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-2.454
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-27.758286
[DECODER] After pos encoding: 256/256 non-zero, sum=-14.952266
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.853 -0.135 0.093 0.131 -0.910 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.727, 2.866]
[DEBUG] Output sample values: -0.241 -0.890 0.029 0.566 -0.957 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 819 (score: 2.5, target_len: 9) [Top scores: 819:2.5 158:2.3 401:2.3 654:2.2 474:2.2 ]
[DEBUG] Forward - source: 10 tokens, target: 3 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-2.151, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-2.151
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-24.340082
[DECODER] After pos encoding: 384/384 non-zero, sum=-5.122025
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.726 -0.020 -0.023 0.117 -0.956 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.833, 2.905]
[DEBUG] Output sample values: -0.196 -0.989 0.050 0.608 -1.055 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 654 (score: 2.4, target_len: 9) [Top scores: 654:2.4 157:2.2 528:2.1 446:2.0 769:2.0 ]
[DEBUG] Forward - source: 10 tokens, target: 4 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.340, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-2.340
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-26.472387
[DECODER] After pos encoding: 512/512 non-zero, sum=-0.836270
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.669 -0.195 0.054 0.012 -0.898 
[DEBUG] Output projection - shape: 4x1000
[DEBUG] Output range: [-2.800, 2.842]
[DEBUG] Output sample values: -0.211 -0.949 0.011 0.571 -0.915 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 5 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.930, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-2.930
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-33.153141
[DECODER] After pos encoding: 640/640 non-zero, sum=-1.092966
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.567 -0.208 0.133 -0.107 -0.794 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.751, 2.783]
[DEBUG] Output sample values: -0.273 -1.143 0.179 0.624 -1.000 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 6 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.158, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-1.158
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-13.104478
[DECODER] After pos encoding: 768/768 non-zero, sum=25.385775
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.579 -0.171 0.064 -0.106 -0.779 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] Output range: [-2.689, 2.832]
[DEBUG] Output sample values: -0.268 -1.161 0.202 0.582 -0.931 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 7 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.856, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.856
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-9.686283
[DECODER] After pos encoding: 896/896 non-zero, sum=35.240025
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.490 -0.277 -0.056 -0.198 -0.818 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-2.613, 2.778]
[DEBUG] Output sample values: -0.163 -1.123 0.201 0.543 -0.895 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 8 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.045, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.045
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.818586
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.549767
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.374 -0.205 -0.162 -0.222 -0.802 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-2.652, 2.798]
[DEBUG] Output sample values: -0.096 -1.213 0.222 0.549 -0.944 
[DEBUG] Forward completed!
  ENG: <sos> how much have you paid for this computer <eos>
  ESP: <sos> m esperanto ximo estaban ndose esperanto ximo domingo
  ================================

Época 16/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.518, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.518
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.425705
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.609322
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.363 -0.138 -0.205 -0.268 -0.806 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.015, 2.802]
[DEBUG] Output sample values: -0.089 -1.229 0.204 0.553 -0.917 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.015, 2.802] Var:0.669
[LOSS] Calculated loss: 7.244
 Loss: 7.244 (LR: 0.0050)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0056, bias: 0.1110
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 9 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0959, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.757 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.994, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.994
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-67.818954
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-10.002537
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.370 -0.335 -0.007 -0.786 -0.826 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.632, 3.085]
[DEBUG] Output sample values: -0.240 -1.126 0.340 0.794 -0.442 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.632, 3.085] Var:0.677
[LOSS] Calculated loss: 7.088
[TRAINER] Loss stagnant (improvement: 0.009), boosting LR to 0.015
 Loss: 7.088 (LR: 0.0150)[LOSS] Gradient sum: 1.9979
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0140, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 9 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0944, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.359 -1.477 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-16.018, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-16.018
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-181.218124
[DECODER] After pos encoding: 6272/6272 non-zero, sum=139.361572
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0064, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.091 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.285, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.285
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.474541
[DECODER] After pos encoding: 1024/1024 non-zero, sum=2.893848
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.616 0.174 0.370 0.049 -1.151 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.087, 2.972]
[DEBUG] Output sample values: -0.299 -0.687 -0.392 0.514 -0.434 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.087, 2.972] Var:0.660
[LOSS] Calculated loss: 7.305
[TRAINER] Loss stagnant (improvement: 0.009), boosting LR to 0.015
 Loss: 7.305 (LR: 0.0150)[LOSS] Gradient sum: 1.9983
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1248
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0027, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.136

Época 17/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.514, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.514
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.378483
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.562024
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.366 -0.140 -0.186 -0.268 -0.803 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.015, 2.799]
[DEBUG] Output sample values: -0.092 -1.195 0.214 0.567 -0.916 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.015, 2.799] Var:0.669
[LOSS] Calculated loss: 7.236
 Loss: 7.236 (LR: 0.0050)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0056, bias: 0.1110
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 9 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0959, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.757 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.989
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-67.762291
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-9.945896
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.371 -0.338 0.013 -0.786 -0.824 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.632, 3.084]
[DEBUG] Output sample values: -0.242 -1.095 0.348 0.807 -0.442 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.632, 3.084] Var:0.677
[LOSS] Calculated loss: 7.070
[TRAINER] Loss stagnant (improvement: 0.009), boosting LR to 0.015
 Loss: 7.070 (LR: 0.0150)[LOSS] Gradient sum: 1.9978
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0150, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 9 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0943, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.359 -1.477 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-16.002, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-16.002
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-181.045380
[DECODER] After pos encoding: 6272/6272 non-zero, sum=139.534134
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0056, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.091 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.281, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.281
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.436462
[DECODER] After pos encoding: 1024/1024 non-zero, sum=2.931924
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000013
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.618 0.173 0.389 0.049 -1.149 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.087, 2.971]
[DEBUG] Output sample values: -0.302 -0.651 -0.382 0.526 -0.434 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.087, 2.971] Var:0.660
[LOSS] Calculated loss: 7.294
[TRAINER] Loss stagnant (improvement: 0.010), boosting LR to 0.015
 Loss: 7.294 (LR: 0.0150)[LOSS] Gradient sum: 1.9983
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1248
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0027, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.127

Época 18/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000020
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.815 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.509, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.509
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.331177
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.514760
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.368 -0.142 -0.166 -0.267 -0.800 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.015, 2.795]
[DEBUG] Output sample values: -0.095 -1.163 0.229 0.580 -0.916 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.015, 2.795] Var:0.669
[LOSS] Calculated loss: 7.229
 Loss: 7.229 (LR: 0.0050)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0055, bias: 0.1109
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 9 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0959, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.757 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.984, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.984
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-67.705719
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-9.889318
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.372 -0.341 0.033 -0.785 -0.821 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.631, 3.083]
[DEBUG] Output sample values: -0.243 -1.065 0.361 0.820 -0.441 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.631, 3.083] Var:0.677
[LOSS] Calculated loss: 7.053
[TRAINER] Loss stagnant (improvement: 0.009), boosting LR to 0.015
 Loss: 7.053 (LR: 0.0150)[LOSS] Gradient sum: 1.9978
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0152, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 9 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0943, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.359 -1.477 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-15.987, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-15.987
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-180.872742
[DECODER] After pos encoding: 6272/6272 non-zero, sum=139.706696
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0064, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.091 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.278, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.278
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.398373
[DECODER] After pos encoding: 1024/1024 non-zero, sum=2.969980
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000014
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.619 0.171 0.409 0.049 -1.146 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.087, 2.970]
[DEBUG] Output sample values: -0.305 -0.612 -0.367 0.541 -0.433 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.087, 2.970] Var:0.660
[LOSS] Calculated loss: 7.282
[TRAINER] Loss stagnant (improvement: 0.009), boosting LR to 0.015
 Loss: 7.282 (LR: 0.0150)[LOSS] Gradient sum: 1.9983
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1248
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0027, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.118

Época 19/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.225 -0.824 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.505, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.505
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.283875
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.467481
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.371 -0.144 -0.147 -0.267 -0.797 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.015, 2.791]
[DEBUG] Output sample values: -0.098 -1.126 0.243 0.594 -0.915 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.015, 2.791] Var:0.669
[LOSS] Calculated loss: 7.221
 Loss: 7.221 (LR: 0.0050)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0055, bias: 0.1109
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 9 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0959, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.757 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.979, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.979
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-67.649162
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-9.832720
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.373 -0.344 0.054 -0.785 -0.818 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.631, 3.082]
[DEBUG] Output sample values: -0.245 -1.031 0.373 0.834 -0.441 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.631, 3.082] Var:0.677
[LOSS] Calculated loss: 7.038
[TRAINER] Loss stagnant (improvement: 0.008), boosting LR to 0.015
 Loss: 7.038 (LR: 0.0150)[LOSS] Gradient sum: 1.9978
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0150, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 9 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0943, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.359 -1.477 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-15.972, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-15.972
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-180.700150
[DECODER] After pos encoding: 6272/6272 non-zero, sum=139.879227
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0051, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.091 0.422 -0.936 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.274, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.274
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.360394
[DECODER] After pos encoding: 1024/1024 non-zero, sum=3.008040
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.621 0.169 0.428 0.050 -1.144 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.086, 2.969]
[DEBUG] Output sample values: -0.308 -0.580 -0.356 0.555 -0.433 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.086, 2.969] Var:0.660
[LOSS] Calculated loss: 7.272
[TRAINER] Loss stagnant (improvement: 0.008), boosting LR to 0.015
 Loss: 7.272 (LR: 0.0150)[LOSS] Gradient sum: 1.9983
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1247
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0027, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.110

Época 20/20
  Procesando 4 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/4: [DEBUG] Forward - source: 10 tokens, target: 9 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.501, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.501
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-62.236710
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-4.420241
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -0.374 -0.146 -0.127 -0.266 -0.794 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.015, 2.788]
[DEBUG] Output sample values: -0.101 -1.097 0.261 0.605 -0.914 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.015, 2.788] Var:0.669
[LOSS] Calculated loss: 7.214
 Loss: 7.214 (LR: 0.0050)[LOSS] Gradient sum: 1.9981
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0056, bias: 0.1109
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 9 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0958, range=[-0.1110, 0.0013]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 2/4: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-3.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-3.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-38.733639
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=19.082806
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -1.380 -0.387 -0.341 -0.124 -0.757 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-5.974, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-5.974
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-67.592529
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-9.776114
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: -1.374 -0.347 0.074 -0.785 -0.815 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.630, 3.082]
[DEBUG] Output sample values: -0.246 -1.002 0.390 0.844 -0.440 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.630, 3.082] Var:0.677
[LOSS] Calculated loss: 7.021
[TRAINER] Loss stagnant (improvement: 0.009), boosting LR to 0.015
 Loss: 7.021 (LR: 0.0150)[LOSS] Gradient sum: 1.9978
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0133, bias: 0.3331
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 9 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0943, range=[-0.1110, 0.0017]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
    Muestra 3/4: [DEBUG] Forward - source: 34 tokens, target: 49 tokens
[ENCODER] Starting encode with 34 tokens
[EMBEDDING] Forward pass - seq_len=34, d_model=128
[EMBEDDING] 4352/4352 non-zero, sum=-14.951, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 4352/4352 non-zero, sum=-14.951
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4288/4352 non-zero, sum=220.945572
[ENCODER] SCALED EMBEDS before add: 4352/4352 non-zero, sum=-169.152206
[ENCODER] After pos encoding: 4352/4352 non-zero, sum=51.793434
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 0 output: 4352/4352 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4352/4352 non-zero
[ENCODER_LAYER] After self-attention: 4352/4352 non-zero
[ENCODER_LAYER] After norm1: 4352/4352 non-zero
[ENCODER_LAYER] After feedforward: 4352/4352 non-zero
[ENCODER_LAYER] Final output: 4352/4352 non-zero
[ENCODER] Layer 1 output: 4352/4352 non-zero, sum=-0.000024
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 34x128
[DEBUG] Encoder sample values: -0.962 -0.665 -0.924 -0.359 -1.477 
[DECODER] Starting decode with 49 tokens
[EMBEDDING] Forward pass - seq_len=49, d_model=128
[EMBEDDING] 6272/6272 non-zero, sum=-15.957, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 6272/6272 non-zero, sum=-15.957
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 6208/6272 non-zero, sum=320.579620
[DECODER] SCALED EMBEDS before add: 6272/6272 non-zero, sum=-180.528259
[DECODER] After pos encoding: 6272/6272 non-zero, sum=140.051544
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/6272 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 49x128
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] Output projection - shape: 49x1000
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [0.000, 0.000] Var:0.000
[LOSS] Calculated loss: 6.908
 Loss: 6.908 (LR: 0.0050)[LOSS] Gradient sum: 1.9972
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0055, bias: 0.2847
[LINEAR] Output projection - using 3x learning rate: 0.0150
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[ATTENTION] Weights updated with lr=0.0050
[FEEDFORWARD] Weights updated with lr=0.0050
[EMBEDDING] Updating weights for 49 tokens with lr=0.0050
[EMBEDDING] Gradient stats: 6272/6272 non-zero, sum=-0.0149, range=[-0.0204, 0.0000]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 49 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00500000
[UPDATE] Gradientes aplicados con lr=0.00500000 [Updated]
    Muestra 4/4: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.660, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.660
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-18.777218
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=32.591156
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.515 -0.085 -0.091 0.422 -0.935 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.271, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-4.271
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-48.322281
[DECODER] After pos encoding: 1024/1024 non-zero, sum=3.046101
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -1.622 0.168 0.447 0.050 -1.141 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-3.086, 2.968]
[DEBUG] Output sample values: -0.311 -0.544 -0.341 0.566 -0.432 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.086, 2.968] Var:0.660
[LOSS] Calculated loss: 7.260
[TRAINER] Loss stagnant (improvement: 0.009), boosting LR to 0.015
 Loss: 7.260 (LR: 0.0150)[LOSS] Gradient sum: 1.9982
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0062, bias: 0.1247
[LINEAR] Output projection - using 3x learning rate: 0.0450
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[ATTENTION] Weights updated with lr=0.0150
[FEEDFORWARD] Weights updated with lr=0.0150
[EMBEDDING] Updating weights for 8 tokens with lr=0.0150
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=0.0027, range=[-0.1249, 0.0016]
[EMBEDDING] Sample weights after update: 0.05804484 -0.08865473 -0.00225818 0.05471970 0.01606741 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01500000
[UPDATE] Gradientes aplicados con lr=0.01500000 [Updated]
  Promedio de loss: 7.101
  === Progreso en época 20 ===
[DEBUG] Forward - source: 10 tokens, target: 1 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-1.838, range=[-0.143, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-1.838
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-20.789499
[DECODER] After pos encoding: 128/128 non-zero, sum=-14.389491
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.969 -0.128 0.113 0.097 -0.945 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.649, 2.943]
[DEBUG] Output sample values: -0.336 -0.638 0.039 0.667 -0.928 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 158 (score: 2.8, target_len: 9) [Top scores: 819:2.9 158:2.8 25:2.4 258:2.3 112:2.3 ]
[DEBUG] Forward - source: 10 tokens, target: 2 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.631, range=[-0.143, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.631
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-7.135056
[DECODER] After pos encoding: 256/256 non-zero, sum=5.670977
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.861 -0.139 0.155 0.135 -0.900 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.759, 2.854]
[DEBUG] Output sample values: -0.250 -0.718 0.102 0.632 -0.954 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 299 (score: 2.6, target_len: 9) [Top scores: 299:2.6 113:2.3 986:2.2 752:2.1 728:2.0 ]
[DEBUG] Forward - source: 10 tokens, target: 3 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.148, range=[-0.144, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=0.148
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=1.679137
[DECODER] After pos encoding: 384/384 non-zero, sum=20.897213
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.737 -0.026 0.045 0.121 -0.945 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.829, 2.892]
[DEBUG] Output sample values: -0.207 -0.815 0.123 0.673 -1.051 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 819 (score: 2.3, target_len: 9) [Top scores: 819:2.3 884:2.2 647:2.1 572:2.0 935:2.0 ]
[DEBUG] Forward - source: 10 tokens, target: 4 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.451, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=0.451
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=5.097335
[DECODER] After pos encoding: 512/512 non-zero, sum=30.733463
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.680 -0.204 0.129 0.014 -0.886 
[DEBUG] Output projection - shape: 4x1000
[DEBUG] Output range: [-2.885, 2.827]
[DEBUG] Output sample values: -0.221 -0.775 0.083 0.635 -0.909 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 5 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.077, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.077
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=12.181107
[DECODER] After pos encoding: 640/640 non-zero, sum=44.241306
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -0.575 -0.216 0.212 -0.108 -0.779 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.941, 2.856]
[DEBUG] Output sample values: -0.284 -0.974 0.253 0.690 -0.996 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 6 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.724, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.724
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=8.193382
[DECODER] After pos encoding: 768/768 non-zero, sum=46.683643
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -0.587 -0.180 0.146 -0.107 -0.764 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] Output range: [-2.978, 2.814]
[DEBUG] Output sample values: -0.280 -0.991 0.275 0.648 -0.928 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 7 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.478, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.478
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=5.404588
[DECODER] After pos encoding: 896/896 non-zero, sum=50.330925
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.500 -0.284 0.033 -0.197 -0.803 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-2.822, 2.761]
[DEBUG] Output sample values: -0.176 -0.954 0.273 0.609 -0.893 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 8 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-5.989, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-5.989
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-67.758057
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=-3.487622
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -0.816 -0.167 -0.582 0.224 -0.824 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.451, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.451
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=5.098721
[DECODER] After pos encoding: 1024/1024 non-zero, sum=56.467098
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.388 -0.214 -0.068 -0.221 -0.788 
[DEBUG] Output projection - shape: 8x1000
[DEBUG] Output range: [-2.909, 2.781]
[DEBUG] Output sample values: -0.111 -1.042 0.293 0.615 -0.941 
[DEBUG] Forward completed!
  ENG: <sos> how much have you paid for this computer <eos>
  ESP: <sos> p vivir esperanto an perd ninguna lares culo
  ================================

¡Entrenamiento completado!

=== Pruebas de Traducción ===
[DEBUG] Forward - source: 3 tokens, target: 1 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-2.637, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-2.637
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-29.836670
[ENCODER] After pos encoding: 384/384 non-zero, sum=-10.618626
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: -1.485 -0.240 -0.275 0.391 -1.016 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-1.838, range=[-0.143, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-1.838
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-20.789499
[DECODER] After pos encoding: 128/128 non-zero, sum=-14.389491
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.440 -0.131 0.290 0.190 -1.122 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.626, 2.908]
[DEBUG] Output sample values: -0.416 -0.361 -0.006 0.604 -0.887 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 819 (score: 2.9, target_len: 2) [Top scores: 158:2.9 819:2.9 45:2.3 25:2.3 258:2.2 ]
[DEBUG] Forward - source: 3 tokens, target: 2 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-2.637, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-2.637
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-29.836670
[ENCODER] After pos encoding: 384/384 non-zero, sum=-10.618626
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: -1.485 -0.240 -0.275 0.391 -1.016 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.535, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.535
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-17.371294
[DECODER] After pos encoding: 256/256 non-zero, sum=-4.565272
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -1.410 -0.177 0.285 0.150 -1.166 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.799, 2.911]
[DEBUG] Output sample values: -0.390 -0.369 0.026 0.577 -0.913 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 3 (score: 5.5, target_len: 2) [Top scores: 3:5.5 45:2.7 158:2.4 769:2.2 25:2.2 ]
ENG: <sos> hello <eos>
ESP: <sos> esperanto <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.585, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-1.585
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-17.935364
[ENCODER] After pos encoding: 640/640 non-zero, sum=14.124835
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.400 -0.445 0.107 0.411 -0.966 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-1.838, range=[-0.143, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-1.838
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-20.789499
[DECODER] After pos encoding: 128/128 non-zero, sum=-14.389491
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.384 -0.336 0.586 0.181 -1.052 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.580, 2.929]
[DEBUG] Output sample values: -0.440 -0.535 -0.107 0.672 -0.983 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 819 (score: 2.9, target_len: 4) [Top scores: 819:2.9 158:2.7 25:2.3 45:2.2 258:2.1 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.585, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-1.585
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-17.935364
[ENCODER] After pos encoding: 640/640 non-zero, sum=14.124835
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.400 -0.445 0.107 0.411 -0.966 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.535, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.535
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-17.371294
[DECODER] After pos encoding: 256/256 non-zero, sum=-4.565272
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -1.279 -0.338 0.616 0.218 -1.005 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.877, 2.843]
[DEBUG] Output sample values: -0.354 -0.617 -0.037 0.636 -1.018 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 157 (score: 2.3, target_len: 4) [Top scores: 654:2.4 157:2.3 624:2.2 769:2.2 782:2.2 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.585, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-1.585
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-17.935364
[ENCODER] After pos encoding: 640/640 non-zero, sum=14.124835
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.400 -0.445 0.107 0.411 -0.966 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.909, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.909
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-10.287519
[DECODER] After pos encoding: 384/384 non-zero, sum=8.930536
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -1.341 -0.498 0.776 0.194 -1.065 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.896, 2.882]
[DEBUG] Output sample values: -0.336 -0.576 -0.264 0.668 -1.009 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 654 (score: 2.4, target_len: 4) [Top scores: 654:2.4 158:2.2 537:2.1 925:2.1 622:2.0 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.585, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-1.585
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-17.935364
[ENCODER] After pos encoding: 640/640 non-zero, sum=14.124835
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.400 -0.445 0.107 0.411 -0.966 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.098, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-1.098
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-12.419823
[DECODER] After pos encoding: 512/512 non-zero, sum=13.216285
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -1.245 -0.508 0.859 0.079 -0.967 
[DEBUG] Output projection - shape: 4x1000
[DEBUG] Output range: [-2.886, 2.826]
[DEBUG] Output sample values: -0.403 -0.772 -0.091 0.716 -1.082 
[DEBUG] Forward completed!
ENG: <sos> how are you <eos>
ESP: <sos> esperanto an ximo <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.413, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.413
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-27.294376
[ENCODER] After pos encoding: 512/512 non-zero, sum=-1.658269
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.458 -0.124 -0.405 0.303 -1.054 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-1.838, range=[-0.143, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-1.838
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-20.789499
[DECODER] After pos encoding: 128/128 non-zero, sum=-14.389491
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.441 -0.025 0.178 0.174 -1.174 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.552, 3.032]
[DEBUG] Output sample values: -0.337 -0.327 -0.067 0.604 -0.965 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 45 (score: 2.3, target_len: 3) [Top scores: 158:3.0 819:2.8 45:2.3 258:2.2 25:2.1 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.413, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.413
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-27.294376
[ENCODER] After pos encoding: 512/512 non-zero, sum=-1.658269
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.458 -0.124 -0.405 0.303 -1.054 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.248, range=[-0.144, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.248
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-14.124547
[DECODER] After pos encoding: 256/256 non-zero, sum=-1.318513
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -1.435 0.020 0.118 0.115 -1.206 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.513, 3.083]
[DEBUG] Output sample values: -0.263 -0.339 -0.065 0.595 -0.991 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 512 (score: 2.7, target_len: 3) [Top scores: 512:2.7 281:2.6 192:2.4 158:2.4 421:2.3 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.413, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.413
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-27.294376
[ENCODER] After pos encoding: 512/512 non-zero, sum=-1.658269
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.458 -0.124 -0.405 0.303 -1.054 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.333, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-1.333
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-15.084477
[DECODER] After pos encoding: 384/384 non-zero, sum=4.133595
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -1.371 0.032 0.038 0.035 -1.292 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.510, 3.158]
[DEBUG] Output sample values: -0.186 -0.331 -0.077 0.550 -1.034 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 3 (score: 5.2, target_len: 3) [Top scores: 3:5.2 158:2.8 819:2.7 25:2.4 113:2.2 ]
ENG: <sos> good morning <eos>
ESP: <sos> este cuanto <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.160, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.160
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-24.440643
[ENCODER] After pos encoding: 512/512 non-zero, sum=1.195479
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.402 -0.079 -0.058 0.359 -0.866 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-1.838, range=[-0.143, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-1.838
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-20.789499
[DECODER] After pos encoding: 128/128 non-zero, sum=-14.389491
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.393 -0.056 0.438 0.131 -0.982 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.626, 2.859]
[DEBUG] Output sample values: -0.513 -0.609 0.071 0.751 -0.985 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 819 (score: 2.9, target_len: 3) [Top scores: 819:2.9 158:2.8 25:2.2 258:2.2 45:2.2 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.160, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.160
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-24.440643
[ENCODER] After pos encoding: 512/512 non-zero, sum=1.195479
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.402 -0.079 -0.058 0.359 -0.866 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.535, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.535
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-17.371294
[DECODER] After pos encoding: 256/256 non-zero, sum=-4.565272
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -1.377 0.055 0.479 0.045 -0.928 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.541, 2.832]
[DEBUG] Output sample values: -0.497 -0.757 0.110 0.853 -1.033 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 158 (score: 2.3, target_len: 3) [Top scores: 158:2.3 25:2.3 401:2.2 697:2.2 366:2.1 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.160, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.160
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-24.440643
[ENCODER] After pos encoding: 512/512 non-zero, sum=1.195479
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.402 -0.079 -0.058 0.359 -0.866 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.329, range=[-0.145, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.329
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-3.716848
[DECODER] After pos encoding: 384/384 non-zero, sum=15.501226
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -1.289 0.005 0.604 -0.092 -0.820 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.826, 2.780]
[DEBUG] Output sample values: -0.591 -0.963 0.285 0.927 -1.124 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 3 (score: 6.3, target_len: 3) [Top scores: 3:6.3 160:2.5 690:2.3 645:2.2 986:2.1 ]
ENG: <sos> thank you <eos>
ESP: <sos> esperanto p <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.111, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.111
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-23.886070
[ENCODER] After pos encoding: 640/640 non-zero, sum=8.174117
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.397 -0.146 0.020 0.274 -0.800 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-1.838, range=[-0.143, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-1.838
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-20.789499
[DECODER] After pos encoding: 128/128 non-zero, sum=-14.389491
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.404 -0.115 0.530 0.098 -0.947 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.760, 2.897]
[DEBUG] Output sample values: -0.573 -0.506 0.025 0.667 -0.922 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 819 (score: 2.8, target_len: 4) [Top scores: 158:2.9 819:2.8 25:2.3 45:2.2 258:2.1 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.111, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.111
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-23.886070
[ENCODER] After pos encoding: 640/640 non-zero, sum=8.174117
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.397 -0.146 0.020 0.274 -0.800 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.535, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.535
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-17.371294
[DECODER] After pos encoding: 256/256 non-zero, sum=-4.565272
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -1.203 -0.012 0.581 -0.070 -0.846 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-3.078, 2.946]
[DEBUG] Output sample values: -0.701 -0.410 -0.009 0.674 -0.963 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 45 (score: 2.3, target_len: 4) [Top scores: 158:2.5 25:2.4 45:2.3 697:2.1 401:2.1 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.111, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.111
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-23.886070
[ENCODER] After pos encoding: 640/640 non-zero, sum=8.174117
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.397 -0.146 0.020 0.274 -0.800 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.946, range=[-0.145, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.946
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-10.706342
[DECODER] After pos encoding: 384/384 non-zero, sum=8.511731
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -1.384 -0.106 0.675 -0.091 -0.855 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.904, 2.935]
[DEBUG] Output sample values: -0.610 -0.537 -0.002 0.710 -0.884 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 512 (score: 2.5, target_len: 4) [Top scores: 512:2.5 158:2.4 131:2.2 308:2.1 483:1.9 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.111, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.111
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-23.886070
[ENCODER] After pos encoding: 640/640 non-zero, sum=8.174117
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.397 -0.146 0.020 0.274 -0.800 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.031, range=[-0.146, 0.145]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-1.031
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-11.666274
[DECODER] After pos encoding: 512/512 non-zero, sum=13.969852
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -1.316 -0.146 0.788 -0.195 -0.771 
[DEBUG] Output projection - shape: 4x1000
[DEBUG] Output range: [-2.877, 2.957]
[DEBUG] Output sample values: -0.681 -0.738 0.144 0.777 -0.964 
[DEBUG] Forward completed!
ENG: <sos> i love you <eos>
ESP: <sos> esperanto este cuanto <eos>
---