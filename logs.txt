Se truncaron las últimas líneas 5000 del resultado de transmisión.
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.895 -0.969 0.376 -1.505 -0.620 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.865, 4.597]
[DEBUG] Output sample values: 1.267 3.958 4.597 3.831 -0.938 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 5 (score: 4.1, target_len: 7) [Top scores: 5:4.1 1:4.0 2:2.6 757:2.3 17:2.3 ]
[DEBUG] Forward - source: 8 tokens, target: 2 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.018 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.556, range=[-0.146, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.556
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=6.289624
[DECODER] After pos encoding: 256/256 non-zero, sum=19.095650
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.992 -0.779 0.656 -1.417 -0.830 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.770, 4.567]
[DEBUG] Output sample values: 1.268 4.004 4.567 3.891 -1.088 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 1 (score: 4.2, target_len: 7) [Top scores: 1:4.2 23:2.1 37:2.0 460:2.0 986:2.0 ]
[DEBUG] Forward - source: 8 tokens, target: 3 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.018 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.145, range=[-0.146, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-1.145
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-12.952944
[DECODER] After pos encoding: 384/384 non-zero, sum=6.265129
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 1.084 -0.553 0.904 -1.292 -1.034 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.681, 4.512]
[DEBUG] Output sample values: 1.251 4.049 4.512 3.948 -1.220 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 986 (score: 3.4, target_len: 7) [Top scores: 986:3.4 15:2.5 1:2.4 23:2.4 37:2.2 ]
[DEBUG] Forward - source: 8 tokens, target: 4 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.018 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.832, range=[-0.146, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.832
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.408720
[DECODER] After pos encoding: 512/512 non-zero, sum=16.227417
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: 1.086 -0.483 1.002 -1.159 -0.949 
[DEBUG] Output projection - shape: 4x1000
[DEBUG] Output range: [-2.836, 4.435]
[DEBUG] Output sample values: 1.217 3.922 4.435 3.851 -1.179 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 8 tokens, target: 5 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.018 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.244, range=[-0.146, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-1.244
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-14.071568
[DECODER] After pos encoding: 640/640 non-zero, sum=17.988623
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 1.127 -0.640 1.152 -1.131 -0.706 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.652, 4.496]
[DEBUG] Output sample values: 1.117 3.995 4.387 3.608 -1.049 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.018 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.025, range=[-0.146, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-1.025
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-11.597013
[DECODER] After pos encoding: 768/768 non-zero, sum=26.893244
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 1.184 -0.482 1.288 -1.045 -0.861 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] Output range: [-2.638, 4.538]
[DEBUG] Output sample values: 1.105 4.038 4.360 3.674 -1.141 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.018 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.726, range=[-0.146, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-2.726
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-30.839584
[DECODER] After pos encoding: 896/896 non-zero, sum=14.086744
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000015
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 1.099 -0.387 1.403 -1.001 -0.919 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-2.667, 4.457]
[DEBUG] Output sample values: 1.097 3.973 4.251 3.671 -1.234 
[DEBUG] Forward completed!
  ENG: <sos> <unk> <unk> is a <unk> city <eos>
  ESP: <sos> de <unk> llegu d de <unk> llegu <eos>
  ================================

Época 46/50
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 8 tokens, target: 9 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.018 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.059, range=[-0.146, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.059
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-23.299290
[DECODER] After pos encoding: 1152/1152 non-zero, sum=34.517105
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 1.046 -0.562 1.967 -1.011 -0.715 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.014, 4.447]
[DEBUG] Output sample values: 0.964 3.734 4.267 3.751 -1.159 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.014, 4.447] Var:0.726
[LOSS] Calculated loss: 4.904
 [EOS penalty: 0.173] Loss: 5.077 (LR: 0.0200)[LOSS] Gradient sum: 1.7463
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0094, bias: 0.2661
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0725, range=[-0.0951, 0.0043]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.372, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-0.372
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-4.204902
[ENCODER] After pos encoding: 896/896 non-zero, sum=40.721413
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.833 -1.043 -1.462 -1.567 -0.673 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.150, range=[-0.146, 0.865]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.150
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-1.696972
[DECODER] After pos encoding: 896/896 non-zero, sum=43.229374
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.220 -0.567 2.486 -0.781 -0.775 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.270, 4.712]
[DEBUG] Output sample values: 0.840 3.973 4.376 4.026 -0.669 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.270, 4.712] Var:0.728
[LOSS] Calculated loss: 4.845
 [EOS penalty: 0.161] Loss: 5.006 (LR: 0.0180)[LOSS] Gradient sum: 1.7453
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0064, bias: 0.1280
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0107, range=[-0.1217, 0.0053]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.969, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.969
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=10.964435
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=81.694832
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000013
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 0.826 -1.152 -1.386 -1.560 -0.407 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.965, range=[-0.146, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.965
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=10.923249
[DECODER] After pos encoding: 1280/1280 non-zero, sum=75.193604
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.225 -0.041 3.687 -0.988 0.237 
[DEBUG] Output projection - shape: 10x1000
[DEBUG] Output range: [-3.147, 4.931]
[DEBUG] Output sample values: 0.154 3.053 4.627 2.633 -0.771 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.147, 4.931] Var:0.743
[LOSS] Calculated loss: 6.079
 [EOS penalty: 0.057] Loss: 6.136 (LR: 0.0180)[LOSS] Gradient sum: 1.7811
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0046, bias: 0.0896
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 10 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0581, range=[-0.0899, 0.0052]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 5 tokens, target: 7 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.208, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.208
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=13.662188
[ENCODER] After pos encoding: 640/640 non-zero, sum=45.722404
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.665 -1.287 -1.348 -1.709 -0.593 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.358, range=[-0.146, 0.869]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.358
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.051149
[DECODER] After pos encoding: 896/896 non-zero, sum=48.977489
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.299 -1.456 2.835 -1.384 -0.609 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.145, 4.917]
[DEBUG] Output sample values: 0.213 3.588 4.917 3.896 -0.450 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.145, 4.917] Var:0.742
[LOSS] Calculated loss: 4.967
 [EOS penalty: 0.188] Loss: 5.155 (LR: 0.0180)[LOSS] Gradient sum: 1.7479
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0067, bias: 0.1271
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0108, range=[-0.1169, 0.0042]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 5 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.673, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.673
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-30.240953
[ENCODER] After pos encoding: 640/640 non-zero, sum=1.819236
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.845 -1.052 -1.375 -1.788 -0.621 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.162, range=[-0.146, 0.871]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-2.162
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-24.459778
[DECODER] After pos encoding: 640/640 non-zero, sum=7.600424
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.538 -0.381 2.327 -1.610 -0.617 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.980, 4.673]
[DEBUG] Output sample values: 0.905 4.171 4.465 3.432 -0.669 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.980, 4.673] Var:0.739
[LOSS] Calculated loss: 4.445
 [EOS penalty: 0.067] Loss: 4.512 (LR: 0.0180)[LOSS] Gradient sum: 1.7307
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0090, bias: 0.1786
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0584, range=[-0.1694, 0.0079]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.300, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.300
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-14.709489
[ENCODER] After pos encoding: 896/896 non-zero, sum=30.216846
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.835 -1.198 -1.359 -1.653 -0.585 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.067, range=[-0.146, 0.874]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.067
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-23.385588
[DECODER] After pos encoding: 1152/1152 non-zero, sum=34.430748
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000014
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.209 -0.916 3.483 -0.932 -0.147 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.063, 4.864]
[DEBUG] Output sample values: 0.164 3.501 4.864 2.934 -1.025 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.063, 4.864] Var:0.728
[LOSS] Calculated loss: 5.804
 [EOS penalty: 0.060] Loss: 5.864 (LR: 0.0200)[LOSS] Gradient sum: 1.7704
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0050, bias: 0.0994
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0778, range=[-0.0999, 0.0044]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 11 tokens, target: 12 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.542, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.542
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=6.134801
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=76.865318
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 1.209 -1.152 -1.396 -1.651 -0.485 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.367, range=[-0.146, 0.876]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.367
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=4.157201
[DECODER] After pos encoding: 1536/1536 non-zero, sum=81.353691
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: 1.779 -0.562 3.652 -0.875 -0.101 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-2.690, 5.182]
[DEBUG] Output sample values: -0.001 4.062 4.830 3.153 -0.350 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.690, 5.182] Var:0.714
[LOSS] Calculated loss: 5.415
 [EOS penalty: 0.121] Loss: 5.535 (LR: 0.0200)[LOSS] Gradient sum: 1.7635
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0067, bias: 0.1312
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0298, range=[-0.0749, 0.0054]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.832, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-2.832
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-32.043373
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=25.773064
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 1.006 -0.990 -1.477 -1.568 -0.628 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-10.074, range=[-0.146, 0.877]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-10.074
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-113.974625
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-56.158192
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.619 -0.043 3.035 -0.966 -0.523 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.835, 4.744]
[DEBUG] Output sample values: 0.002 3.618 4.744 3.499 -1.206 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.835, 4.744] Var:0.749
[LOSS] Calculated loss: 4.815
 [EOS penalty: 0.101] Loss: 4.916 (LR: 0.0180)[LOSS] Gradient sum: 1.7405
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0122, bias: 0.2661
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 9 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0766, range=[-0.0992, 0.0036]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
  Promedio de loss: 5.275

Época 47/50
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 8 tokens, target: 9 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.047, range=[-0.147, 0.879]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.047
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-23.160664
[DECODER] After pos encoding: 1152/1152 non-zero, sum=34.655754
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 1.046 -0.558 2.019 -1.003 -0.717 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.017, 4.452]
[DEBUG] Output sample values: 0.952 3.746 4.280 3.739 -1.157 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.017, 4.452] Var:0.726
[LOSS] Calculated loss: 4.895
 [EOS penalty: 0.172] Loss: 5.067 (LR: 0.0200)[LOSS] Gradient sum: 1.7457
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0133, bias: 0.2656
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0723, range=[-0.0950, 0.0043]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.372, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-0.372
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-4.204902
[ENCODER] After pos encoding: 896/896 non-zero, sum=40.721413
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000012
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.833 -1.043 -1.462 -1.567 -0.673 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.139, range=[-0.147, 0.881]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.139
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-1.577536
[DECODER] After pos encoding: 896/896 non-zero, sum=43.348789
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.210 -0.561 2.540 -0.768 -0.778 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.270, 4.725]
[DEBUG] Output sample values: 0.825 3.984 4.392 4.024 -0.662 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.270, 4.725] Var:0.729
[LOSS] Calculated loss: 4.836
 [EOS penalty: 0.161] Loss: 4.997 (LR: 0.0180)[LOSS] Gradient sum: 1.7447
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0064, bias: 0.1280
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0107, range=[-0.1216, 0.0053]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.969, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.969
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=10.964435
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=81.694832
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 0.826 -1.152 -1.386 -1.560 -0.407 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.976, range=[-0.147, 0.883]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.976
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=11.040768
[DECODER] After pos encoding: 1280/1280 non-zero, sum=75.311272
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000012
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.247 -0.018 3.772 -0.976 0.248 
[DEBUG] Output projection - shape: 10x1000
[DEBUG] Output range: [-3.149, 4.948]
[DEBUG] Output sample values: 0.121 3.058 4.650 2.608 -0.767 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.149, 4.948] Var:0.743
[LOSS] Calculated loss: 6.073
 [EOS penalty: 0.056] Loss: 6.129 (LR: 0.0200)[LOSS] Gradient sum: 1.7808
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0052, bias: 0.0896
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 10 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0580, range=[-0.0899, 0.0053]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 5 tokens, target: 7 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.208, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.208
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=13.662188
[ENCODER] After pos encoding: 640/640 non-zero, sum=45.722404
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.665 -1.287 -1.348 -1.709 -0.593 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.368, range=[-0.147, 0.885]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.368
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.168931
[DECODER] After pos encoding: 896/896 non-zero, sum=49.095242
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.312 -1.460 2.898 -1.377 -0.609 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.144, 4.942]
[DEBUG] Output sample values: 0.189 3.603 4.942 3.895 -0.443 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.144, 4.942] Var:0.743
[LOSS] Calculated loss: 4.954
 [EOS penalty: 0.189][TRAINER] Loss stagnant (improvement: -0.127), boosting LR to 0.050
 Loss: 5.143 (LR: 0.0500)[LOSS] Gradient sum: 1.7468
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0068, bias: 0.1271
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0108, range=[-0.1167, 0.0042]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 5 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.673, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.673
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-30.240953
[ENCODER] After pos encoding: 640/640 non-zero, sum=1.819236
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.845 -1.052 -1.375 -1.788 -0.621 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.149, range=[-0.147, 0.890]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-2.149
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-24.316067
[DECODER] After pos encoding: 640/640 non-zero, sum=7.744145
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.532 -0.374 2.381 -1.604 -0.615 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.978, 4.672]
[DEBUG] Output sample values: 0.889 4.170 4.505 3.405 -0.662 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.978, 4.672] Var:0.739
[LOSS] Calculated loss: 4.432
 [EOS penalty: 0.066] Loss: 4.498 (LR: 0.0180)[LOSS] Gradient sum: 1.7296
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0095, bias: 0.1786
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0582, range=[-0.1690, 0.0079]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.300, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.300
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-14.709489
[ENCODER] After pos encoding: 896/896 non-zero, sum=30.216846
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.835 -1.198 -1.359 -1.654 -0.585 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.054, range=[-0.147, 0.893]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.054
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-23.233799
[DECODER] After pos encoding: 1152/1152 non-zero, sum=34.582607
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000018
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.194 -0.903 3.579 -0.905 -0.133 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.062, 4.898]
[DEBUG] Output sample values: 0.123 3.495 4.898 2.897 -1.020 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.062, 4.898] Var:0.729
[LOSS] Calculated loss: 5.793
 [EOS penalty: 0.059] Loss: 5.853 (LR: 0.0200)[LOSS] Gradient sum: 1.7697
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0050, bias: 0.0994
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0777, range=[-0.0999, 0.0044]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 11 tokens, target: 12 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.542, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.542
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=6.134801
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=76.865318
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 1.209 -1.152 -1.396 -1.651 -0.486 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.379, range=[-0.147, 0.895]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.379
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=4.292030
[DECODER] After pos encoding: 1536/1536 non-zero, sum=81.488503
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: 1.781 -0.548 3.726 -0.860 -0.096 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-2.677, 5.183]
[DEBUG] Output sample values: -0.033 4.060 4.867 3.142 -0.340 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.677, 5.183] Var:0.714
[LOSS] Calculated loss: 5.407
 [EOS penalty: 0.121] Loss: 5.528 (LR: 0.0200)[LOSS] Gradient sum: 1.7629
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0072, bias: 0.1313
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0297, range=[-0.0749, 0.0054]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.832, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-2.832
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-32.043373
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=25.773064
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 1.006 -0.989 -1.477 -1.568 -0.628 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-10.060, range=[-0.147, 0.897]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-10.060
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-113.818741
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-56.002270
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.609 -0.024 3.110 -0.951 -0.516 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.833, 4.777]
[DEBUG] Output sample values: -0.036 3.616 4.777 3.483 -1.203 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.833, 4.777] Var:0.749
[LOSS] Calculated loss: 4.806
 [EOS penalty: 0.101] Loss: 4.907 (LR: 0.0180)[LOSS] Gradient sum: 1.7397
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0109, bias: 0.2659
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 9 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0764, range=[-0.0992, 0.0036]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
  Promedio de loss: 5.265

Época 48/50
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 8 tokens, target: 9 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.034, range=[-0.147, 0.898]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.034
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-23.007669
[DECODER] After pos encoding: 1152/1152 non-zero, sum=34.808750
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 1.045 -0.551 2.081 -0.991 -0.719 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.020, 4.458]
[DEBUG] Output sample values: 0.935 3.740 4.314 3.729 -1.155 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.020, 4.458] Var:0.726
[LOSS] Calculated loss: 4.888
 [EOS penalty: 0.172] Loss: 5.060 (LR: 0.0200)[LOSS] Gradient sum: 1.7452
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0106, bias: 0.2656
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0722, range=[-0.0949, 0.0043]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.372, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-0.372
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-4.204902
[ENCODER] After pos encoding: 896/896 non-zero, sum=40.721413
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.833 -1.043 -1.462 -1.567 -0.673 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.127, range=[-0.147, 0.900]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.127
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-1.434663
[DECODER] After pos encoding: 896/896 non-zero, sum=43.491650
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000012
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.197 -0.554 2.604 -0.750 -0.780 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.268, 4.733]
[DEBUG] Output sample values: 0.806 3.972 4.420 4.021 -0.653 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.268, 4.733] Var:0.729
[LOSS] Calculated loss: 4.829
 [EOS penalty: 0.161] Loss: 4.990 (LR: 0.0180)[LOSS] Gradient sum: 1.7442
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0064, bias: 0.1279
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0106, range=[-0.1214, 0.0053]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.969, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.969
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=10.964435
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=81.694832
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000014
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 0.826 -1.152 -1.386 -1.560 -0.407 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.989, range=[-0.147, 0.902]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.989
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=11.186459
[DECODER] After pos encoding: 1280/1280 non-zero, sum=75.456970
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.275 0.012 3.872 -0.958 0.262 
[DEBUG] Output projection - shape: 10x1000
[DEBUG] Output range: [-3.152, 4.956]
[DEBUG] Output sample values: 0.079 3.040 4.678 2.564 -0.763 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.152, 4.956] Var:0.744
[LOSS] Calculated loss: 6.067
 [EOS penalty: 0.055] Loss: 6.122 (LR: 0.0200)[LOSS] Gradient sum: 1.7805
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0052, bias: 0.0896
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 10 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0579, range=[-0.0899, 0.0053]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 5 tokens, target: 7 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.208, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.208
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=13.662188
[ENCODER] After pos encoding: 640/640 non-zero, sum=45.722404
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.665 -1.286 -1.348 -1.709 -0.593 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.379, range=[-0.147, 0.904]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.379
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.290262
[DECODER] After pos encoding: 896/896 non-zero, sum=49.216587
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.330 -1.464 2.972 -1.366 -0.609 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.143, 4.961]
[DEBUG] Output sample values: 0.158 3.593 4.961 3.881 -0.434 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.143, 4.961] Var:0.743
[LOSS] Calculated loss: 4.933
 [EOS penalty: 0.188][TRAINER] Loss stagnant (improvement: -0.127), boosting LR to 0.050
 Loss: 5.121 (LR: 0.0500)[LOSS] Gradient sum: 1.7464
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0066, bias: 0.1270
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0108, range=[-0.1165, 0.0041]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 5 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.673, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.673
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-30.240953
[ENCODER] After pos encoding: 640/640 non-zero, sum=1.819236
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.845 -1.052 -1.375 -1.788 -0.621 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.137, range=[-0.147, 0.910]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-2.137
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-24.172768
[DECODER] After pos encoding: 640/640 non-zero, sum=7.887416
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.527 -0.367 2.434 -1.598 -0.613 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.976, 4.663]
[DEBUG] Output sample values: 0.873 4.173 4.508 3.390 -0.654 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.976, 4.663] Var:0.739
[LOSS] Calculated loss: 4.427
 [EOS penalty: 0.065] Loss: 4.492 (LR: 0.0180)[LOSS] Gradient sum: 1.7296
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0090, bias: 0.1786
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 639/640 non-zero, sum=-0.0581, range=[-0.1689, 0.0079]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.300, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.300
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-14.709489
[ENCODER] After pos encoding: 896/896 non-zero, sum=30.216846
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.835 -1.198 -1.359 -1.654 -0.585 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.040, range=[-0.147, 0.913]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.040
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-23.082285
[DECODER] After pos encoding: 1152/1152 non-zero, sum=34.734135
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.179 -0.889 3.673 -0.877 -0.117 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.060, 4.915]
[DEBUG] Output sample values: 0.082 3.484 4.915 2.859 -1.013 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.060, 4.915] Var:0.729
[LOSS] Calculated loss: 5.787
 [EOS penalty: 0.058] Loss: 5.845 (LR: 0.0200)[LOSS] Gradient sum: 1.7694
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0053, bias: 0.0994
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0776, range=[-0.0999, 0.0045]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 11 tokens, target: 12 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.542, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.542
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=6.134801
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=76.865318
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 1.209 -1.152 -1.396 -1.651 -0.485 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.391, range=[-0.147, 0.915]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.391
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=4.426603
[DECODER] After pos encoding: 1536/1536 non-zero, sum=81.622971
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: 1.782 -0.536 3.796 -0.844 -0.091 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-2.663, 5.195]
[DEBUG] Output sample values: -0.065 4.053 4.877 3.118 -0.329 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.663, 5.195] Var:0.715
[LOSS] Calculated loss: 5.402
 [EOS penalty: 0.118] Loss: 5.521 (LR: 0.0200)[LOSS] Gradient sum: 1.7628
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0071, bias: 0.1313
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0297, range=[-0.0749, 0.0054]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.832, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-2.832
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-32.043373
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=25.773064
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000014
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 1.006 -0.989 -1.477 -1.568 -0.628 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-10.046, range=[-0.147, 0.916]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-10.046
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-113.663055
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-55.846619
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.599 -0.007 3.183 -0.936 -0.509 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.832, 4.795]
[DEBUG] Output sample values: -0.073 3.609 4.795 3.457 -1.198 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.832, 4.795] Var:0.749
[LOSS] Calculated loss: 4.802
 [EOS penalty: 0.099] Loss: 4.901 (LR: 0.0180)[LOSS] Gradient sum: 1.7394
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0114, bias: 0.2659
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 9 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0764, range=[-0.0992, 0.0037]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
  Promedio de loss: 5.256

Época 49/50
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 8 tokens, target: 9 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.020, range=[-0.147, 0.918]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.020
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-22.854919
[DECODER] After pos encoding: 1152/1152 non-zero, sum=34.961536
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 1.043 -0.545 2.143 -0.978 -0.721 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.024, 4.471]
[DEBUG] Output sample values: 0.918 3.734 4.309 3.718 -1.153 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.024, 4.471] Var:0.726
[LOSS] Calculated loss: 4.884
 [EOS penalty: 0.172] Loss: 5.056 (LR: 0.0200)[LOSS] Gradient sum: 1.7451
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0119, bias: 0.2657
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0721, range=[-0.0949, 0.0043]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.372, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-0.372
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-4.204902
[ENCODER] After pos encoding: 896/896 non-zero, sum=40.721413
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.833 -1.043 -1.462 -1.567 -0.673 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.114, range=[-0.147, 0.920]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.114
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-1.292030
[DECODER] After pos encoding: 896/896 non-zero, sum=43.634300
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.182 -0.546 2.668 -0.732 -0.781 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.267, 4.740]
[DEBUG] Output sample values: 0.787 3.974 4.419 4.011 -0.645 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.267, 4.740] Var:0.729
[LOSS] Calculated loss: 4.822
 [EOS penalty: 0.161] Loss: 4.983 (LR: 0.0180)[LOSS] Gradient sum: 1.7439
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0064, bias: 0.1279
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0106, range=[-0.1214, 0.0053]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.969, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.969
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=10.964435
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=81.694832
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 0.826 -1.152 -1.386 -1.560 -0.407 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.002, range=[-0.147, 0.922]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.002
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=11.332002
[DECODER] After pos encoding: 1280/1280 non-zero, sum=75.602425
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.303 0.040 3.970 -0.939 0.277 
[DEBUG] Output projection - shape: 10x1000
[DEBUG] Output range: [-3.154, 4.966]
[DEBUG] Output sample values: 0.039 3.023 4.691 2.541 -0.759 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.154, 4.966] Var:0.744
[LOSS] Calculated loss: 6.059
 [EOS penalty: 0.055] Loss: 6.114 (LR: 0.0200)[LOSS] Gradient sum: 1.7802
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0050, bias: 0.0896
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 10 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0578, range=[-0.0899, 0.0054]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 5 tokens, target: 7 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.208, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.208
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=13.662188
[ENCODER] After pos encoding: 640/640 non-zero, sum=45.722404
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.665 -1.286 -1.348 -1.709 -0.593 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.390, range=[-0.147, 0.924]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.390
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.411450
[DECODER] After pos encoding: 896/896 non-zero, sum=49.337765
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.348 -1.468 3.045 -1.354 -0.607 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.141, 4.969]
[DEBUG] Output sample values: 0.129 3.597 4.969 3.875 -0.425 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.141, 4.969] Var:0.744
[LOSS] Calculated loss: 4.908
 [EOS penalty: 0.189][TRAINER] Loss stagnant (improvement: -0.123), boosting LR to 0.050
 Loss: 5.097 (LR: 0.0500)[LOSS] Gradient sum: 1.7456
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0064, bias: 0.1269
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0107, range=[-0.1164, 0.0041]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 5 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.673, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.673
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-30.240953
[ENCODER] After pos encoding: 640/640 non-zero, sum=1.819236
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.845 -1.052 -1.375 -1.788 -0.621 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.124, range=[-0.147, 0.929]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-2.124
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-24.029705
[DECODER] After pos encoding: 640/640 non-zero, sum=8.030491
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.522 -0.359 2.487 -1.591 -0.611 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.975, 4.685]
[DEBUG] Output sample values: 0.857 4.191 4.508 3.394 -0.647 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.975, 4.685] Var:0.740
[LOSS] Calculated loss: 4.417
 [EOS penalty: 0.065] Loss: 4.482 (LR: 0.0180)[LOSS] Gradient sum: 1.7286
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0090, bias: 0.1785
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0579, range=[-0.1689, 0.0080]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.300, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.300
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-14.709489
[ENCODER] After pos encoding: 896/896 non-zero, sum=30.216846
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.835 -1.197 -1.359 -1.654 -0.585 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.027, range=[-0.147, 0.932]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.027
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-22.931000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=34.885429
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000014
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.164 -0.874 3.765 -0.849 -0.102 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.059, 4.923]
[DEBUG] Output sample values: 0.042 3.490 4.923 2.852 -1.005 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.059, 4.923] Var:0.730
[LOSS] Calculated loss: 5.781
 [EOS penalty: 0.058] Loss: 5.840 (LR: 0.0200)[LOSS] Gradient sum: 1.7691
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0050, bias: 0.0993
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1151/1152 non-zero, sum=-0.0774, range=[-0.0999, 0.0046]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 11 tokens, target: 12 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.542, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.542
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=6.134801
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=76.865318
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000012
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 1.209 -1.151 -1.396 -1.651 -0.485 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.403, range=[-0.147, 0.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.403
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=4.560956
[DECODER] After pos encoding: 1536/1536 non-zero, sum=81.757309
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000021
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: 1.783 -0.523 3.864 -0.828 -0.085 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-2.663, 5.212]
[DEBUG] Output sample values: -0.096 4.074 4.873 3.129 -0.319 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.663, 5.212] Var:0.715
[LOSS] Calculated loss: 5.397
 [EOS penalty: 0.120] Loss: 5.516 (LR: 0.0200)[LOSS] Gradient sum: 1.7625
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0072, bias: 0.1313
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0296, range=[-0.0749, 0.0055]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.832, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-2.832
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-32.043373
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=25.773064
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 1.006 -0.989 -1.477 -1.568 -0.628 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-10.033, range=[-0.147, 0.936]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-10.033
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-113.507736
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-55.691277
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.590 0.011 3.254 -0.922 -0.502 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.831, 4.794]
[DEBUG] Output sample values: -0.109 3.621 4.794 3.463 -1.194 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.831, 4.794] Var:0.749
[LOSS] Calculated loss: 4.792
 [EOS penalty: 0.100] Loss: 4.892 (LR: 0.0180)[LOSS] Gradient sum: 1.7387
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0128, bias: 0.2653
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 9 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0763, range=[-0.0992, 0.0037]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
  Promedio de loss: 5.247

Época 50/50
  Procesando 8 muestras...
  Vocabulario objetivo: 1000 clases
    Muestra 1/8: [DEBUG] Forward - source: 8 tokens, target: 9 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.007, range=[-0.147, 0.937]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.007
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-22.702477
[DECODER] After pos encoding: 1152/1152 non-zero, sum=35.113911
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 1.042 -0.539 2.204 -0.966 -0.723 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.027, 4.481]
[DEBUG] Output sample values: 0.901 3.749 4.307 3.737 -1.151 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.027, 4.481] Var:0.727
[LOSS] Calculated loss: 4.875
 [EOS penalty: 0.174] Loss: 5.049 (LR: 0.0200)[LOSS] Gradient sum: 1.7445
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0112, bias: 0.2650
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0720, range=[-0.0949, 0.0044]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.372, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-0.372
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-4.204902
[ENCODER] After pos encoding: 896/896 non-zero, sum=40.721413
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.833 -1.042 -1.462 -1.568 -0.673 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.102, range=[-0.147, 0.939]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.102
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-1.149642
[DECODER] After pos encoding: 896/896 non-zero, sum=43.776737
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 0.169 -0.538 2.729 -0.714 -0.783 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.266, 4.757]
[DEBUG] Output sample values: 0.769 3.992 4.415 4.037 -0.636 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.266, 4.757] Var:0.730
[LOSS] Calculated loss: 4.816
 [EOS penalty: 0.165] Loss: 4.981 (LR: 0.0180)[LOSS] Gradient sum: 1.7435
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1279
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0106, range=[-0.1215, 0.0053]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 11 tokens, target: 10 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.969, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.969
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=10.964435
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=81.694832
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 0.826 -1.151 -1.386 -1.560 -0.407 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.014, range=[-0.147, 0.941]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=1.014
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=11.477265
[DECODER] After pos encoding: 1280/1280 non-zero, sum=75.747780
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.332 0.068 4.064 -0.919 0.291 
[DEBUG] Output projection - shape: 10x1000
[DEBUG] Output range: [-3.156, 4.973]
[DEBUG] Output sample values: -0.000 3.034 4.701 2.549 -0.753 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.156, 4.973] Var:0.745
[LOSS] Calculated loss: 6.051
 [EOS penalty: 0.055] Loss: 6.106 (LR: 0.0200)[LOSS] Gradient sum: 1.7800
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0049, bias: 0.0896
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 10 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0577, range=[-0.0899, 0.0054]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 5 tokens, target: 7 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.208, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.208
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=13.662188
[ENCODER] After pos encoding: 640/640 non-zero, sum=45.722404
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.665 -1.286 -1.348 -1.709 -0.593 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.401, range=[-0.147, 0.943]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.401
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=4.532357
[DECODER] After pos encoding: 896/896 non-zero, sum=49.458668
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000008
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.366 -1.472 3.116 -1.343 -0.606 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-3.140, 4.975]
[DEBUG] Output sample values: 0.100 3.613 4.975 3.892 -0.416 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.140, 4.975] Var:0.744
[LOSS] Calculated loss: 4.888
 [EOS penalty: 0.191][TRAINER] Loss stagnant (improvement: -0.121), boosting LR to 0.050
 Loss: 5.079 (LR: 0.0500)[LOSS] Gradient sum: 1.7451
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0069, bias: 0.1269
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0107, range=[-0.1163, 0.0042]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 5 tokens, target: 5 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.673, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-2.673
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-30.240953
[ENCODER] After pos encoding: 640/640 non-zero, sum=1.819236
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.845 -1.052 -1.375 -1.788 -0.621 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-2.111, range=[-0.147, 0.949]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-2.111
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-23.886993
[DECODER] After pos encoding: 640/640 non-zero, sum=8.173199
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 0.517 -0.352 2.538 -1.584 -0.610 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.973, 4.699]
[DEBUG] Output sample values: 0.842 4.210 4.534 3.397 -0.640 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.973, 4.699] Var:0.740
[LOSS] Calculated loss: 4.407
 [EOS penalty: 0.065] Loss: 4.472 (LR: 0.0180)[LOSS] Gradient sum: 1.7279
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0090, bias: 0.1785
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.0577, range=[-0.1687, 0.0082]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 7 tokens, target: 9 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.300, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=-1.300
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-14.709489
[ENCODER] After pos encoding: 896/896 non-zero, sum=30.216846
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: 0.835 -1.197 -1.359 -1.654 -0.585 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.013, range=[-0.147, 0.952]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-2.013
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-22.780060
[DECODER] After pos encoding: 1152/1152 non-zero, sum=35.036400
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.150 -0.860 3.855 -0.821 -0.088 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-3.058, 4.932]
[DEBUG] Output sample values: 0.002 3.501 4.932 2.838 -0.998 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-3.058, 4.932] Var:0.730
[LOSS] Calculated loss: 5.778
 [EOS penalty: 0.058] Loss: 5.836 (LR: 0.0200)[LOSS] Gradient sum: 1.7689
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0052, bias: 0.0993
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 9 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0773, range=[-0.0999, 0.0046]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 11 tokens, target: 12 tokens
[ENCODER] Starting encode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.542, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1408/1408 non-zero, sum=0.542
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=6.134801
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=76.865318
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 11x128
[DEBUG] Encoder sample values: 1.209 -1.151 -1.396 -1.651 -0.485 
[DECODER] Starting decode with 12 tokens
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=0.415, range=[-0.147, 0.954]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=0.415
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=4.695010
[DECODER] After pos encoding: 1536/1536 non-zero, sum=81.891388
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 12x128
[DEBUG] Decoder sample values: 1.784 -0.511 3.930 -0.813 -0.080 
[DEBUG] Output projection - shape: 12x1000
[DEBUG] Output range: [-2.667, 5.227]
[DEBUG] Output sample values: -0.126 4.088 4.887 3.126 -0.309 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.667, 5.227] Var:0.716
[LOSS] Calculated loss: 5.391
 [EOS penalty: 0.120] Loss: 5.511 (LR: 0.0200)[LOSS] Gradient sum: 1.7622
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0074, bias: 0.1314
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 12 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.0295, range=[-0.0749, 0.0056]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 9 tokens, target: 9 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.832, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=-2.832
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-32.043373
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=25.773064
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000038
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: 1.006 -0.989 -1.477 -1.568 -0.628 
[DECODER] Starting decode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-10.019, range=[-0.147, 0.955]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-10.019
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-113.352798
[DECODER] After pos encoding: 1152/1152 non-zero, sum=-55.536385
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 9x128
[DEBUG] Decoder sample values: 0.580 0.027 3.322 -0.907 -0.495 
[DEBUG] Output projection - shape: 9x1000
[DEBUG] Output range: [-2.829, 4.798]
[DEBUG] Output sample values: -0.143 3.624 4.798 3.454 -1.189 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.829, 4.798] Var:0.749
[LOSS] Calculated loss: 4.788
 [EOS penalty: 0.100] Loss: 4.888 (LR: 0.0180)[LOSS] Gradient sum: 1.7386
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0116, bias: 0.2652
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 9 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.0762, range=[-0.0992, 0.0037]
[EMBEDDING] Sample weights after update: 0.13788122 0.00458774 0.02848999 0.00551402 -0.01498904 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
  Promedio de loss: 5.240
  === Progreso en época 50 ===
[DEBUG] Forward - source: 8 tokens, target: 1 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.410, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.410
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=4.642797
[DECODER] After pos encoding: 128/128 non-zero, sum=11.042795
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.896 -0.971 0.487 -1.493 -0.623 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.875, 4.681]
[DEBUG] Output sample values: 1.226 4.014 4.681 3.830 -0.925 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 5 (score: 4.1, target_len: 7) [Top scores: 5:4.1 1:4.0 2:2.7 17:2.3 339:2.3 ]
[DEBUG] Forward - source: 8 tokens, target: 2 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.629, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.629
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=7.118590
[DECODER] After pos encoding: 256/256 non-zero, sum=19.924623
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 1.002 -0.758 0.812 -1.394 -0.853 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.767, 4.645]
[DEBUG] Output sample values: 1.223 4.058 4.645 3.893 -1.088 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 1 (score: 4.2, target_len: 7) [Top scores: 1:4.2 23:2.2 37:2.1 460:2.0 719:2.0 ]
[DEBUG] Forward - source: 8 tokens, target: 3 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.069, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-1.069
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-12.091496
[DECODER] After pos encoding: 384/384 non-zero, sum=7.126573
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 1.097 -0.505 1.091 -1.247 -1.076 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.698, 4.577]
[DEBUG] Output sample values: 1.199 4.099 4.577 3.952 -1.230 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 986 (score: 3.4, target_len: 7) [Top scores: 986:3.4 15:2.5 23:2.5 1:2.4 37:2.2 ]
[DEBUG] Forward - source: 8 tokens, target: 4 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.755, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.755
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-8.547270
[DECODER] After pos encoding: 512/512 non-zero, sum=17.088860
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: 1.097 -0.443 1.193 -1.113 -0.981 
[DEBUG] Output projection - shape: 4x1000
[DEBUG] Output range: [-2.834, 4.495]
[DEBUG] Output sample values: 1.160 3.969 4.495 3.849 -1.182 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 8 tokens, target: 5 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.168, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-1.168
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-13.218433
[DECODER] After pos encoding: 640/640 non-zero, sum=18.841768
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: 1.140 -0.610 1.360 -1.092 -0.725 
[DEBUG] Output projection - shape: 5x1000
[DEBUG] Output range: [-2.646, 4.585]
[DEBUG] Output sample values: 1.055 4.045 4.459 3.596 -1.042 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.950, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.950
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.742645
[DECODER] After pos encoding: 768/768 non-zero, sum=27.747633
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: 1.199 -0.442 1.505 -0.995 -0.889 
[DEBUG] Output projection - shape: 6x1000
[DEBUG] Output range: [-2.638, 4.622]
[DEBUG] Output sample values: 1.042 4.085 4.420 3.666 -1.139 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-4.364, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-4.364
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-49.377274
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=1.991079
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: 1.092 -1.017 -1.644 -1.536 -0.696 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.647, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-2.647
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-29.952742
[DECODER] After pos encoding: 896/896 non-zero, sum=14.973603
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: 1.106 -0.335 1.633 -0.942 -0.950 
[DEBUG] Output projection - shape: 7x1000
[DEBUG] Output range: [-2.686, 4.538]
[DEBUG] Output sample values: 1.034 4.007 4.300 3.664 -1.242 
[DEBUG] Forward completed!
  ENG: <sos> <unk> <unk> is a <unk> city <eos>
  ESP: <sos> de <unk> llegu d de <unk> llegu <eos>
  ================================

¡Entrenamiento completado!

=== Pruebas de Traducción ===
[DEBUG] Forward - source: 3 tokens, target: 1 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-2.910, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-2.910
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-32.922398
[ENCODER] After pos encoding: 384/384 non-zero, sum=-13.704330
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: 0.902 -1.150 -1.444 -1.698 -0.595 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.410, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.410
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=4.642797
[DECODER] After pos encoding: 128/128 non-zero, sum=11.042795
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.813 -1.065 0.602 -1.592 -0.534 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.966, 4.813]
[DEBUG] Output sample values: 1.157 4.033 4.813 3.795 -0.823 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 1 (score: 4.0, target_len: 2) [Top scores: 5:4.1 1:4.0 2:2.8 17:2.4 757:2.3 ]
[DEBUG] Forward - source: 3 tokens, target: 2 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-2.910, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-2.910
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-32.922398
[ENCODER] After pos encoding: 384/384 non-zero, sum=-13.704330
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: 0.902 -1.150 -1.444 -1.698 -0.595 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.288, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.288
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-14.567294
[DECODER] After pos encoding: 256/256 non-zero, sum=-1.761276
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.948 -0.865 0.933 -1.513 -0.781 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.878, 4.787]
[DEBUG] Output sample values: 1.179 4.080 4.787 3.880 -1.021 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 5 (score: 3.0, target_len: 2) [Top scores: 986:3.4 5:3.0 23:2.5 15:2.5 1:2.5 ]
ENG: <sos> hello <eos>
ESP: <sos> <unk> de <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.101, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.101
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-1.139453
[ENCODER] After pos encoding: 640/640 non-zero, sum=30.920774
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.976 -1.278 -1.359 -1.704 -0.575 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.410, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.410
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=4.642797
[DECODER] After pos encoding: 128/128 non-zero, sum=11.042795
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.844 -1.148 0.663 -1.630 -0.566 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.925, 4.768]
[DEBUG] Output sample values: 1.177 4.086 4.768 3.616 -0.746 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 1 (score: 4.1, target_len: 4) [Top scores: 5:4.2 1:4.1 2:2.8 17:2.5 757:2.3 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.101, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.101
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-1.139453
[ENCODER] After pos encoding: 640/640 non-zero, sum=30.920774
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.976 -1.278 -1.359 -1.704 -0.575 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.288, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.288
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-14.567294
[DECODER] After pos encoding: 256/256 non-zero, sum=-1.761276
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.779 -1.326 1.480 -1.404 -0.744 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.688, 4.645]
[DEBUG] Output sample values: 1.002 4.233 4.645 3.207 -0.548 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 1 (score: 2.3, target_len: 4) [Top scores: 5:3.6 15:2.3 1:2.3 23:2.2 195:2.1 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.101, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.101
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-1.139453
[ENCODER] After pos encoding: 640/640 non-zero, sum=30.920774
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.976 -1.278 -1.359 -1.704 -0.575 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-2.986, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-2.986
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-33.777397
[DECODER] After pos encoding: 384/384 non-zero, sum=-14.559324
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 0.969 -1.178 2.244 -1.599 -0.450 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.684, 4.590]
[DEBUG] Output sample values: 0.720 4.049 4.590 3.124 -0.782 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 5 (score: 3.6, target_len: 4) [Top scores: 5:3.6 15:2.4 1:2.2 195:2.1 37:2.0 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.101, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.101
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-1.139453
[ENCODER] After pos encoding: 640/640 non-zero, sum=30.920774
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.976 -1.278 -1.359 -1.704 -0.575 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.767, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-2.767
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-31.301609
[DECODER] After pos encoding: 512/512 non-zero, sum=-5.665481
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: 1.129 -0.772 2.545 -1.835 -0.389 
[DEBUG] Output projection - shape: 4x1000
[DEBUG] Output range: [-2.599, 4.670]
[DEBUG] Output sample values: 0.627 3.915 4.670 2.758 -0.807 
[DEBUG] Forward completed!
ENG: <sos> how are you <eos>
ESP: <sos> <unk> <unk> de tarde <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-16.114012
[ENCODER] After pos encoding: 512/512 non-zero, sum=9.522116
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.846 -1.220 -1.438 -1.833 -0.568 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.410, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.410
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=4.642797
[DECODER] After pos encoding: 128/128 non-zero, sum=11.042795
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.793 -1.163 0.571 -1.680 -0.484 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.941, 4.752]
[DEBUG] Output sample values: 1.196 3.997 4.752 3.696 -0.731 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 5 (score: 4.2, target_len: 3) [Top scores: 5:4.2 1:4.0 2:2.8 17:2.3 757:2.3 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-16.114012
[ENCODER] After pos encoding: 512/512 non-zero, sum=9.522116
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.846 -1.220 -1.438 -1.833 -0.568 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.629, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.629
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=7.118590
[DECODER] After pos encoding: 256/256 non-zero, sum=19.924623
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.927 -1.012 0.901 -1.740 -0.457 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.901, 4.688]
[DEBUG] Output sample values: 1.301 3.927 4.688 3.593 -0.749 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 581 (score: 2.4, target_len: 3) [Top scores: 1:3.9 812:2.4 581:2.4 132:2.4 789:2.1 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.424, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.424
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-16.114012
[ENCODER] After pos encoding: 512/512 non-zero, sum=9.522116
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.846 -1.220 -1.438 -1.833 -0.568 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.031, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=0.031
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=0.345226
[DECODER] After pos encoding: 384/384 non-zero, sum=19.563303
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 0.827 -1.247 1.175 -1.928 -0.612 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-3.206, 4.486]
[DEBUG] Output sample values: 1.294 3.768 4.486 3.473 -0.683 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 1 (score: 3.1, target_len: 3) [Top scores: 1:3.1 789:2.8 132:2.6 460:2.6 23:2.4 ]
ENG: <sos> good morning <eos>
ESP: <sos> de entiendo <unk> <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.040, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.040
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-23.084393
[ENCODER] After pos encoding: 512/512 non-zero, sum=2.551737
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.904 -1.134 -1.388 -1.744 -0.518 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.410, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.410
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=4.642797
[DECODER] After pos encoding: 128/128 non-zero, sum=11.042795
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.815 -1.049 0.615 -1.621 -0.475 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-3.017, 4.810]
[DEBUG] Output sample values: 1.157 3.998 4.810 3.698 -0.805 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 5 (score: 4.2, target_len: 3) [Top scores: 5:4.2 1:4.0 2:2.8 17:2.4 339:2.3 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.040, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.040
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-23.084393
[ENCODER] After pos encoding: 512/512 non-zero, sum=2.551737
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.904 -1.134 -1.388 -1.744 -0.518 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.629, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.629
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=7.118590
[DECODER] After pos encoding: 256/256 non-zero, sum=19.924623
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.870 -1.020 0.784 -1.563 -0.562 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-3.070, 4.789]
[DEBUG] Output sample values: 1.250 3.956 4.789 3.704 -0.922 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 1 (score: 3.7, target_len: 3) [Top scores: 1:3.7 710:2.5 57:2.2 433:2.1 756:2.1 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.040, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-2.040
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-23.084393
[ENCODER] After pos encoding: 512/512 non-zero, sum=2.551737
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: 0.904 -1.134 -1.388 -1.744 -0.518 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.069, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-1.069
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-12.091496
[DECODER] After pos encoding: 384/384 non-zero, sum=7.126573
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 1.079 -0.484 1.572 -1.835 -0.538 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-3.147, 4.825]
[DEBUG] Output sample values: 1.012 3.797 4.825 3.104 -0.883 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 195 (score: 2.3, target_len: 3) [Top scores: 195:2.3 986:2.2 57:2.2 5:2.1 176:2.1 ]
ENG: <sos> thank you <eos>
ESP: <sos> de <unk> ndo <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.777, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.777
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-8.794705
[ENCODER] After pos encoding: 640/640 non-zero, sum=23.265476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.944 -1.169 -1.424 -1.800 -0.552 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.410, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.410
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=4.642797
[DECODER] After pos encoding: 128/128 non-zero, sum=11.042795
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: 0.855 -1.063 0.594 -1.653 -0.501 
[DEBUG] Output projection - shape: 1x1000
[DEBUG] Output range: [-2.974, 4.798]
[DEBUG] Output sample values: 1.175 3.999 4.798 3.654 -0.802 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 5 (score: 4.1, target_len: 4) [Top scores: 5:4.1 1:4.0 2:2.8 17:2.4 757:2.3 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.777, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.777
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-8.794705
[ENCODER] After pos encoding: 640/640 non-zero, sum=23.265476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.944 -1.169 -1.424 -1.800 -0.552 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.629, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.629
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=7.118590
[DECODER] After pos encoding: 256/256 non-zero, sum=19.924623
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000012
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: 0.924 -1.105 0.680 -1.596 -0.523 
[DEBUG] Output projection - shape: 2x1000
[DEBUG] Output range: [-2.929, 4.803]
[DEBUG] Output sample values: 1.199 3.998 4.803 3.567 -0.863 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 1 (score: 4.1, target_len: 4) [Top scores: 1:4.1 150:2.7 581:2.3 710:2.3 819:2.2 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.777, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.777
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-8.794705
[ENCODER] After pos encoding: 640/640 non-zero, sum=23.265476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.944 -1.169 -1.424 -1.800 -0.552 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.069, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-1.069
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-12.091496
[DECODER] After pos encoding: 384/384 non-zero, sum=7.126573
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: 1.012 -0.848 1.574 -1.962 -0.666 
[DEBUG] Output projection - shape: 3x1000
[DEBUG] Output range: [-2.785, 4.746]
[DEBUG] Output sample values: 1.232 3.801 4.746 3.231 -0.829 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 150 (score: 2.4, target_len: 4) [Top scores: 150:2.4 37:2.3 23:2.2 15:2.1 460:2.0 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.777, range=[-0.146, 0.146]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-0.777
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-8.794705
[ENCODER] After pos encoding: 640/640 non-zero, sum=23.265476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: 0.944 -1.169 -1.424 -1.800 -0.552 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-4.064, range=[-0.146, 0.957]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-4.064
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-45.974319
[DECODER] After pos encoding: 512/512 non-zero, sum=-20.338192
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: 1.231 -0.322 2.112 -2.116 -0.610 
[DEBUG] Output projection - shape: 4x1000
[DEBUG] Output range: [-2.807, 4.729]
[DEBUG] Output sample values: 1.057 3.650 4.729 2.755 -0.789 
[DEBUG] Forward completed!
ENG: <sos> i love you <eos>
ESP: <sos> de <unk> tarde lejos <eos>
---