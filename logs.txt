Se han truncado las últimas 5000 líneas del flujo de salida.
[DEBUG] Output sample values: 0.087 2.811 4.272 3.752 1.583 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 98 (score: 3.3, target_len: 9) [Top scores: 98:3.3 21:2.6 7:2.6 881:2.5 677:2.5 ]
[DEBUG] Forward - source: 10 tokens, target: 4 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.427 -0.946 1.318 0.551 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.029, range=[-0.106, 2.349]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1.029
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=11.638241
[DECODER] After pos encoding: 512/512 non-zero, sum=37.274372
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -2.278 -0.031 3.522 0.294 -0.691 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.049, 4.526]
[DEBUG] Output sample values: 0.266 3.218 4.269 3.933 1.355 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 5 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.427 -0.946 1.318 0.551 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.215, range=[-0.106, 2.349]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.215
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=13.745186
[DECODER] After pos encoding: 640/640 non-zero, sum=45.805401
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -2.263 -0.166 3.540 0.506 -0.744 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.010, 4.380]
[DEBUG] Output sample values: 0.297 3.292 4.204 3.794 1.408 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 6 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.427 -0.946 1.318 0.551 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=3.110, range=[-0.106, 2.349]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=3.110
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=35.190899
[DECODER] After pos encoding: 768/768 non-zero, sum=73.681198
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -2.559 0.089 3.941 0.272 -0.786 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.250, 4.189]
[DEBUG] Output sample values: 0.423 3.416 4.026 3.767 1.517 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 7 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.427 -0.946 1.318 0.551 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.262, range=[-0.106, 2.349]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=2.262
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=25.597212
[DECODER] After pos encoding: 896/896 non-zero, sum=70.523605
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000014
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -2.379 0.074 3.963 0.318 -0.787 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.234, 4.160]
[DEBUG] Output sample values: 0.366 3.408 3.988 3.765 1.523 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 8 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.427 -0.946 1.318 0.551 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.834, range=[-0.106, 2.349]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.834
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=9.433532
[DECODER] After pos encoding: 1024/1024 non-zero, sum=60.801975
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -2.307 0.075 3.916 0.307 -0.830 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.245, 4.187]
[DEBUG] Output sample values: 0.416 3.441 4.016 3.732 1.546 
[DEBUG] Forward completed!
  ENG: <sos> my grandfather is a bit hard of hearing <eos>
  ESP: <sos> ma tuve ana que les ma tuve ana
  ================================

Época 96/100
  Procesando 8 muestras...
  Vocabulario objetivo: 2000 clases
    Muestra 1/8: [DEBUG] Forward - source: 10 tokens, target: 11 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.427 -0.946 1.318 0.551 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.808, range=[-0.107, 2.349]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=2.808
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=31.765869
[DECODER] After pos encoding: 1408/1408 non-zero, sum=102.496338
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000012
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.649 -0.168 5.117 0.599 -0.922 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.213, 4.674]
[DEBUG] Output sample values: 0.697 3.610 3.683 3.419 1.254 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.213, 4.674] Var:0.427
[LOSS] Calculated loss: 6.609
 [EOS penalty: 0.086] Loss: 6.695 (LR: 0.0200)[LOSS] Gradient sum: 1.7932
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0041, bias: 0.0814
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 11 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0212, range=[-0.0804, 0.0013]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.687, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.687
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-7.773623
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=43.594772
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.834 0.047 0.148 1.419 1.115 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.277, range=[-0.107, 2.350]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.277
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.135345
[DECODER] After pos encoding: 1024/1024 non-zero, sum=48.233051
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.360 -0.742 5.381 0.784 0.061 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-1.904, 4.239]
[DEBUG] Output sample values: 0.713 3.175 3.405 3.910 1.673 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-1.904, 4.239] Var:0.404
[LOSS] Calculated loss: 5.302
 [EOS penalty: 0.107][TRAINER] Loss stagnant (improvement: -0.126), boosting LR to 0.050
 Loss: 5.410 (LR: 0.0500)[LOSS] Gradient sum: 1.7848
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0056, bias: 0.1097
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 8 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0482, range=[-0.1110, 0.0024]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 7 tokens, target: 5 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.259, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.259
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.246510
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.172813
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -1.264 0.997 -0.606 1.024 1.174 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.423, range=[-0.107, 2.356]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.423
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.729923
[DECODER] After pos encoding: 640/640 non-zero, sum=70.790192
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -1.091 1.089 4.826 0.228 0.774 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.052, 4.073]
[DEBUG] Output sample values: 0.535 3.263 3.666 3.683 1.510 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.052, 4.073] Var:0.400
[LOSS] Calculated loss: 5.298
 [EOS penalty: 0.054] Loss: 5.352 (LR: 0.0180)[LOSS] Gradient sum: 1.7830
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0090, bias: 0.1787
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.1103, range=[-0.1769, 0.0031]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.721, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=2.721
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=30.780994
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.149437
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000011
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.261 0.550 -0.522 0.900 1.511 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.130, range=[-0.107, 2.359]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.130
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.092667
[DECODER] After pos encoding: 768/768 non-zero, sum=62.582909
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -1.245 0.391 3.965 0.067 1.020 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.279, 4.737]
[DEBUG] Output sample values: 0.014 2.904 4.719 3.704 1.736 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.279, 4.737] Var:0.420
[LOSS] Calculated loss: 5.398
 [EOS penalty: 0.055] Loss: 5.453 (LR: 0.0200)[LOSS] Gradient sum: 1.7772
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0077, bias: 0.1488
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0793, range=[-0.1429, 0.0026]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.639, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.639
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.548738
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.475082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.829 0.671 -0.549 1.279 0.876 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.648, range=[-0.107, 2.362]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.648
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.648417
[DECODER] After pos encoding: 896/896 non-zero, sum=63.574722
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.304 1.127 4.447 0.627 -0.056 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.384, 4.390]
[DEBUG] Output sample values: -0.206 3.586 4.210 3.586 1.283 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.384, 4.390] Var:0.407
[LOSS] Calculated loss: 5.834
 [EOS penalty: 0.065] Loss: 5.899 (LR: 0.0180)[LOSS] Gradient sum: 1.7841
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1278
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0626, range=[-0.1248, 0.0020]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.132, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.132
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.812376
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.556019
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.115 0.156 -0.686 1.431 0.733 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.570, range=[-0.107, 2.364]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.570
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=6.444687
[DECODER] After pos encoding: 1280/1280 non-zero, sum=70.715233
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.903 0.138 4.885 0.943 -0.459 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.331, 4.317]
[DEBUG] Output sample values: 0.962 3.463 4.055 3.169 1.333 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.331, 4.317] Var:0.414
[LOSS] Calculated loss: 6.019
 [EOS penalty: 0.057] Loss: 6.076 (LR: 0.0180)[LOSS] Gradient sum: 1.7879
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0068, bias: 0.1682
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 10 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0284, range=[-0.0878, 0.0014]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.128, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.128
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=1.442956
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=59.259331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.956 1.081 -0.141 1.515 0.961 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.361, range=[-0.107, 2.366]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.361
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=15.398082
[DECODER] After pos encoding: 1024/1024 non-zero, sum=66.766441
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000010
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.121 0.973 5.511 1.319 0.107 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.071, 4.192]
[DEBUG] Output sample values: 0.767 3.495 3.807 3.812 1.687 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.071, 4.192] Var:0.410
[LOSS] Calculated loss: 5.987
 [EOS penalty: 0.089] Loss: 6.075 (LR: 0.0200)[LOSS] Gradient sum: 1.7894
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0057, bias: 0.1115
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 8 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0480, range=[-0.1104, 0.0022]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.581, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.581
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-17.887306
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=33.481041
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.627 0.491 -0.618 1.363 1.284 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.771, range=[-0.107, 2.368]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.771
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=8.724917
[DECODER] After pos encoding: 896/896 non-zero, sum=53.651234
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.925 -0.095 4.786 0.450 0.330 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.307, 4.001]
[DEBUG] Output sample values: 0.526 3.115 3.810 3.399 1.253 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.307, 4.001] Var:0.410
[LOSS] Calculated loss: 5.032
 [EOS penalty: 0.060][TRAINER] Loss stagnant (improvement: -0.058), boosting LR to 0.050
 Loss: 5.092 (LR: 0.0500)[LOSS] Gradient sum: 1.7803
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1243
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0640, range=[-0.1260, 0.0017]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.756

Época 97/100
  Procesando 8 muestras...
  Vocabulario objetivo: 2000 clases
    Muestra 1/8: [DEBUG] Forward - source: 10 tokens, target: 11 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.427 -0.946 1.318 0.551 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.827, range=[-0.107, 2.374]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=2.827
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=31.986837
[DECODER] After pos encoding: 1408/1408 non-zero, sum=102.717270
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.649 -0.168 5.122 0.596 -0.924 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.213, 4.691]
[DEBUG] Output sample values: 0.699 3.620 3.691 3.427 1.258 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.213, 4.691] Var:0.428
[LOSS] Calculated loss: 6.602
 [EOS penalty: 0.087] Loss: 6.688 (LR: 0.0200)[LOSS] Gradient sum: 1.7931
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0041, bias: 0.0814
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 11 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0211, range=[-0.0804, 0.0013]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.687, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.687
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-7.773623
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=43.594772
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.834 0.047 0.148 1.419 1.115 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.259, range=[-0.107, 2.376]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.259
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-2.925839
[DECODER] After pos encoding: 1024/1024 non-zero, sum=48.442574
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.359 -0.741 5.384 0.782 0.059 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-1.907, 4.260]
[DEBUG] Output sample values: 0.715 3.185 3.405 3.923 1.682 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-1.907, 4.260] Var:0.405
[LOSS] Calculated loss: 5.280
 [EOS penalty: 0.110][TRAINER] Loss stagnant (improvement: -0.117), boosting LR to 0.050
 Loss: 5.389 (LR: 0.0500)[LOSS] Gradient sum: 1.7845
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0059, bias: 0.1096
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 8 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0481, range=[-0.1110, 0.0024]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 7 tokens, target: 5 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.259, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.259
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.246510
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.172813
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000015
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -1.264 0.997 -0.606 1.024 1.175 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.443, range=[-0.107, 2.382]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.443
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.952007
[DECODER] After pos encoding: 640/640 non-zero, sum=71.012222
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -1.090 1.091 4.833 0.225 0.773 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.051, 4.067]
[DEBUG] Output sample values: 0.536 3.268 3.692 3.681 1.521 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.051, 4.067] Var:0.401
[LOSS] Calculated loss: 5.287
 [EOS penalty: 0.054] Loss: 5.341 (LR: 0.0180)[LOSS] Gradient sum: 1.7828
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0092, bias: 0.1787
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.1101, range=[-0.1769, 0.0031]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.721, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=2.721
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=30.780994
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.149437
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.261 0.550 -0.522 0.900 1.511 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.149, range=[-0.107, 2.385]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.149
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.317402
[DECODER] After pos encoding: 768/768 non-zero, sum=62.807755
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -1.244 0.392 3.968 0.065 1.018 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.281, 4.769]
[DEBUG] Output sample values: 0.016 2.916 4.747 3.706 1.747 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.281, 4.769] Var:0.421
[LOSS] Calculated loss: 5.388
 [EOS penalty: 0.055] Loss: 5.443 (LR: 0.0200)[LOSS] Gradient sum: 1.7768
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0075, bias: 0.1488
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0790, range=[-0.1427, 0.0026]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.639, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.639
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.548738
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.475082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.829 0.671 -0.549 1.279 0.876 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.668, range=[-0.107, 2.388]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.668
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.867109
[DECODER] After pos encoding: 896/896 non-zero, sum=63.793442
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.304 1.128 4.450 0.624 -0.057 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.388, 4.423]
[DEBUG] Output sample values: -0.205 3.584 4.251 3.602 1.293 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.388, 4.423] Var:0.408
[LOSS] Calculated loss: 5.822
 [EOS penalty: 0.065] Loss: 5.888 (LR: 0.0180)[LOSS] Gradient sum: 1.7837
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0066, bias: 0.1278
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0624, range=[-0.1247, 0.0020]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.132, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.132
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.812376
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.556019
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.115 0.156 -0.686 1.431 0.733 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.588, range=[-0.107, 2.390]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.588
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=6.656343
[DECODER] After pos encoding: 1280/1280 non-zero, sum=70.926689
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.903 0.140 4.890 0.940 -0.461 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.331, 4.329]
[DEBUG] Output sample values: 0.964 3.466 4.081 3.166 1.342 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.331, 4.329] Var:0.415
[LOSS] Calculated loss: 6.012
 [EOS penalty: 0.057] Loss: 6.069 (LR: 0.0180)[LOSS] Gradient sum: 1.7877
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0080, bias: 0.1682
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 10 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0283, range=[-0.0877, 0.0014]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.128, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.128
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=1.442956
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=59.259331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.956 1.081 -0.141 1.515 0.961 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.381, range=[-0.107, 2.391]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.381
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=15.620052
[DECODER] After pos encoding: 1024/1024 non-zero, sum=66.988403
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.120 0.974 5.513 1.317 0.105 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.071, 4.186]
[DEBUG] Output sample values: 0.768 3.497 3.821 3.819 1.696 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.071, 4.186] Var:0.411
[LOSS] Calculated loss: 5.979
 [EOS penalty: 0.089] Loss: 6.067 (LR: 0.0200)[LOSS] Gradient sum: 1.7892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0058, bias: 0.1115
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 8 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0480, range=[-0.1103, 0.0023]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.581, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.581
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-17.887306
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=33.481041
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.627 0.490 -0.618 1.364 1.284 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.790, range=[-0.107, 2.394]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.790
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=8.936299
[DECODER] After pos encoding: 896/896 non-zero, sum=53.862648
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.924 -0.097 4.791 0.445 0.328 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.308, 4.025]
[DEBUG] Output sample values: 0.528 3.124 3.840 3.400 1.262 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.308, 4.025] Var:0.412
[LOSS] Calculated loss: 5.006
 [EOS penalty: 0.060][TRAINER] Loss stagnant (improvement: -0.057), boosting LR to 0.050
 Loss: 5.066 (LR: 0.0500)[LOSS] Gradient sum: 1.7798
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1242
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0639, range=[-0.1259, 0.0017]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.744

Época 98/100
  Procesando 8 muestras...
  Vocabulario objetivo: 2000 clases
    Muestra 1/8: [DEBUG] Forward - source: 10 tokens, target: 11 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000009
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.426 -0.946 1.318 0.551 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.847, range=[-0.107, 2.400]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=2.847
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=32.207397
[DECODER] After pos encoding: 1407/1408 non-zero, sum=102.937828
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000016
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.650 -0.167 5.126 0.592 -0.926 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.213, 4.690]
[DEBUG] Output sample values: 0.701 3.624 3.712 3.431 1.263 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.213, 4.690] Var:0.429
[LOSS] Calculated loss: 6.596
 [EOS penalty: 0.086] Loss: 6.682 (LR: 0.0200)[LOSS] Gradient sum: 1.7931
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0043, bias: 0.0814
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 11 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0211, range=[-0.0804, 0.0013]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.687, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.687
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-7.773623
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=43.594772
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.835 0.047 0.148 1.419 1.115 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.240, range=[-0.107, 2.402]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.240
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-2.716772
[DECODER] After pos encoding: 1024/1024 non-zero, sum=48.651596
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.358 -0.741 5.387 0.781 0.057 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-1.911, 4.249]
[DEBUG] Output sample values: 0.716 3.200 3.433 3.911 1.686 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-1.911, 4.249] Var:0.406
[LOSS] Calculated loss: 5.266
 [EOS penalty: 0.108][TRAINER] Loss stagnant (improvement: -0.113), boosting LR to 0.050
 Loss: 5.375 (LR: 0.0500)[LOSS] Gradient sum: 1.7843
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0059, bias: 0.1095
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 8 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0480, range=[-0.1110, 0.0024]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 7 tokens, target: 5 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.259, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.259
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.246510
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.172813
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -1.264 0.997 -0.606 1.024 1.175 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.462, range=[-0.107, 2.407]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.462
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=39.173653
[DECODER] After pos encoding: 640/640 non-zero, sum=71.233841
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -1.089 1.092 4.840 0.222 0.772 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.052, 4.092]
[DEBUG] Output sample values: 0.538 3.273 3.718 3.702 1.531 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.052, 4.092] Var:0.402
[LOSS] Calculated loss: 5.273
 [EOS penalty: 0.055] Loss: 5.327 (LR: 0.0180)[LOSS] Gradient sum: 1.7825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0090, bias: 0.1787
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.1099, range=[-0.1768, 0.0032]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.721, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=2.721
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=30.780994
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.149437
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.261 0.550 -0.522 0.900 1.511 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.169, range=[-0.107, 2.410]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.169
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.541750
[DECODER] After pos encoding: 768/768 non-zero, sum=63.031956
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -1.242 0.392 3.971 0.063 1.016 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.283, 4.783]
[DEBUG] Output sample values: 0.017 2.928 4.763 3.700 1.750 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.283, 4.783] Var:0.422
[LOSS] Calculated loss: 5.379
 [EOS penalty: 0.054] Loss: 5.433 (LR: 0.0200)[LOSS] Gradient sum: 1.7765
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0076, bias: 0.1488
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0788, range=[-0.1426, 0.0026]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.639, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.639
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.548738
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.475082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.829 0.671 -0.549 1.279 0.876 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.687, range=[-0.107, 2.413]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.687
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=19.085413
[DECODER] After pos encoding: 896/896 non-zero, sum=64.011765
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.304 1.130 4.454 0.622 -0.058 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.392, 4.429]
[DEBUG] Output sample values: -0.204 3.579 4.271 3.591 1.300 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.392, 4.429] Var:0.409
[LOSS] Calculated loss: 5.816
 [EOS penalty: 0.065] Loss: 5.880 (LR: 0.0180)[LOSS] Gradient sum: 1.7836
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1278
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 895/896 non-zero, sum=-0.0623, range=[-0.1246, 0.0020]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.132, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.132
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.812376
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.556019
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.115 0.156 -0.686 1.431 0.734 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.607, range=[-0.107, 2.415]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.607
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=6.867544
[DECODER] After pos encoding: 1280/1280 non-zero, sum=71.137993
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.904 0.143 4.896 0.937 -0.462 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.331, 4.330]
[DEBUG] Output sample values: 0.965 3.476 4.092 3.155 1.350 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.331, 4.330] Var:0.416
[LOSS] Calculated loss: 6.005
 [EOS penalty: 0.056] Loss: 6.061 (LR: 0.0180)[LOSS] Gradient sum: 1.7876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0081, bias: 0.1681
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 10 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0282, range=[-0.0877, 0.0014]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.128, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.128
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=1.442956
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=59.259331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.956 1.081 -0.141 1.515 0.961 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.400, range=[-0.107, 2.417]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.400
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=15.841735
[DECODER] After pos encoding: 1024/1024 non-zero, sum=67.210121
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.119 0.974 5.516 1.315 0.104 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.072, 4.202]
[DEBUG] Output sample values: 0.768 3.509 3.844 3.827 1.703 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.072, 4.202] Var:0.412
[LOSS] Calculated loss: 5.970
 [EOS penalty: 0.089] Loss: 6.060 (LR: 0.0200)[LOSS] Gradient sum: 1.7891
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0057, bias: 0.1114
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 8 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0478, range=[-0.1103, 0.0024]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.581, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.581
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-17.887306
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=33.481041
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.627 0.490 -0.618 1.364 1.284 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.809, range=[-0.107, 2.419]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.809
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.147389
[DECODER] After pos encoding: 896/896 non-zero, sum=54.073746
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.921 -0.098 4.797 0.441 0.326 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.310, 4.031]
[DEBUG] Output sample values: 0.529 3.137 3.853 3.421 1.269 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.310, 4.031] Var:0.413
[LOSS] Calculated loss: 4.987
 [EOS penalty: 0.061][TRAINER] Loss stagnant (improvement: -0.058), boosting LR to 0.050
 Loss: 5.048 (LR: 0.0500)[LOSS] Gradient sum: 1.7794
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1241
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0638, range=[-0.1259, 0.0017]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.733

Época 99/100
  Procesando 8 muestras...
  Vocabulario objetivo: 2000 clases
    Muestra 1/8: [DEBUG] Forward - source: 10 tokens, target: 11 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.426 -0.946 1.318 0.551 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.866, range=[-0.107, 2.425]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=2.866
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=32.427605
[DECODER] After pos encoding: 1408/1408 non-zero, sum=103.158012
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.650 -0.167 5.131 0.588 -0.927 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.213, 4.700]
[DEBUG] Output sample values: 0.702 3.628 3.710 3.434 1.269 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.213, 4.700] Var:0.430
[LOSS] Calculated loss: 6.589
 [EOS penalty: 0.086] Loss: 6.675 (LR: 0.0200)[LOSS] Gradient sum: 1.7930
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0042, bias: 0.0814
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 11 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0210, range=[-0.0804, 0.0013]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.687, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.687
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-7.773623
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=43.594772
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.835 0.047 0.148 1.419 1.115 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.222, range=[-0.107, 2.427]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.222
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-2.508063
[DECODER] After pos encoding: 1024/1024 non-zero, sum=48.860291
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.357 -0.741 5.391 0.779 0.056 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-1.915, 4.284]
[DEBUG] Output sample values: 0.718 3.215 3.433 3.935 1.690 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-1.915, 4.284] Var:0.407
[LOSS] Calculated loss: 5.249
 [EOS penalty: 0.111][TRAINER] Loss stagnant (improvement: -0.110), boosting LR to 0.050
 Loss: 5.361 (LR: 0.0500)[LOSS] Gradient sum: 1.7840
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0056, bias: 0.1095
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 8 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0479, range=[-0.1110, 0.0025]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 7 tokens, target: 5 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.259, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.259
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.246510
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.172813
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000013
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -1.265 0.997 -0.606 1.024 1.175 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.482, range=[-0.107, 2.433]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.482
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=39.394875
[DECODER] After pos encoding: 640/640 non-zero, sum=71.455070
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000012
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -1.088 1.094 4.846 0.220 0.772 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.051, 4.124]
[DEBUG] Output sample values: 0.539 3.292 3.723 3.713 1.542 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.051, 4.124] Var:0.403
[LOSS] Calculated loss: 5.257
 [EOS penalty: 0.056] Loss: 5.312 (LR: 0.0180)[LOSS] Gradient sum: 1.7822
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0091, bias: 0.1787
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.1098, range=[-0.1768, 0.0032]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.721, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=2.721
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=30.780994
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.149437
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.262 0.550 -0.522 0.900 1.511 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.189, range=[-0.107, 2.436]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.189
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.765585
[DECODER] After pos encoding: 768/768 non-zero, sum=63.255882
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -1.241 0.393 3.974 0.060 1.015 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.285, 4.811]
[DEBUG] Output sample values: 0.018 2.935 4.790 3.721 1.757 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.285, 4.811] Var:0.423
[LOSS] Calculated loss: 5.364
 [EOS penalty: 0.055] Loss: 5.420 (LR: 0.0200)[LOSS] Gradient sum: 1.7760
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0077, bias: 0.1488
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0786, range=[-0.1424, 0.0026]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.639, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.639
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.548738
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.475082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.829 0.670 -0.549 1.279 0.877 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.706, range=[-0.107, 2.439]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.706
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=19.303324
[DECODER] After pos encoding: 896/896 non-zero, sum=64.229645
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.303 1.130 4.457 0.619 -0.058 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.395, 4.433]
[DEBUG] Output sample values: -0.204 3.588 4.274 3.606 1.306 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.395, 4.433] Var:0.410
[LOSS] Calculated loss: 5.804
 [EOS penalty: 0.066] Loss: 5.870 (LR: 0.0180)[LOSS] Gradient sum: 1.7834
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0064, bias: 0.1278
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0622, range=[-0.1246, 0.0020]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.132, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.132
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.812376
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.556019
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.115 0.156 -0.686 1.431 0.734 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.626, range=[-0.107, 2.441]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.626
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=7.078353
[DECODER] After pos encoding: 1280/1280 non-zero, sum=71.348801
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.904 0.145 4.901 0.933 -0.463 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.331, 4.340]
[DEBUG] Output sample values: 0.966 3.475 4.109 3.167 1.357 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.331, 4.340] Var:0.417
[LOSS] Calculated loss: 5.997
 [EOS penalty: 0.056] Loss: 6.053 (LR: 0.0180)[LOSS] Gradient sum: 1.7875
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0084, bias: 0.1681
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 10 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0281, range=[-0.0877, 0.0014]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.128, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.128
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=1.442956
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=59.259331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000010
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.956 1.081 -0.141 1.515 0.961 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.420, range=[-0.107, 2.442]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.420
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=16.062954
[DECODER] After pos encoding: 1024/1024 non-zero, sum=67.431335
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.117 0.974 5.518 1.313 0.102 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.073, 4.200]
[DEBUG] Output sample values: 0.769 3.511 3.841 3.828 1.708 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.073, 4.200] Var:0.413
[LOSS] Calculated loss: 5.964
 [EOS penalty: 0.089] Loss: 6.053 (LR: 0.0200)[LOSS] Gradient sum: 1.7891
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0057, bias: 0.1114
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 8 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0478, range=[-0.1103, 0.0023]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.581, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.581
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-17.887306
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=33.481041
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.627 0.490 -0.618 1.363 1.284 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.827, range=[-0.107, 2.445]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.827
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.358086
[DECODER] After pos encoding: 896/896 non-zero, sum=54.284424
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000009
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.919 -0.100 4.801 0.436 0.324 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.311, 4.041]
[DEBUG] Output sample values: 0.529 3.135 3.866 3.423 1.279 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.311, 4.041] Var:0.414
[LOSS] Calculated loss: 4.975
 [EOS penalty: 0.061][TRAINER] Loss stagnant (improvement: -0.061), boosting LR to 0.050
 Loss: 5.036 (LR: 0.0500)[LOSS] Gradient sum: 1.7791
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1239
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0637, range=[-0.1259, 0.0017]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.722

Época 100/100
  Procesando 8 muestras...
  Vocabulario objetivo: 2000 clases
    Muestra 1/8: [DEBUG] Forward - source: 10 tokens, target: 11 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000019
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.339 0.426 -0.946 1.318 0.552 
[DECODER] Starting decode with 11 tokens
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.886, range=[-0.107, 2.451]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=2.886
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=32.647354
[DECODER] After pos encoding: 1408/1408 non-zero, sum=103.377930
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 11x128
[DEBUG] Decoder sample values: -1.651 -0.167 5.135 0.584 -0.929 
[DEBUG] Output projection - shape: 11x2000
[DEBUG] Output range: [-2.213, 4.709]
[DEBUG] Output sample values: 0.703 3.628 3.738 3.437 1.279 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.213, 4.709] Var:0.431
[LOSS] Calculated loss: 6.580
 [EOS penalty: 0.087] Loss: 6.667 (LR: 0.0200)[LOSS] Gradient sum: 1.7929
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0043, bias: 0.0814
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 11 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.0210, range=[-0.0803, 0.0013]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 2/8: [DEBUG] Forward - source: 8 tokens, target: 8 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.687, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-0.687
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-7.773623
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=43.594772
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -0.835 0.046 0.148 1.419 1.115 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.203, range=[-0.107, 2.453]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.203
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-2.299801
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.068649
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.355 -0.741 5.394 0.776 0.054 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-1.918, 4.300]
[DEBUG] Output sample values: 0.719 3.213 3.458 3.938 1.700 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-1.918, 4.300] Var:0.408
[LOSS] Calculated loss: 5.233
 [EOS penalty: 0.112][TRAINER] Loss stagnant (improvement: -0.111), boosting LR to 0.050
 Loss: 5.345 (LR: 0.0500)[LOSS] Gradient sum: 1.7837
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0057, bias: 0.1094
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 8 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0478, range=[-0.1110, 0.0025]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
    Muestra 3/8: [DEBUG] Forward - source: 7 tokens, target: 5 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.259, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.259
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.246510
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.172813
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -1.265 0.997 -0.606 1.024 1.175 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.502, range=[-0.107, 2.458]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.502
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=39.615757
[DECODER] After pos encoding: 640/640 non-zero, sum=71.675941
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -1.088 1.095 4.852 0.217 0.770 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-2.051, 4.140]
[DEBUG] Output sample values: 0.540 3.293 3.737 3.730 1.554 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.051, 4.140] Var:0.404
[LOSS] Calculated loss: 5.248
 [EOS penalty: 0.057] Loss: 5.304 (LR: 0.0180)[LOSS] Gradient sum: 1.7821
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0091, bias: 0.1786
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 5 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.1096, range=[-0.1767, 0.0032]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 4/8: [DEBUG] Forward - source: 8 tokens, target: 6 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.721, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=2.721
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=30.780994
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.149437
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.262 0.550 -0.522 0.900 1.511 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.209, range=[-0.107, 2.461]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=2.209
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=24.989164
[DECODER] After pos encoding: 768/768 non-zero, sum=63.479500
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -1.240 0.394 3.976 0.058 1.013 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.287, 4.847]
[DEBUG] Output sample values: 0.019 2.933 4.821 3.718 1.766 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.287, 4.847] Var:0.424
[LOSS] Calculated loss: 5.355
 [EOS penalty: 0.055] Loss: 5.410 (LR: 0.0200)[LOSS] Gradient sum: 1.7756
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0078, bias: 0.1488
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 6 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.0783, range=[-0.1422, 0.0026]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 5/8: [DEBUG] Forward - source: 7 tokens, target: 7 tokens
[ENCODER] Starting encode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.639, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 896/896 non-zero, sum=1.639
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.548738
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.475082
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 7x128
[DEBUG] Encoder sample values: -0.829 0.670 -0.549 1.279 0.877 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.725, range=[-0.107, 2.464]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.725
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=19.520853
[DECODER] After pos encoding: 896/896 non-zero, sum=64.447227
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -0.303 1.131 4.460 0.616 -0.059 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.400, 4.440]
[DEBUG] Output sample values: -0.203 3.586 4.293 3.608 1.317 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.400, 4.440] Var:0.411
[LOSS] Calculated loss: 5.797
 [EOS penalty: 0.066] Loss: 5.863 (LR: 0.0180)[LOSS] Gradient sum: 1.7833
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1277
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 7 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0621, range=[-0.1246, 0.0020]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 6/8: [DEBUG] Forward - source: 8 tokens, target: 10 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.132, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.132
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.812376
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=38.556019
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.116 0.156 -0.686 1.431 0.734 
[DECODER] Starting decode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=0.644, range=[-0.107, 2.466]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=0.644
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=7.288820
[DECODER] After pos encoding: 1280/1280 non-zero, sum=71.559258
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 10x128
[DEBUG] Decoder sample values: -0.905 0.147 4.906 0.931 -0.465 
[DEBUG] Output projection - shape: 10x2000
[DEBUG] Output range: [-2.330, 4.342]
[DEBUG] Output sample values: 0.967 3.483 4.127 3.179 1.369 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.330, 4.342] Var:0.418
[LOSS] Calculated loss: 5.990
 [EOS penalty: 0.057] Loss: 6.047 (LR: 0.0180)[LOSS] Gradient sum: 1.7874
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0087, bias: 0.1681
[LINEAR] Output projection - using 5x learning rate: 0.0900
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[ATTENTION] Weights updated with lr=0.0180
[FEEDFORWARD] Weights updated with lr=0.0180
[EMBEDDING] Updating weights for 10 tokens with lr=0.0180
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.0280, range=[-0.0876, 0.0015]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01800000
[UPDATE] Gradientes aplicados con lr=0.01800000 [Updated]
    Muestra 7/8: [DEBUG] Forward - source: 9 tokens, target: 8 tokens
[ENCODER] Starting encode with 9 tokens
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.128, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1152/1152 non-zero, sum=0.128
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=1.442956
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=59.259331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 9x128
[DEBUG] Encoder sample values: -0.956 1.080 -0.141 1.515 0.961 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.439, range=[-0.107, 2.468]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.439
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=16.283779
[DECODER] After pos encoding: 1024/1024 non-zero, sum=67.652176
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000011
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -0.116 0.974 5.521 1.311 0.101 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.073, 4.202]
[DEBUG] Output sample values: 0.769 3.530 3.860 3.838 1.717 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.073, 4.202] Var:0.414
[LOSS] Calculated loss: 5.957
 [EOS penalty: 0.090] Loss: 6.047 (LR: 0.0200)[LOSS] Gradient sum: 1.7890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0060, bias: 0.1114
[LINEAR] Output projection - using 5x learning rate: 0.1000
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[ATTENTION] Weights updated with lr=0.0200
[FEEDFORWARD] Weights updated with lr=0.0200
[EMBEDDING] Updating weights for 8 tokens with lr=0.0200
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.0477, range=[-0.1103, 0.0024]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.02000000
[UPDATE] Gradientes aplicados con lr=0.02000000 [Updated]
    Muestra 8/8: [DEBUG] Forward - source: 8 tokens, target: 7 tokens
[ENCODER] Starting encode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.581, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1024/1024 non-zero, sum=-1.581
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-17.887306
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=33.481041
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 8x128
[DEBUG] Encoder sample values: -1.627 0.490 -0.618 1.363 1.284 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.846, range=[-0.107, 2.470]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.846
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.568401
[DECODER] After pos encoding: 896/896 non-zero, sum=54.494766
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -1.918 -0.102 4.806 0.431 0.322 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.312, 4.075]
[DEBUG] Output sample values: 0.530 3.142 3.899 3.446 1.282 
[DEBUG] Forward completed!
FWD✓ [LOSS] Predictions range: [-2.312, 4.075] Var:0.415
[LOSS] Calculated loss: 4.957
 [EOS penalty: 0.062][TRAINER] Loss stagnant (improvement: -0.062), boosting LR to 0.050
 Loss: 5.019 (LR: 0.0500)[LOSS] Gradient sum: 1.7787
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Max gradients - weights: 0.0065, bias: 0.1239
[LINEAR] Output projection - using 5x learning rate: 0.2500
[LINEAR] Weights updated
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[ATTENTION] Weights updated with lr=0.0500
[FEEDFORWARD] Weights updated with lr=0.0500
[EMBEDDING] Updating weights for 7 tokens with lr=0.0500
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.0635, range=[-0.1258, 0.0018]
[EMBEDDING] Sample weights after update: -0.08371182 -0.09513368 -0.03629364 0.01341167 0.04031998 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[UPDATE] Gradientes aplicados con lr=0.05000000 [Updated]
  Promedio de loss: 5.713
  === Progreso en época 100 ===
[DEBUG] Forward - source: 10 tokens, target: 1 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.340 0.426 -0.946 1.317 0.551 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.577, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.577
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=29.155437
[DECODER] After pos encoding: 128/128 non-zero, sum=35.555450
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.234 0.177 2.612 0.922 0.368 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-1.865, 3.999]
[DEBUG] Output sample values: 0.195 2.813 3.999 3.294 1.199 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 7 (score: 3.0, target_len: 9) [Top scores: 95:3.2 7:3.0 98:2.8 507:2.7 21:2.5 ]
[DEBUG] Forward - source: 10 tokens, target: 2 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.340 0.426 -0.946 1.317 0.551 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.762, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.762
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=31.244585
[DECODER] After pos encoding: 256/256 non-zero, sum=44.050632
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -1.852 -0.386 3.176 0.621 -0.403 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-1.873, 4.374]
[DEBUG] Output sample values: 0.155 2.744 4.225 3.607 1.582 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 507 (score: 3.0, target_len: 9) [Top scores: 507:3.0 98:3.0 95:3.0 19:2.8 881:2.4 ]
[DEBUG] Forward - source: 10 tokens, target: 3 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.340 0.426 -0.946 1.317 0.551 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1.331, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1.331
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=15.059565
[DECODER] After pos encoding: 384/384 non-zero, sum=34.277660
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000004
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -2.109 -0.101 3.214 0.575 -0.506 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-1.897, 4.579]
[DEBUG] Output sample values: 0.091 2.838 4.352 3.753 1.629 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 98 (score: 3.4, target_len: 9) [Top scores: 98:3.4 95:3.2 21:2.6 677:2.6 881:2.6 ]
[DEBUG] Forward - source: 10 tokens, target: 4 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.340 0.426 -0.946 1.317 0.551 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=2.168, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=2.168
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=24.526627
[DECODER] After pos encoding: 512/512 non-zero, sum=50.162785
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -2.283 -0.034 3.539 0.272 -0.706 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.041, 4.638]
[DEBUG] Output sample values: 0.272 3.263 4.331 3.946 1.393 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 5 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.340 0.426 -0.946 1.317 0.551 
[DECODER] Starting decode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.318, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.318
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=14.909710
[DECODER] After pos encoding: 640/640 non-zero, sum=46.969933
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 5x128
[DEBUG] Decoder sample values: -2.269 -0.168 3.562 0.482 -0.761 
[DEBUG] Output projection - shape: 5x2000
[DEBUG] Output range: [-1.980, 4.439]
[DEBUG] Output sample values: 0.304 3.334 4.272 3.804 1.445 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 6 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.340 0.426 -0.946 1.317 0.551 
[DECODER] Starting decode with 6 tokens
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.933, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=0.933
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=10.558003
[DECODER] After pos encoding: 768/768 non-zero, sum=49.048298
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 6x128
[DEBUG] Decoder sample values: -2.561 0.091 3.956 0.251 -0.796 
[DEBUG] Output projection - shape: 6x2000
[DEBUG] Output range: [-2.244, 4.341]
[DEBUG] Output sample values: 0.431 3.454 4.105 3.777 1.557 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 7 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.340 0.426 -0.946 1.317 0.551 
[DECODER] Starting decode with 7 tokens
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.215, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1.215
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=13.749351
[DECODER] After pos encoding: 896/896 non-zero, sum=58.675709
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 7x128
[DEBUG] Decoder sample values: -2.383 0.077 3.980 0.297 -0.797 
[DEBUG] Output projection - shape: 7x2000
[DEBUG] Output range: [-2.234, 4.329]
[DEBUG] Output sample values: 0.375 3.444 4.067 3.774 1.564 
[DEBUG] Forward completed!
[DEBUG] Forward - source: 10 tokens, target: 8 tokens
[ENCODER] Starting encode with 10 tokens
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.728, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 1280/1280 non-zero, sum=-0.728
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-8.240268
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=56.030170
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 10x128
[DEBUG] Encoder sample values: -1.340 0.426 -0.946 1.317 0.551 
[DECODER] Starting decode with 8 tokens
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.215, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.215
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-2.435670
[DECODER] After pos encoding: 1024/1024 non-zero, sum=48.932777
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 8x128
[DEBUG] Decoder sample values: -2.309 0.078 3.932 0.286 -0.839 
[DEBUG] Output projection - shape: 8x2000
[DEBUG] Output range: [-2.239, 4.297]
[DEBUG] Output sample values: 0.425 3.477 4.093 3.743 1.585 
[DEBUG] Forward completed!
  ENG: <sos> my grandfather is a bit hard of hearing <eos>
  ESP: <sos> que tuve ana ma lo una tuve ana
  ================================

¡Entrenamiento completado!

=== Pruebas de Traducción ===
[DEBUG] Forward - source: 3 tokens, target: 1 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.475, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-0.475
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-5.378339
[ENCODER] After pos encoding: 384/384 non-zero, sum=13.839719
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: -1.023 0.949 -0.473 1.176 1.062 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.577, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.577
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=29.155437
[DECODER] After pos encoding: 128/128 non-zero, sum=35.555450
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.897 0.689 2.926 0.727 0.956 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-1.899, 3.956]
[DEBUG] Output sample values: -0.044 2.953 3.956 3.285 1.103 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 95 (score: 3.2, target_len: 2) [Top scores: 95:3.2 7:2.9 93:2.8 98:2.8 507:2.7 ]
[DEBUG] Forward - source: 3 tokens, target: 2 tokens
[ENCODER] Starting encode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.475, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 384/384 non-zero, sum=-0.475
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-5.378339
[ENCODER] After pos encoding: 384/384 non-zero, sum=13.839719
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 3x128
[DEBUG] Encoder sample values: -1.023 0.949 -0.473 1.176 1.062 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1.727, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1.727
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=19.538523
[DECODER] After pos encoding: 256/256 non-zero, sum=32.344559
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.645 0.973 3.419 0.525 0.689 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-1.933, 3.919]
[DEBUG] Output sample values: -0.288 3.419 3.919 3.221 1.189 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 507 (score: 3.0, target_len: 2) [Top scores: 98:3.0 507:3.0 7:2.9 677:2.8 21:2.8 ]
ENG: <sos> hello <eos>
ESP: <sos> ma tuve <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.413, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.413
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=15.982855
[ENCODER] After pos encoding: 640/640 non-zero, sum=48.043022
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.246 1.045 -0.322 1.163 1.202 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.577, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.577
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=29.155437
[DECODER] After pos encoding: 128/128 non-zero, sum=35.555450
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -0.949 0.815 3.230 0.787 1.037 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-2.095, 4.061]
[DEBUG] Output sample values: 0.048 2.839 4.061 3.523 1.239 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 7 (score: 2.9, target_len: 4) [Top scores: 7:2.9 98:2.9 507:2.8 93:2.8 95:2.6 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.413, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.413
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=15.982855
[ENCODER] After pos encoding: 640/640 non-zero, sum=48.043022
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.246 1.045 -0.322 1.163 1.202 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.762, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.762
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=31.244585
[DECODER] After pos encoding: 256/256 non-zero, sum=44.050632
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000007
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.864 0.621 3.524 0.838 0.932 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.121, 4.207]
[DEBUG] Output sample values: -0.026 2.903 4.053 3.595 1.285 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 98 (score: 3.1, target_len: 4) [Top scores: 98:3.1 507:3.0 93:2.7 881:2.5 75:2.3 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.413, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.413
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=15.982855
[ENCODER] After pos encoding: 640/640 non-zero, sum=48.043022
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.246 1.045 -0.322 1.163 1.202 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=3.598, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=3.598
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=40.711632
[DECODER] After pos encoding: 384/384 non-zero, sum=59.929733
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.411 1.637 4.429 0.039 0.705 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.150, 4.231]
[DEBUG] Output sample values: -0.264 3.298 4.069 3.801 1.554 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 881 (score: 2.7, target_len: 4) [Top scores: 881:2.7 95:2.7 507:2.6 93:2.4 677:2.3 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.413, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=1.413
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=15.982855
[ENCODER] After pos encoding: 640/640 non-zero, sum=48.043022
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000006
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.246 1.045 -0.322 1.163 1.202 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=3.738, range=[-0.107, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=3.738
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=42.288391
[DECODER] After pos encoding: 512/512 non-zero, sum=67.924538
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -0.767 1.720 4.685 -0.036 0.881 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.123, 4.467]
[DEBUG] Output sample values: -0.008 3.380 4.139 4.034 1.701 
[DEBUG] Forward completed!
ENG: <sos> how are you <eos>
ESP: <sos> que ana ped tuve <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.545, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.545
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-17.481731
[ENCODER] After pos encoding: 512/512 non-zero, sum=8.154400
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.602 0.305 -0.548 0.695 1.053 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.577, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.577
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=29.155437
[DECODER] After pos encoding: 128/128 non-zero, sum=35.555450
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.332 0.032 2.969 0.289 0.885 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-1.991, 4.040]
[DEBUG] Output sample values: 0.236 2.830 4.040 3.486 1.143 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 7 (score: 3.0, target_len: 3) [Top scores: 93:3.1 95:3.1 7:3.0 98:2.8 507:2.6 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.545, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.545
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-17.481731
[ENCODER] After pos encoding: 512/512 non-zero, sum=8.154400
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.602 0.305 -0.548 0.695 1.053 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.762, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.762
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=31.244585
[DECODER] After pos encoding: 256/256 non-zero, sum=44.050632
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -1.328 -0.563 3.271 -0.274 0.853 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.094, 4.229]
[DEBUG] Output sample values: 0.233 3.077 4.081 3.739 1.167 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 507 (score: 2.9, target_len: 3) [Top scores: 93:3.6 507:2.9 98:2.9 19:2.8 95:2.8 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.545, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=-1.545
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-17.481731
[ENCODER] After pos encoding: 512/512 non-zero, sum=8.154400
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.602 0.305 -0.548 0.695 1.053 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1.331, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1.331
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=15.059565
[DECODER] After pos encoding: 384/384 non-zero, sum=34.277660
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000000
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -1.749 -0.002 4.252 -0.540 -0.246 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-1.786, 4.499]
[DEBUG] Output sample values: 0.455 3.207 3.799 3.689 1.391 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 98 (score: 3.3, target_len: 3) [Top scores: 98:3.3 95:3.2 93:3.2 780:2.9 19:2.7 ]
ENG: <sos> good morning <eos>
ESP: <sos> que tuve ana <eos>
---
[DEBUG] Forward - source: 4 tokens, target: 1 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.378, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=0.378
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=4.271219
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.907333
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.548 1.269 -0.394 1.121 1.370 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.577, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.577
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=29.155437
[DECODER] After pos encoding: 128/128 non-zero, sum=35.555450
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.285 0.929 3.130 0.743 1.167 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-1.927, 4.068]
[DEBUG] Output sample values: 0.121 2.716 4.068 3.603 1.231 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 98 (score: 3.0, target_len: 3) [Top scores: 98:3.0 7:2.9 507:2.8 93:2.8 95:2.8 ]
[DEBUG] Forward - source: 4 tokens, target: 2 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.378, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=0.378
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=4.271219
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.907333
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.548 1.269 -0.394 1.121 1.370 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=3.414, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=3.414
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=38.622482
[DECODER] After pos encoding: 256/256 non-zero, sum=51.428539
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -1.465 1.355 3.919 0.534 1.051 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.116, 4.085]
[DEBUG] Output sample values: -0.096 2.612 3.874 3.905 1.386 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 7 (score: 2.9, target_len: 3) [Top scores: 7:2.9 95:2.9 507:2.7 93:2.7 881:2.6 ]
[DEBUG] Forward - source: 4 tokens, target: 3 tokens
[ENCODER] Starting encode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.378, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 512/512 non-zero, sum=0.378
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=4.271219
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.907333
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 4x128
[DEBUG] Encoder sample values: -1.548 1.269 -0.394 1.121 1.370 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=3.598, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=3.598
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=40.711662
[DECODER] After pos encoding: 384/384 non-zero, sum=59.929749
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -1.783 1.693 4.498 0.269 1.322 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-1.924, 4.691]
[DEBUG] Output sample values: 0.321 3.047 4.079 4.309 1.729 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 507 (score: 3.2, target_len: 3) [Top scores: 507:3.2 93:2.8 881:2.7 19:2.6 847:2.4 ]
ENG: <sos> thank you <eos>
ESP: <sos> ana que tuve <eos>
---
[DEBUG] Forward - source: 5 tokens, target: 1 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.046, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-1.046
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.834213
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.225986
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.177 0.933 -0.466 1.414 1.453 
[DECODER] Starting decode with 1 tokens
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=2.577, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=2.577
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=29.155437
[DECODER] After pos encoding: 128/128 non-zero, sum=35.555450
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 1x128
[DEBUG] Decoder sample values: -1.037 0.707 2.992 1.007 1.312 
[DEBUG] Output projection - shape: 1x2000
[DEBUG] Output range: [-1.966, 4.112]
[DEBUG] Output sample values: 0.178 2.745 4.112 3.519 1.404 
[DEBUG] Forward completed!
[GEN] Step 0 - Best token: 507 (score: 3.1, target_len: 4) [Top scores: 507:3.1 7:2.8 98:2.7 93:2.7 95:2.7 ]
[DEBUG] Forward - source: 5 tokens, target: 2 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.046, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-1.046
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.834213
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.225986
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.177 0.933 -0.466 1.414 1.453 
[DECODER] Starting decode with 2 tokens
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1.146, range=[-0.105, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1.146
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=12.970419
[DECODER] After pos encoding: 256/256 non-zero, sum=25.776447
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 2x128
[DEBUG] Decoder sample values: -0.843 0.341 3.888 1.604 1.236 
[DEBUG] Output projection - shape: 2x2000
[DEBUG] Output range: [-2.133, 4.152]
[DEBUG] Output sample values: 0.230 2.749 4.152 3.451 1.853 
[DEBUG] Forward completed!
[GEN] Step 1 - Best token: 98 (score: 2.9, target_len: 4) [Top scores: 98:2.9 4:2.8 7:2.8 677:2.7 21:2.7 ]
[DEBUG] Forward - source: 5 tokens, target: 3 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.046, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-1.046
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.834213
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.225986
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.177 0.933 -0.466 1.414 1.453 
[DECODER] Starting decode with 3 tokens
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1.983, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1.983
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=22.437477
[DECODER] After pos encoding: 384/384 non-zero, sum=41.655548
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 3x128
[DEBUG] Decoder sample values: -0.499 0.561 4.012 1.266 1.299 
[DEBUG] Output projection - shape: 3x2000
[DEBUG] Output range: [-2.154, 4.418]
[DEBUG] Output sample values: 0.186 3.011 4.300 3.686 1.908 
[DEBUG] Forward completed!
[GEN] Step 2 - Best token: 7 (score: 2.7, target_len: 4) [Top scores: 7:2.7 95:2.7 677:2.6 881:2.6 93:2.4 ]
[DEBUG] Forward - source: 5 tokens, target: 4 tokens
[ENCODER] Starting encode with 5 tokens
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.046, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[ENCODER] Embeddings stats: 640/640 non-zero, sum=-1.046
[ENCODER] Scaling embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.834213
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.225986
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[ENCODER] Encoding complete
[DEBUG] Encode OK - shape: 5x128
[DEBUG] Encoder sample values: -1.177 0.933 -0.466 1.414 1.453 
[DECODER] Starting decode with 4 tokens
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=2.168, range=[-0.106, 2.476]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=2.168
[DECODER] Scaling target embeddings by 11.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=24.526628
[DECODER] After pos encoding: 512/512 non-zero, sum=50.162769
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DECODER] Decoding complete
[DEBUG] Decode OK - shape: 4x128
[DEBUG] Decoder sample values: -1.065 1.027 4.613 0.892 1.464 
[DEBUG] Output projection - shape: 4x2000
[DEBUG] Output range: [-2.086, 4.631]
[DEBUG] Output sample values: 0.487 3.254 4.400 4.051 2.084 
[DEBUG] Forward completed!
ENG: <sos> i love you <eos>
ESP: <sos> tuve ana que ped <eos>
---