Se truncaron las últimas líneas 5000 del resultado de transmisión.
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: -1.821 -0.406 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.164, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.164
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-1.850205
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.518124
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.793 -0.108 0.249 -0.024 1.201 
[DEBUG] Output range: [-2.474, 2.402]
[DEBUG] Output sample values: 0.450 0.023 0.568 0.811 -0.028 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.533, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=6.025813
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=63.842281
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -1.824 -0.409 -0.504 0.116 1.296 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.935, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.935
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.580652
[DECODER] After pos encoding: 768/768 non-zero, sum=27.909615
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -1.795 -0.108 0.250 -0.020 1.203 
[DEBUG] Output range: [-2.628, 2.143]
[DEBUG] Output sample values: 0.452 0.024 0.565 0.808 -0.024 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.951827
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.538464
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -1.821 -0.404 -0.506 0.113 1.293 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.453, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.453
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.122741
[DECODER] After pos encoding: 640/640 non-zero, sum=26.937452
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -1.793 -0.106 0.250 -0.021 1.200 
[DEBUG] Output range: [-2.103, 2.139]
[DEBUG] Output sample values: 0.451 0.024 0.567 0.811 -0.026 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.925, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.466502
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.593699
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -1.819 -0.409 -0.508 0.120 1.296 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.255, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.255
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.882822
[DECODER] After pos encoding: 640/640 non-zero, sum=34.943016
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.792 -0.109 0.248 -0.016 1.202 
[DEBUG] Output range: [-2.315, 2.169]
[DEBUG] Output sample values: 0.450 0.022 0.567 0.811 -0.025 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-20.048559
[ENCODER] After pos encoding: 768/768 non-zero, sum=18.441727
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -1.818 -0.406 -0.505 0.109 1.294 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.078, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.078
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.513559
[DECODER] After pos encoding: 640/640 non-zero, sum=55.573719
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -1.790 -0.107 0.250 -0.023 1.201 
[DEBUG] Output range: [-2.172, 2.233]
[DEBUG] Output sample values: 0.450 0.019 0.570 0.815 -0.027 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
Epoca 143/150 - Loss: 7.3710 | LR: 7.738e-04

Época 144/150
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-3.099, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-3.099
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-35.066227
[DECODER] After pos encoding: 768/768 non-zero, sum=3.424000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -1.796 -0.101 0.244 -0.025 1.194 
[DEBUG] Output range: [-2.492, 2.871]
[DEBUG] Output sample values: 0.449 0.025 0.571 0.817 -0.026 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.757, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=31.190388
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.558838
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -1.820 -0.406 -0.506 0.107 1.295 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-2.719, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-2.719
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-30.765455
[DECODER] After pos encoding: 1280/1280 non-zero, sum=33.505013
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.793 -0.107 0.250 -0.026 1.202 
[DEBUG] Output range: [-2.265, 2.670]
[DEBUG] Output sample values: 0.451 0.024 0.571 0.813 -0.025 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.347605
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=75.716080
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -1.823 -0.408 -0.507 0.111 1.292 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.049, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.049
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.863651
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.504734
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.794 -0.108 0.249 -0.023 1.199 
[DEBUG] Output range: [-2.551, 2.362]
[DEBUG] Output sample values: 0.451 0.023 0.570 0.815 -0.025 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.043, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-23.117678
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=28.250721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -1.821 -0.406 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.164, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.164
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-1.852253
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.516136
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.793 -0.108 0.249 -0.024 1.201 
[DEBUG] Output range: [-2.474, 2.402]
[DEBUG] Output sample values: 0.450 0.024 0.573 0.816 -0.027 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.533, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=6.025813
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=63.842281
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -1.824 -0.409 -0.504 0.116 1.296 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.935, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.935
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.582699
[DECODER] After pos encoding: 768/768 non-zero, sum=27.907558
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -1.795 -0.108 0.250 -0.020 1.203 
[DEBUG] Output range: [-2.628, 2.143]
[DEBUG] Output sample values: 0.452 0.025 0.570 0.813 -0.022 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.951827
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.538464
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: -1.821 -0.404 -0.506 0.113 1.293 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.453, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.453
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.124698
[DECODER] After pos encoding: 640/640 non-zero, sum=26.935495
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000009
[DEBUG] Decoder sample values: -1.793 -0.106 0.250 -0.021 1.200 
[DEBUG] Output range: [-2.103, 2.139]
[DEBUG] Output sample values: 0.451 0.026 0.572 0.816 -0.024 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.925, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.466502
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.593699
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -1.819 -0.409 -0.508 0.120 1.296 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.255, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.255
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.881130
[DECODER] After pos encoding: 640/640 non-zero, sum=34.941311
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.792 -0.109 0.248 -0.016 1.203 
[DEBUG] Output range: [-2.315, 2.169]
[DEBUG] Output sample values: 0.450 0.023 0.572 0.817 -0.024 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-20.048559
[ENCODER] After pos encoding: 768/768 non-zero, sum=18.441727
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -1.818 -0.406 -0.505 0.109 1.294 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.078, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.078
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.511593
[DECODER] After pos encoding: 640/640 non-zero, sum=55.571774
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.790 -0.107 0.250 -0.023 1.201 
[DEBUG] Output range: [-2.172, 2.233]
[DEBUG] Output sample values: 0.450 0.021 0.575 0.821 -0.025 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
Epoca 144/150 - Loss: 7.3686 | LR: 7.738e-04

Época 145/150
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-3.100, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-3.100
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-35.067974
[DECODER] After pos encoding: 768/768 non-zero, sum=3.422283
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.795 -0.101 0.244 -0.025 1.194 
[DEBUG] Output range: [-2.492, 2.870]
[DEBUG] Output sample values: 0.449 0.027 0.576 0.823 -0.025 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.757, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=31.190388
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.558838
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -1.820 -0.406 -0.506 0.107 1.295 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-2.719, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-2.719
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-30.767307
[DECODER] After pos encoding: 1280/1280 non-zero, sum=33.503120
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: -1.793 -0.107 0.250 -0.026 1.202 
[DEBUG] Output range: [-2.265, 2.670]
[DEBUG] Output sample values: 0.451 0.026 0.576 0.819 -0.023 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.347605
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=75.716080
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.823 -0.408 -0.507 0.111 1.292 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.049, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.049
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.865634
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.502758
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.793 -0.108 0.249 -0.023 1.199 
[DEBUG] Output range: [-2.551, 2.362]
[DEBUG] Output sample values: 0.451 0.025 0.575 0.821 -0.024 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.043, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-23.117678
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=28.250721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -1.821 -0.406 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.164, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.164
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-1.854295
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.514122
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.792 -0.108 0.249 -0.024 1.202 
[DEBUG] Output range: [-2.475, 2.402]
[DEBUG] Output sample values: 0.450 0.026 0.579 0.822 -0.026 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.533, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=6.025813
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=63.842281
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.824 -0.409 -0.504 0.116 1.296 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.936, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.936
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.584742
[DECODER] After pos encoding: 768/768 non-zero, sum=27.905521
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.795 -0.108 0.250 -0.020 1.203 
[DEBUG] Output range: [-2.628, 2.143]
[DEBUG] Output sample values: 0.452 0.027 0.575 0.819 -0.021 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.951827
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.538464
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -1.821 -0.404 -0.506 0.113 1.293 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.453, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.453
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.126655
[DECODER] After pos encoding: 640/640 non-zero, sum=26.933510
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.793 -0.106 0.250 -0.021 1.200 
[DEBUG] Output range: [-2.103, 2.139]
[DEBUG] Output sample values: 0.451 0.028 0.577 0.822 -0.023 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.925, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.466502
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.593699
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -1.819 -0.409 -0.508 0.120 1.296 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.255, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.255
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.879437
[DECODER] After pos encoding: 640/640 non-zero, sum=34.939636
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -1.792 -0.109 0.248 -0.016 1.203 
[DEBUG] Output range: [-2.315, 2.169]
[DEBUG] Output sample values: 0.450 0.026 0.577 0.823 -0.023 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-20.048559
[ENCODER] After pos encoding: 768/768 non-zero, sum=18.441727
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -1.818 -0.406 -0.505 0.109 1.294 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.078, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.078
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.509638
[DECODER] After pos encoding: 640/640 non-zero, sum=55.569801
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000011
[DEBUG] Decoder sample values: -1.790 -0.107 0.250 -0.023 1.201 
[DEBUG] Output range: [-2.172, 2.233]
[DEBUG] Output sample values: 0.450 0.023 0.580 0.827 -0.024 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
Epoca 145/150 - Loss: 7.3665 | LR: 7.738e-04

Época 146/150
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-3.100, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-3.100
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-35.069714
[DECODER] After pos encoding: 768/768 non-zero, sum=3.420562
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.795 -0.101 0.244 -0.025 1.195 
[DEBUG] Output range: [-2.492, 2.870]
[DEBUG] Output sample values: 0.449 0.029 0.582 0.828 -0.024 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.757, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=31.190388
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.558838
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -1.820 -0.406 -0.506 0.107 1.295 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-2.720, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-2.720
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-30.769163
[DECODER] After pos encoding: 1280/1280 non-zero, sum=33.501270
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000013
[DEBUG] Decoder sample values: -1.792 -0.107 0.250 -0.026 1.202 
[DEBUG] Output range: [-2.265, 2.670]
[DEBUG] Output sample values: 0.451 0.028 0.582 0.824 -0.022 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.347605
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=75.716080
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -1.823 -0.408 -0.507 0.111 1.292 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.049, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.049
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.867593
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.500813
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -1.793 -0.108 0.249 -0.023 1.199 
[DEBUG] Output range: [-2.551, 2.362]
[DEBUG] Output sample values: 0.451 0.027 0.580 0.826 -0.023 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.043, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-23.117678
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=28.250721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -1.821 -0.406 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.164, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.164
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-1.856320
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.512081
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.792 -0.108 0.249 -0.024 1.202 
[DEBUG] Output range: [-2.475, 2.402]
[DEBUG] Output sample values: 0.450 0.028 0.584 0.827 -0.025 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.533, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=6.025813
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=63.842281
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000012
[DEBUG] Encoder sample values: -1.824 -0.409 -0.504 0.116 1.296 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.936, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.936
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.586791
[DECODER] After pos encoding: 768/768 non-zero, sum=27.903465
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.795 -0.108 0.250 -0.020 1.203 
[DEBUG] Output range: [-2.628, 2.143]
[DEBUG] Output sample values: 0.452 0.029 0.581 0.825 -0.020 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.951827
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.538464
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000013
[DEBUG] Encoder sample values: -1.821 -0.404 -0.506 0.113 1.293 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.453, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.453
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.128621
[DECODER] After pos encoding: 640/640 non-zero, sum=26.931574
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.793 -0.106 0.250 -0.021 1.200 
[DEBUG] Output range: [-2.103, 2.139]
[DEBUG] Output sample values: 0.451 0.030 0.582 0.827 -0.022 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.925, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.466502
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.593699
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -1.819 -0.409 -0.508 0.120 1.296 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.254, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.254
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.877747
[DECODER] After pos encoding: 640/640 non-zero, sum=34.937943
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DEBUG] Decoder sample values: -1.792 -0.109 0.248 -0.016 1.203 
[DEBUG] Output range: [-2.315, 2.169]
[DEBUG] Output sample values: 0.450 0.028 0.582 0.828 -0.022 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-20.048559
[ENCODER] After pos encoding: 768/768 non-zero, sum=18.441727
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -1.818 -0.406 -0.505 0.109 1.294 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.078, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.078
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.507679
[DECODER] After pos encoding: 640/640 non-zero, sum=55.567875
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.790 -0.108 0.250 -0.023 1.201 
[DEBUG] Output range: [-2.172, 2.233]
[DEBUG] Output sample values: 0.450 0.025 0.585 0.831 -0.023 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
Epoca 146/150 - Loss: 7.3642 | LR: 7.738e-04

Época 147/150
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-3.100, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-3.100
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-35.071388
[DECODER] After pos encoding: 768/768 non-zero, sum=3.418843
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -1.795 -0.101 0.244 -0.025 1.195 
[DEBUG] Output range: [-2.492, 2.870]
[DEBUG] Output sample values: 0.449 0.031 0.587 0.833 -0.023 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.757, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=31.190388
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.558838
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000011
[DEBUG] Encoder sample values: -1.820 -0.406 -0.506 0.107 1.295 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-2.720, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-2.720
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-30.771042
[DECODER] After pos encoding: 1280/1280 non-zero, sum=33.499405
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000014
[DEBUG] Decoder sample values: -1.792 -0.107 0.250 -0.026 1.202 
[DEBUG] Output range: [-2.265, 2.670]
[DEBUG] Output sample values: 0.451 0.030 0.588 0.829 -0.021 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.347605
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=75.716080
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: -1.823 -0.408 -0.507 0.111 1.292 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.049, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.049
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.869566
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.498837
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000010
[DEBUG] Decoder sample values: -1.793 -0.108 0.249 -0.023 1.199 
[DEBUG] Output range: [-2.551, 2.362]
[DEBUG] Output sample values: 0.451 0.029 0.586 0.831 -0.022 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.043, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-23.117678
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=28.250721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -1.821 -0.406 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.164, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.164
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-1.858360
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.509995
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.792 -0.109 0.249 -0.024 1.202 
[DEBUG] Output range: [-2.475, 2.403]
[DEBUG] Output sample values: 0.450 0.030 0.589 0.832 -0.024 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.533, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=6.025813
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=63.842281
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -1.824 -0.409 -0.504 0.116 1.296 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.936, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.936
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.588843
[DECODER] After pos encoding: 768/768 non-zero, sum=27.901415
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.795 -0.108 0.250 -0.020 1.203 
[DEBUG] Output range: [-2.628, 2.143]
[DEBUG] Output sample values: 0.452 0.031 0.586 0.830 -0.019 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.951827
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.538464
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -1.821 -0.404 -0.506 0.113 1.293 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.453, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.453
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.130580
[DECODER] After pos encoding: 640/640 non-zero, sum=26.929621
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -1.793 -0.106 0.250 -0.021 1.200 
[DEBUG] Output range: [-2.103, 2.139]
[DEBUG] Output sample values: 0.451 0.032 0.587 0.832 -0.021 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.925, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.466502
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.593699
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -1.819 -0.409 -0.508 0.120 1.296 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.254, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.254
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.876054
[DECODER] After pos encoding: 640/640 non-zero, sum=34.936264
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -1.792 -0.110 0.248 -0.016 1.203 
[DEBUG] Output range: [-2.315, 2.169]
[DEBUG] Output sample values: 0.450 0.029 0.587 0.833 -0.021 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-20.048559
[ENCODER] After pos encoding: 768/768 non-zero, sum=18.441727
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: -1.818 -0.406 -0.505 0.109 1.294 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.078, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.078
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.505701
[DECODER] After pos encoding: 640/640 non-zero, sum=55.565914
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000009
[DEBUG] Decoder sample values: -1.790 -0.108 0.250 -0.023 1.202 
[DEBUG] Output range: [-2.172, 2.233]
[DEBUG] Output sample values: 0.450 0.026 0.590 0.837 -0.022 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
Epoca 147/150 - Loss: 7.3619 | LR: 7.738e-04

Época 148/150
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-3.100, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-3.100
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-35.073128
[DECODER] After pos encoding: 768/768 non-zero, sum=3.417113
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.795 -0.101 0.244 -0.025 1.195 
[DEBUG] Output range: [-2.492, 2.870]
[DEBUG] Output sample values: 0.449 0.033 0.591 0.839 -0.022 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.757, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=31.190388
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.558838
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -1.820 -0.406 -0.506 0.107 1.295 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-2.720, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-2.720
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-30.772932
[DECODER] After pos encoding: 1280/1280 non-zero, sum=33.497547
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.792 -0.107 0.250 -0.026 1.202 
[DEBUG] Output range: [-2.265, 2.670]
[DEBUG] Output sample values: 0.451 0.032 0.591 0.835 -0.020 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.347605
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=75.716080
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -1.823 -0.408 -0.507 0.111 1.292 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.049, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.049
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.871528
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.496838
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000010
[DEBUG] Decoder sample values: -1.793 -0.108 0.249 -0.023 1.199 
[DEBUG] Output range: [-2.551, 2.362]
[DEBUG] Output sample values: 0.451 0.030 0.590 0.837 -0.021 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.043, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-23.117678
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=28.250721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000011
[DEBUG] Encoder sample values: -1.821 -0.406 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.164, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.164
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-1.860394
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.508011
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -1.792 -0.109 0.249 -0.024 1.202 
[DEBUG] Output range: [-2.475, 2.403]
[DEBUG] Output sample values: 0.450 0.031 0.594 0.838 -0.023 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.533, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=6.025813
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=63.842281
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -1.824 -0.409 -0.504 0.116 1.296 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.936, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.936
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.590877
[DECODER] After pos encoding: 768/768 non-zero, sum=27.899370
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.795 -0.108 0.250 -0.020 1.203 
[DEBUG] Output range: [-2.628, 2.143]
[DEBUG] Output sample values: 0.452 0.033 0.591 0.836 -0.018 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.951827
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.538464
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.821 -0.404 -0.506 0.113 1.293 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.454, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.454
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.132537
[DECODER] After pos encoding: 640/640 non-zero, sum=26.927649
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -1.792 -0.106 0.250 -0.021 1.200 
[DEBUG] Output range: [-2.103, 2.138]
[DEBUG] Output sample values: 0.451 0.034 0.592 0.839 -0.020 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.925, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.466502
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.593699
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.819 -0.409 -0.508 0.120 1.296 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.254, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.254
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.874358
[DECODER] After pos encoding: 640/640 non-zero, sum=34.934536
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -1.791 -0.110 0.248 -0.016 1.203 
[DEBUG] Output range: [-2.315, 2.169]
[DEBUG] Output sample values: 0.450 0.031 0.592 0.840 -0.020 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-20.048559
[ENCODER] After pos encoding: 768/768 non-zero, sum=18.441727
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -1.818 -0.406 -0.505 0.109 1.294 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.077, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.077
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.503763
[DECODER] After pos encoding: 640/640 non-zero, sum=55.563961
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -1.790 -0.108 0.250 -0.023 1.202 
[DEBUG] Output range: [-2.172, 2.232]
[DEBUG] Output sample values: 0.450 0.028 0.595 0.844 -0.021 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
Epoca 148/150 - Loss: 7.3598 | LR: 7.738e-04

Época 149/150
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-3.100, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-3.100
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-35.074890
[DECODER] After pos encoding: 768/768 non-zero, sum=3.415390
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -1.795 -0.102 0.244 -0.024 1.195 
[DEBUG] Output range: [-2.492, 2.870]
[DEBUG] Output sample values: 0.449 0.035 0.597 0.845 -0.021 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.757, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=31.190388
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.558838
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -1.820 -0.406 -0.506 0.107 1.295 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-2.720, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-2.720
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-30.774738
[DECODER] After pos encoding: 1280/1280 non-zero, sum=33.495663
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.792 -0.107 0.250 -0.026 1.202 
[DEBUG] Output range: [-2.265, 2.670]
[DEBUG] Output sample values: 0.451 0.034 0.597 0.841 -0.020 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.347605
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=75.716080
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: -1.823 -0.408 -0.507 0.111 1.292 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.049, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.049
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.873504
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.494942
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.793 -0.109 0.249 -0.023 1.199 
[DEBUG] Output range: [-2.551, 2.362]
[DEBUG] Output sample values: 0.451 0.033 0.595 0.843 -0.020 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.043, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-23.117678
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=28.250721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: -1.821 -0.406 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.165, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.165
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-1.862422
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.505951
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.792 -0.109 0.249 -0.024 1.202 
[DEBUG] Output range: [-2.475, 2.403]
[DEBUG] Output sample values: 0.450 0.034 0.599 0.844 -0.022 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.533, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=6.025813
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=63.842281
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -1.824 -0.409 -0.504 0.116 1.296 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.936, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.936
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.592927
[DECODER] After pos encoding: 768/768 non-zero, sum=27.897297
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -1.794 -0.109 0.250 -0.020 1.203 
[DEBUG] Output range: [-2.628, 2.143]
[DEBUG] Output sample values: 0.452 0.035 0.596 0.842 -0.017 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.951827
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.538464
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -1.821 -0.404 -0.506 0.113 1.293 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.454, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.454
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.134497
[DECODER] After pos encoding: 640/640 non-zero, sum=26.925688
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -1.792 -0.106 0.250 -0.021 1.200 
[DEBUG] Output range: [-2.103, 2.138]
[DEBUG] Output sample values: 0.451 0.035 0.597 0.844 -0.019 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.925, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.466502
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.593699
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -1.819 -0.409 -0.508 0.120 1.296 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.254, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.254
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.872666
[DECODER] After pos encoding: 640/640 non-zero, sum=34.932873
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.791 -0.110 0.248 -0.016 1.203 
[DEBUG] Output range: [-2.315, 2.169]
[DEBUG] Output sample values: 0.450 0.033 0.597 0.845 -0.019 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-20.048559
[ENCODER] After pos encoding: 768/768 non-zero, sum=18.441727
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -1.818 -0.406 -0.505 0.109 1.294 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.077, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.077
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.501801
[DECODER] After pos encoding: 640/640 non-zero, sum=55.561962
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.790 -0.108 0.250 -0.023 1.202 
[DEBUG] Output range: [-2.172, 2.232]
[DEBUG] Output sample values: 0.450 0.030 0.601 0.849 -0.020 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
Epoca 149/150 - Loss: 7.3576 | LR: 7.738e-04

Época 150/150
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-3.100, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-3.100
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-35.076576
[DECODER] After pos encoding: 768/768 non-zero, sum=3.413673
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.795 -0.102 0.244 -0.024 1.195 
[DEBUG] Output range: [-2.492, 2.870]
[DEBUG] Output sample values: 0.449 0.036 0.602 0.850 -0.020 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.757, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=31.190388
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=82.558838
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -1.820 -0.406 -0.506 0.107 1.295 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-2.720, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=-2.720
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-30.776648
[DECODER] After pos encoding: 1280/1280 non-zero, sum=33.493782
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.792 -0.107 0.250 -0.026 1.202 
[DEBUG] Output range: [-2.265, 2.670]
[DEBUG] Output sample values: 0.451 0.035 0.603 0.847 -0.019 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.033, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.152, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.347605
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=75.716080
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.823 -0.408 -0.507 0.111 1.292 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.050, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.050
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.875479
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.492878
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[DEBUG] Decoder sample values: -1.793 -0.109 0.249 -0.023 1.199 
[DEBUG] Output range: [-2.551, 2.361]
[DEBUG] Output sample values: 0.451 0.034 0.601 0.848 -0.020 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-2.043, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-23.117678
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=28.250721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[DEBUG] Encoder sample values: -1.821 -0.406 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.165, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-0.165
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-1.864471
[DECODER] After pos encoding: 1024/1024 non-zero, sum=49.503914
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.792 -0.109 0.249 -0.024 1.202 
[DEBUG] Output range: [-2.475, 2.403]
[DEBUG] Output sample values: 0.450 0.035 0.605 0.849 -0.021 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.057, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.533, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=6.025813
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=63.842281
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -1.824 -0.409 -0.504 0.116 1.296 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.936, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.936
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-10.594987
[DECODER] After pos encoding: 768/768 non-zero, sum=27.895269
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -1.794 -0.109 0.250 -0.020 1.203 
[DEBUG] Output range: [-2.628, 2.143]
[DEBUG] Output sample values: 0.452 0.036 0.602 0.847 -0.017 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 6 tokens with lr=0.001
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.097, range=[-0.158, 0.000]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.145, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.951827
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.538464
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -1.821 -0.404 -0.506 0.113 1.293 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.454, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.454
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-5.136464
[DECODER] After pos encoding: 640/640 non-zero, sum=26.923735
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.792 -0.106 0.250 -0.021 1.200 
[DEBUG] Output range: [-2.103, 2.138]
[DEBUG] Output sample values: 0.451 0.037 0.603 0.849 -0.019 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.925, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.466502
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.593699
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -1.819 -0.409 -0.508 0.120 1.296 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.254, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.254
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=2.870981
[DECODER] After pos encoding: 640/640 non-zero, sum=34.931164
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.791 -0.110 0.248 -0.016 1.203 
[DEBUG] Output range: [-2.315, 2.169]
[DEBUG] Output sample values: 0.450 0.035 0.603 0.850 -0.019 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-20.048559
[ENCODER] After pos encoding: 768/768 non-zero, sum=18.441727
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -1.818 -0.406 -0.505 0.109 1.294 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.077, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.077
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=23.499847
[DECODER] After pos encoding: 640/640 non-zero, sum=55.560040
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.789 -0.108 0.250 -0.023 1.202 
[DEBUG] Output range: [-2.172, 2.232]
[DEBUG] Output sample values: 0.450 0.032 0.606 0.853 -0.020 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.004
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 5 tokens with lr=0.001
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.130, range=[-0.190, 0.001]
[EMBEDDING] Sample weights after update: -0.02472577 -0.06843667 0.08969525 0.03875091 -0.04074692 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00077378
Epoca 150/150 - Loss: 7.3553 | LR: 7.738e-04[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.318, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-3.601181
[DECODER] After pos encoding: 128/128 non-zero, sum=2.798820
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.794 -0.102 0.244 -0.024 1.195 
[DEBUG] Output range: [-2.107, 1.924]
[DEBUG] Output sample values: 0.449 0.038 0.607 0.854 -0.019 
[GEN] Step 0 - Best token: 8 (score: 1.9, target_len: 3) [Top scores: 8:1.9 802:1.8 21:1.8 145:1.7 895:1.7 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.133, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.133
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=1.502137
[DECODER] After pos encoding: 256/256 non-zero, sum=14.308164
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.794 -0.102 0.244 -0.024 1.195 
[DEBUG] Output range: [-2.107, 2.284]
[DEBUG] Output sample values: 0.449 0.038 0.607 0.854 -0.019 
[GEN] Step 1 - Best token: 28 (score: 2.3, target_len: 3) [Top scores: 28:2.3 377:1.9 927:1.9 828:1.8 602:1.8 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.337, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.815417
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.451532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -1.826 -0.398 -0.511 0.108 1.286 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.816, range=[-0.100, 0.103]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=0.816
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=9.236814
[DECODER] After pos encoding: 384/384 non-zero, sum=28.454895
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -1.795 -0.102 0.244 -0.024 1.195 
[DEBUG] Output range: [-2.212, 2.052]
[DEBUG] Output sample values: 0.449 0.038 0.607 0.854 -0.019 
[GEN] Step 2 - Best token: 987 (score: 1.9, target_len: 3) [Top scores: 987:1.9 378:1.7 185:1.7 612:1.7 145:1.6 ]
 | Test: <sos> no con felices <eos>

=== RESUMEN DE ENTRENAMIENTO ===
Pérdida inicial: 7.6807
Mejor pérdida: 7.3553
Mejora absoluta: 0.3254
Mejora porcentual: 4.2368%
¡Entrenamiento completado! Pérdida guardada en training_loss.txt

=== Pruebas de Traducción ===
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.514, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=5.810266
[ENCODER] After pos encoding: 384/384 non-zero, sum=25.028337
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -1.823 -0.405 -0.506 0.110 1.295 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.318, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-3.601181
[DECODER] After pos encoding: 128/128 non-zero, sum=2.798820
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.793 -0.106 0.249 -0.023 1.202 
[DEBUG] Output range: [-2.105, 1.926]
[DEBUG] Output sample values: 0.451 0.036 0.605 0.851 -0.019 
[GEN] Step 0 - Best token: 8 (score: 1.9, target_len: 2) [Top scores: 8:1.9 802:1.8 21:1.8 145:1.7 895:1.7 ]
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.514, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=5.810266
[ENCODER] After pos encoding: 384/384 non-zero, sum=25.028337
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -1.823 -0.405 -0.506 0.110 1.295 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.133, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.133
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=1.502137
[DECODER] After pos encoding: 256/256 non-zero, sum=14.308164
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -1.793 -0.106 0.249 -0.023 1.202 
[DEBUG] Output range: [-2.105, 2.221]
[DEBUG] Output sample values: 0.451 0.036 0.605 0.851 -0.019 
[GEN] Step 1 - Best token: 84 (score: 2.2, target_len: 2) [Top scores: 84:2.2 199:2.0 139:2.0 478:1.9 926:1.9 ]
ENG: <sos> hello <eos>
ESP: <sos> no vez <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.060, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=0.675910
[ENCODER] After pos encoding: 640/640 non-zero, sum=32.736122
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.826 -0.410 -0.506 0.111 1.298 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.318, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-3.601181
[DECODER] After pos encoding: 128/128 non-zero, sum=2.798820
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.796 -0.110 0.250 -0.022 1.204 
[DEBUG] Output range: [-2.103, 1.927]
[DEBUG] Output sample values: 0.450 0.036 0.604 0.848 -0.019 
[GEN] Step 0 - Best token: 21 (score: 1.8, target_len: 4) [Top scores: 8:1.9 802:1.8 21:1.8 145:1.7 895:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.060, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=0.675910
[ENCODER] After pos encoding: 640/640 non-zero, sum=32.736122
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.826 -0.410 -0.506 0.111 1.298 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.475, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.475
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-5.372570
[DECODER] After pos encoding: 256/256 non-zero, sum=7.433459
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -1.796 -0.110 0.250 -0.022 1.204 
[DEBUG] Output range: [-2.155, 1.927]
[DEBUG] Output sample values: 0.450 0.036 0.604 0.848 -0.019 
[GEN] Step 1 - Best token: 211 (score: 1.8, target_len: 4) [Top scores: 8:1.9 211:1.8 987:1.8 962:1.7 895:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.060, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=0.675910
[ENCODER] After pos encoding: 640/640 non-zero, sum=32.736122
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.826 -0.410 -0.506 0.111 1.298 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.072, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.072
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-0.811372
[DECODER] After pos encoding: 384/384 non-zero, sum=18.406712
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000011
[DEBUG] Decoder sample values: -1.796 -0.110 0.250 -0.022 1.204 
[DEBUG] Output range: [-2.110, 2.256]
[DEBUG] Output sample values: 0.450 0.036 0.604 0.848 -0.019 
[GEN] Step 2 - Best token: 800 (score: 2.3, target_len: 4) [Top scores: 800:2.3 8:1.8 881:1.8 155:1.7 877:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.060, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=0.675910
[ENCODER] After pos encoding: 640/640 non-zero, sum=32.736122
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -1.826 -0.410 -0.506 0.111 1.298 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.160, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-1.160
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-13.128054
[DECODER] After pos encoding: 512/512 non-zero, sum=12.508089
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.796 -0.110 0.250 -0.022 1.204 
[DEBUG] Output range: [-2.227, 2.223]
[DEBUG] Output sample values: 0.450 0.036 0.604 0.848 -0.019 
ENG: <sos> how are you <eos>
ESP: <sos> lo otro haces tomar <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.238, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-2.696097
[ENCODER] After pos encoding: 512/512 non-zero, sum=22.940027
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: -1.821 -0.407 -0.506 0.112 1.296 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.318, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-3.601181
[DECODER] After pos encoding: 128/128 non-zero, sum=2.798820
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.792 -0.108 0.250 -0.022 1.203 
[DEBUG] Output range: [-2.105, 1.926]
[DEBUG] Output sample values: 0.451 0.035 0.605 0.850 -0.018 
[GEN] Step 0 - Best token: 8 (score: 1.9, target_len: 3) [Top scores: 8:1.9 802:1.8 21:1.8 145:1.7 895:1.7 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.238, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-2.696097
[ENCODER] After pos encoding: 512/512 non-zero, sum=22.940027
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: -1.821 -0.407 -0.506 0.112 1.296 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.133, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.133
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=1.502137
[DECODER] After pos encoding: 256/256 non-zero, sum=14.308164
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -1.792 -0.108 0.250 -0.022 1.203 
[DEBUG] Output range: [-2.105, 2.563]
[DEBUG] Output sample values: 0.451 0.035 0.605 0.850 -0.018 
[GEN] Step 1 - Best token: 836 (score: 1.7, target_len: 3) [Top scores: 895:2.6 987:2.0 836:1.7 683:1.5 167:1.5 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.238, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-2.696097
[ENCODER] After pos encoding: 512/512 non-zero, sum=22.940027
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: -1.821 -0.407 -0.506 0.112 1.296 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1.282, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1.282
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=14.504983
[DECODER] After pos encoding: 384/384 non-zero, sum=33.723045
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.792 -0.108 0.250 -0.022 1.203 
[DEBUG] Output range: [-2.105, 2.117]
[DEBUG] Output sample values: 0.451 0.035 0.605 0.850 -0.018 
[GEN] Step 2 - Best token: 76 (score: 1.9, target_len: 3) [Top scores: 76:1.9 895:1.9 834:1.5 251:1.4 999:1.4 ]
ENG: <sos> good morning <eos>
ESP: <sos> no campo tan <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.326, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.690566
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.326693
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -1.825 -0.407 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.318, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-3.601181
[DECODER] After pos encoding: 128/128 non-zero, sum=2.798820
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -1.794 -0.108 0.249 -0.023 1.203 
[DEBUG] Output range: [-2.103, 1.926]
[DEBUG] Output sample values: 0.450 0.036 0.604 0.850 -0.019 
[GEN] Step 0 - Best token: 21 (score: 1.8, target_len: 3) [Top scores: 8:1.9 802:1.8 21:1.8 145:1.7 895:1.7 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.326, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.690566
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.326693
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -1.825 -0.407 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.475, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.475
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-5.372570
[DECODER] After pos encoding: 256/256 non-zero, sum=7.433459
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.794 -0.108 0.249 -0.023 1.203 
[DEBUG] Output range: [-2.103, 1.926]
[DEBUG] Output sample values: 0.450 0.036 0.604 0.850 -0.019 
[GEN] Step 1 - Best token: 8 (score: 1.9, target_len: 3) [Top scores: 8:1.9 211:1.8 962:1.8 895:1.8 802:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.326, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.690566
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.326693
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -1.825 -0.407 -0.507 0.109 1.296 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.024, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.024
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-0.269253
[DECODER] After pos encoding: 384/384 non-zero, sum=18.948820
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.794 -0.108 0.249 -0.023 1.203 
[DEBUG] Output range: [-2.103, 2.254]
[DEBUG] Output sample values: 0.450 0.036 0.604 0.850 -0.019 
[GEN] Step 2 - Best token: 927 (score: 2.3, target_len: 3) [Top scores: 927:2.3 754:1.9 895:1.7 108:1.7 635:1.6 ]
ENG: <sos> thank you <eos>
ESP: <sos> lo no caro <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.937, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.596553
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.656784
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -1.821 -0.410 -0.508 0.115 1.295 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.318, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-3.601181
[DECODER] After pos encoding: 128/128 non-zero, sum=2.798820
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.792 -0.109 0.248 -0.019 1.202 
[DEBUG] Output range: [-2.103, 1.927]
[DEBUG] Output sample values: 0.451 0.036 0.605 0.850 -0.018 
[GEN] Step 0 - Best token: 802 (score: 1.8, target_len: 4) [Top scores: 8:1.9 802:1.8 21:1.8 145:1.7 895:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.937, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.596553
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.656784
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -1.821 -0.410 -0.508 0.115 1.295 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.207, range=[-0.100, 0.100]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.207
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-2.347515
[DECODER] After pos encoding: 256/256 non-zero, sum=10.458510
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.791 -0.110 0.248 -0.019 1.202 
[DEBUG] Output range: [-2.145, 2.081]
[DEBUG] Output sample values: 0.451 0.036 0.605 0.850 -0.018 
[GEN] Step 1 - Best token: 903 (score: 2.0, target_len: 4) [Top scores: 8:2.0 903:2.0 629:1.8 64:1.8 167:1.8 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.937, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.596553
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.656784
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -1.821 -0.410 -0.508 0.115 1.295 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.135, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=0.135
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=1.524975
[DECODER] After pos encoding: 384/384 non-zero, sum=20.743036
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -1.791 -0.110 0.248 -0.019 1.202 
[DEBUG] Output range: [-2.103, 2.313]
[DEBUG] Output sample values: 0.451 0.036 0.605 0.850 -0.018 
[GEN] Step 2 - Best token: 8 (score: 2.3, target_len: 4) [Top scores: 8:2.3 16:2.2 933:1.8 837:1.7 362:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.937, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.596553
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.656784
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -1.821 -0.410 -0.508 0.115 1.295 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.586, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=0.586
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=6.628293
[DECODER] After pos encoding: 512/512 non-zero, sum=32.264412
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -1.791 -0.110 0.248 -0.019 1.202 
[DEBUG] Output range: [-2.103, 2.226]
[DEBUG] Output sample values: 0.451 0.036 0.605 0.850 -0.018 
ENG: <sos> i love you <eos>
ESP: <sos> modo hermanos no con <eos>
---