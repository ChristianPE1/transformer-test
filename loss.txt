Se truncaron las últimas líneas 5000 del resultado de transmisión.
[DEBUG] Encoder sample values: -0.918 -0.199 0.559 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.423, range=[-0.106, 0.808]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.423
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.414200
[DECODER] After pos encoding: 640/640 non-zero, sum=59.474400
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -1.163 -0.247 2.545 1.257 0.357 
[DEBUG] Output range: [-2.156, 5.191]
[DEBUG] Output sample values: 1.257 3.434 5.191 3.879 3.902 
[LOSS] Gradient sum: 1.865
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.113, range=[-0.177, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=8.267, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[ENCODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=93.532303
[ENCODER] After pos encoding: 4736/4736 non-zero, sum=334.300476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 0 output: 4736/4736 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 1 output: 4736/4736 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.931 -0.164 0.544 1.221 0.158 
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=5.649, range=[-0.106, 0.809]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 4736/4736 non-zero, sum=5.649
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[DECODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=63.907372
[DECODER] After pos encoding: 4736/4736 non-zero, sum=304.675964
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 4736/4736 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 4736/4736 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -1.169 -0.214 2.593 1.272 0.360 
[DEBUG] Output range: [-2.673, 5.199]
[DEBUG] Output sample values: 1.258 3.431 5.199 3.903 3.916 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 37 tokens with lr=0.010
[EMBEDDING] Gradient stats: 4736/4736 non-zero, sum=0.010, range=[-0.026, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 37 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.744, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-8.421099
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=49.395344
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.943 -0.195 0.536 1.209 0.140 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.732, range=[-0.106, 0.810]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.732
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=19.599251
[DECODER] After pos encoding: 1408/1408 non-zero, sum=90.329803
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000017
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.180 -0.247 2.534 1.261 0.352 
[DEBUG] Output range: [-2.380, 5.187]
[DEBUG] Output sample values: 1.249 3.439 5.187 3.884 3.907 
[LOSS] Gradient sum: 1.877
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=45.754883
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=97.123177
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.928 -0.196 0.554 1.219 0.142 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.292, range=[-0.106, 0.810]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.292
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-3.300886
[DECODER] After pos encoding: 768/768 non-zero, sum=35.189350
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.174 -0.248 2.549 1.267 0.349 
[DEBUG] Output range: [-2.584, 5.187]
[DEBUG] Output sample values: 1.251 3.429 5.187 3.887 3.905 
[LOSS] Gradient sum: 1.871
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.084, range=[-0.147, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
Epoca 93/100 - Loss: 6.0034

Época 94/100
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000009
[DEBUG] Encoder sample values: -0.917 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.067, range=[-0.106, 0.812]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.067
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.067969
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.300442
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.162 -0.243 2.551 1.264 0.360 
[DEBUG] Output range: [-2.237, 5.195]
[DEBUG] Output sample values: 1.258 3.436 5.195 3.881 3.909 
[LOSS] Gradient sum: 1.876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.050, range=[-0.110, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.768, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.006992
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.919350
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.922 -0.206 0.557 1.206 0.157 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.510, range=[-0.106, 0.813]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.510
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.392406
[DECODER] After pos encoding: 1152/1152 non-zero, sum=86.208878
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.168 -0.256 2.559 1.258 0.363 
[DEBUG] Output range: [-2.300, 5.198]
[DEBUG] Output sample values: 1.266 3.438 5.198 3.881 3.909 
[LOSS] Gradient sum: 1.876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-3.163, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-35.789436
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=34.941017
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000011
[DEBUG] Encoder sample values: -0.935 -0.194 0.532 1.201 0.154 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.212, range=[-0.106, 0.814]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.212
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=2.400270
[DECODER] After pos encoding: 1408/1408 non-zero, sum=73.130745
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.180 -0.242 2.534 1.253 0.361 
[DEBUG] Output range: [-2.203, 5.190]
[DEBUG] Output sample values: 1.255 3.437 5.190 3.893 3.920 
[LOSS] Gradient sum: 1.883
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.057, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=0.639915
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=84.308220
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.933 -0.185 0.537 1.221 0.161 
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=5.362, range=[-0.106, 0.815]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1664/1664 non-zero, sum=5.362
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[DECODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=60.669209
[DECODER] After pos encoding: 1664/1664 non-zero, sum=144.337524
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1664/1664 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -1.175 -0.238 2.546 1.275 0.365 
[DEBUG] Output range: [-2.519, 5.190]
[DEBUG] Output sample values: 1.253 3.435 5.190 3.894 3.924 
[LOSS] Gradient sum: 1.881
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 13 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1664/1664 non-zero, sum=-0.011, range=[-0.068, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 13 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.186, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13.421194
[ENCODER] After pos encoding: 768/768 non-zero, sum=51.911469
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.918 -0.199 0.559 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.429, range=[-0.106, 0.816]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.429
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.482796
[DECODER] After pos encoding: 640/640 non-zero, sum=59.542946
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000009
[DEBUG] Decoder sample values: -1.163 -0.249 2.557 1.256 0.356 
[DEBUG] Output range: [-2.157, 5.191]
[DEBUG] Output sample values: 1.258 3.438 5.191 3.889 3.922 
[LOSS] Gradient sum: 1.865
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.112, range=[-0.177, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=8.267, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[ENCODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=93.532303
[ENCODER] After pos encoding: 4736/4736 non-zero, sum=334.300476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 0 output: 4736/4736 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 1 output: 4736/4736 non-zero, sum=0.000017
[DEBUG] Encoder sample values: -0.931 -0.164 0.544 1.221 0.158 
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=5.651, range=[-0.106, 0.817]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 4736/4736 non-zero, sum=5.651
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[DECODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=63.937847
[DECODER] After pos encoding: 4736/4736 non-zero, sum=304.705597
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 4736/4736 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.169 -0.216 2.607 1.270 0.359 
[DEBUG] Output range: [-2.674, 5.205]
[DEBUG] Output sample values: 1.259 3.435 5.205 3.907 3.936 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 37 tokens with lr=0.010
[EMBEDDING] Gradient stats: 4736/4736 non-zero, sum=0.010, range=[-0.026, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 37 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.744, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-8.421099
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=49.395344
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.943 -0.195 0.536 1.209 0.140 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.737, range=[-0.106, 0.818]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.737
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=19.654467
[DECODER] After pos encoding: 1408/1408 non-zero, sum=90.384933
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000017
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.181 -0.249 2.546 1.260 0.352 
[DEBUG] Output range: [-2.380, 5.194]
[DEBUG] Output sample values: 1.250 3.444 5.194 3.887 3.927 
[LOSS] Gradient sum: 1.877
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=45.754883
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=97.123177
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000014
[DEBUG] Encoder sample values: -0.928 -0.196 0.554 1.219 0.142 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.286, range=[-0.106, 0.818]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.286
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-3.232725
[DECODER] After pos encoding: 768/768 non-zero, sum=35.257515
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.175 -0.251 2.561 1.266 0.348 
[DEBUG] Output range: [-2.583, 5.190]
[DEBUG] Output sample values: 1.252 3.428 5.190 3.887 3.926 
[LOSS] Gradient sum: 1.871
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.084, range=[-0.147, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
Epoca 94/100 - Loss: 5.9966

Época 95/100
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.917 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.061, range=[-0.106, 0.820]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.061
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.005323
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.363071
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -1.162 -0.245 2.563 1.263 0.359 
[DEBUG] Output range: [-2.237, 5.198]
[DEBUG] Output sample values: 1.259 3.436 5.198 3.883 3.929 
[LOSS] Gradient sum: 1.876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.050, range=[-0.110, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.768, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.006992
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.919350
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -0.922 -0.206 0.557 1.206 0.157 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.515, range=[-0.106, 0.821]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.515
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.453520
[DECODER] After pos encoding: 1152/1152 non-zero, sum=86.269905
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -1.169 -0.258 2.571 1.257 0.363 
[DEBUG] Output range: [-2.301, 5.200]
[DEBUG] Output sample values: 1.267 3.439 5.200 3.883 3.929 
[LOSS] Gradient sum: 1.876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-3.163, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-35.789436
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=34.941017
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.935 -0.194 0.532 1.201 0.154 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.218, range=[-0.106, 0.822]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.218
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=2.461868
[DECODER] After pos encoding: 1408/1408 non-zero, sum=73.192314
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.180 -0.244 2.545 1.251 0.361 
[DEBUG] Output range: [-2.204, 5.193]
[DEBUG] Output sample values: 1.256 3.438 5.193 3.890 3.945 
[LOSS] Gradient sum: 1.883
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.057, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=0.639915
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=84.308220
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.933 -0.185 0.537 1.221 0.161 
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=5.367, range=[-0.106, 0.823]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1664/1664 non-zero, sum=5.367
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[DECODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=60.725025
[DECODER] After pos encoding: 1664/1664 non-zero, sum=144.393402
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1664/1664 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -1.176 -0.240 2.558 1.273 0.365 
[DEBUG] Output range: [-2.519, 5.196]
[DEBUG] Output sample values: 1.254 3.438 5.196 3.890 3.948 
[LOSS] Gradient sum: 1.881
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 13 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1664/1664 non-zero, sum=-0.011, range=[-0.068, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 13 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.186, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13.421194
[ENCODER] After pos encoding: 768/768 non-zero, sum=51.911469
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -0.918 -0.199 0.559 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.435, range=[-0.106, 0.823]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.435
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.551321
[DECODER] After pos encoding: 640/640 non-zero, sum=59.611519
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.164 -0.251 2.569 1.254 0.356 
[DEBUG] Output range: [-2.157, 5.198]
[DEBUG] Output sample values: 1.259 3.438 5.198 3.888 3.943 
[LOSS] Gradient sum: 1.864
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.112, range=[-0.176, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=8.267, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[ENCODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=93.532303
[ENCODER] After pos encoding: 4736/4736 non-zero, sum=334.300476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 0 output: 4736/4736 non-zero, sum=0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 1 output: 4736/4736 non-zero, sum=0.000015
[DEBUG] Encoder sample values: -0.931 -0.164 0.544 1.221 0.158 
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=5.654, range=[-0.106, 0.825]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 4736/4736 non-zero, sum=5.654
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[DECODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=63.968235
[DECODER] After pos encoding: 4736/4736 non-zero, sum=304.736115
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 4736/4736 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 4736/4736 non-zero, sum=0.000016
[DEBUG] Decoder sample values: -1.170 -0.218 2.621 1.269 0.359 
[DEBUG] Output range: [-2.674, 5.205]
[DEBUG] Output sample values: 1.260 3.436 5.205 3.909 3.957 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 37 tokens with lr=0.010
[EMBEDDING] Gradient stats: 4736/4736 non-zero, sum=0.010, range=[-0.026, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 37 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.744, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-8.421099
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=49.395344
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DEBUG] Encoder sample values: -0.943 -0.195 0.536 1.209 0.140 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.742, range=[-0.106, 0.825]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.742
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=19.709703
[DECODER] After pos encoding: 1408/1408 non-zero, sum=90.440170
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.182 -0.251 2.557 1.259 0.352 
[DEBUG] Output range: [-2.380, 5.193]
[DEBUG] Output sample values: 1.251 3.443 5.193 3.889 3.948 
[LOSS] Gradient sum: 1.877
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=45.754883
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=97.123177
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[DEBUG] Encoder sample values: -0.928 -0.196 0.554 1.219 0.142 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.280, range=[-0.106, 0.826]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.280
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-3.164634
[DECODER] After pos encoding: 768/768 non-zero, sum=35.325630
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.176 -0.253 2.573 1.265 0.348 
[DEBUG] Output range: [-2.582, 5.191]
[DEBUG] Output sample values: 1.253 3.431 5.191 3.894 3.945 
[LOSS] Gradient sum: 1.871
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.084, range=[-0.147, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
Epoca 95/100 - Loss: 5.9901

Época 96/100
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.917 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.056, range=[-0.106, 0.828]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.056
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.942730
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.425640
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -1.163 -0.248 2.575 1.262 0.359 
[DEBUG] Output range: [-2.238, 5.202]
[DEBUG] Output sample values: 1.260 3.439 5.202 3.888 3.948 
[LOSS] Gradient sum: 1.876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.050, range=[-0.110, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.768, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.006992
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.919350
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -0.922 -0.206 0.557 1.206 0.156 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.520, range=[-0.106, 0.829]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.520
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.514540
[DECODER] After pos encoding: 1152/1152 non-zero, sum=86.330841
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.169 -0.261 2.583 1.255 0.363 
[DEBUG] Output range: [-2.301, 5.203]
[DEBUG] Output sample values: 1.268 3.444 5.203 3.885 3.949 
[LOSS] Gradient sum: 1.876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-3.163, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-35.789436
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=34.941017
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000012
[DEBUG] Encoder sample values: -0.935 -0.194 0.532 1.201 0.154 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.223, range=[-0.106, 0.830]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.223
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=2.523414
[DECODER] After pos encoding: 1408/1408 non-zero, sum=73.253845
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: -1.181 -0.246 2.557 1.250 0.361 
[DEBUG] Output range: [-2.204, 5.198]
[DEBUG] Output sample values: 1.257 3.442 5.198 3.893 3.962 
[LOSS] Gradient sum: 1.882
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.057, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=0.639915
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=84.308220
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.933 -0.185 0.537 1.221 0.161 
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=5.372, range=[-0.106, 0.831]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1664/1664 non-zero, sum=5.372
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[DECODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=60.780846
[DECODER] After pos encoding: 1664/1664 non-zero, sum=144.448929
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1664/1664 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.177 -0.242 2.569 1.272 0.365 
[DEBUG] Output range: [-2.518, 5.199]
[DEBUG] Output sample values: 1.255 3.439 5.199 3.890 3.965 
[LOSS] Gradient sum: 1.881
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 13 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1664/1664 non-zero, sum=-0.011, range=[-0.068, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 13 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.186, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13.421194
[ENCODER] After pos encoding: 768/768 non-zero, sum=51.911469
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.918 -0.199 0.559 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.441, range=[-0.106, 0.831]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.441
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.619757
[DECODER] After pos encoding: 640/640 non-zero, sum=59.679989
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -1.165 -0.253 2.581 1.253 0.356 
[DEBUG] Output range: [-2.158, 5.202]
[DEBUG] Output sample values: 1.260 3.440 5.202 3.886 3.962 
[LOSS] Gradient sum: 1.864
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.112, range=[-0.176, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=8.267, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[ENCODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=93.532303
[ENCODER] After pos encoding: 4736/4736 non-zero, sum=334.300476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 0 output: 4736/4736 non-zero, sum=-0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 1 output: 4736/4736 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.931 -0.164 0.544 1.221 0.158 
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=5.657, range=[-0.106, 0.833]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 4736/4736 non-zero, sum=5.657
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[DECODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=63.998501
[DECODER] After pos encoding: 4736/4736 non-zero, sum=304.766815
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 4736/4736 non-zero, sum=0.000018
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000011
[DEBUG] Decoder sample values: -1.171 -0.220 2.634 1.268 0.359 
[DEBUG] Output range: [-2.675, 5.209]
[DEBUG] Output sample values: 1.261 3.437 5.209 3.905 3.977 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 37 tokens with lr=0.010
[EMBEDDING] Gradient stats: 4736/4736 non-zero, sum=0.010, range=[-0.026, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 37 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.744, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-8.421099
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=49.395344
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.943 -0.195 0.536 1.209 0.139 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.747, range=[-0.106, 0.833]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.747
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=19.764856
[DECODER] After pos encoding: 1408/1408 non-zero, sum=90.495270
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.183 -0.253 2.569 1.258 0.351 
[DEBUG] Output range: [-2.380, 5.198]
[DEBUG] Output sample values: 1.251 3.445 5.198 3.885 3.967 
[LOSS] Gradient sum: 1.877
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=45.754883
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=97.123177
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.928 -0.196 0.554 1.218 0.142 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.274, range=[-0.106, 0.834]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.274
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-3.096608
[DECODER] After pos encoding: 768/768 non-zero, sum=35.393631
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.176 -0.255 2.584 1.264 0.348 
[DEBUG] Output range: [-2.581, 5.196]
[DEBUG] Output sample values: 1.254 3.436 5.196 3.887 3.965 
[LOSS] Gradient sum: 1.871
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.084, range=[-0.147, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
Epoca 96/100 - Loss: 5.9840

Época 97/100
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000014
[DEBUG] Encoder sample values: -0.917 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.050, range=[-0.106, 0.835]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.050
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.880182
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.488148
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000014
[DEBUG] Decoder sample values: -1.164 -0.249 2.587 1.260 0.359 
[DEBUG] Output range: [-2.238, 5.208]
[DEBUG] Output sample values: 1.260 3.443 5.208 3.883 3.968 
[LOSS] Gradient sum: 1.875
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.050, range=[-0.110, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.768, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.006992
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.919350
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.922 -0.206 0.557 1.206 0.156 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.526, range=[-0.106, 0.837]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.526
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.575523
[DECODER] After pos encoding: 1152/1152 non-zero, sum=86.391907
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -1.170 -0.263 2.594 1.254 0.363 
[DEBUG] Output range: [-2.301, 5.212]
[DEBUG] Output sample values: 1.268 3.452 5.212 3.881 3.968 
[LOSS] Gradient sum: 1.875
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-3.163, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-35.789436
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=34.941017
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.935 -0.193 0.532 1.201 0.154 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.228, range=[-0.106, 0.838]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.228
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=2.584872
[DECODER] After pos encoding: 1408/1408 non-zero, sum=73.315323
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.182 -0.248 2.568 1.249 0.360 
[DEBUG] Output range: [-2.204, 5.205]
[DEBUG] Output sample values: 1.257 3.450 5.205 3.887 3.977 
[LOSS] Gradient sum: 1.882
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.057, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=0.639915
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=84.308220
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.933 -0.185 0.537 1.221 0.161 
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=5.377, range=[-0.106, 0.838]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1664/1664 non-zero, sum=5.377
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[DECODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=60.836548
[DECODER] After pos encoding: 1664/1664 non-zero, sum=144.504929
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1664/1664 non-zero, sum=0.000018
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.178 -0.244 2.580 1.271 0.364 
[DEBUG] Output range: [-2.517, 5.206]
[DEBUG] Output sample values: 1.256 3.448 5.206 3.886 3.981 
[LOSS] Gradient sum: 1.881
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 13 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1664/1664 non-zero, sum=-0.011, range=[-0.068, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 13 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.186, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13.421194
[ENCODER] After pos encoding: 768/768 non-zero, sum=51.911469
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.918 -0.199 0.559 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.447, range=[-0.106, 0.839]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.447
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.688183
[DECODER] After pos encoding: 640/640 non-zero, sum=59.748344
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -1.166 -0.255 2.592 1.252 0.355 
[DEBUG] Output range: [-2.158, 5.208]
[DEBUG] Output sample values: 1.261 3.447 5.208 3.882 3.977 
[LOSS] Gradient sum: 1.864
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.112, range=[-0.176, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=8.267, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[ENCODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=93.532303
[ENCODER] After pos encoding: 4736/4736 non-zero, sum=334.300476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 0 output: 4736/4736 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000031
[DEBUG] Encoder sample values: -0.931 -0.164 0.544 1.221 0.158 
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=5.659, range=[-0.106, 0.841]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 4736/4736 non-zero, sum=5.659
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[DECODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=64.028709
[DECODER] After pos encoding: 4736/4736 non-zero, sum=304.797577
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 4736/4736 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000014
[DEBUG] Decoder sample values: -1.172 -0.222 2.648 1.267 0.359 
[DEBUG] Output range: [-2.675, 5.212]
[DEBUG] Output sample values: 1.262 3.444 5.212 3.905 3.992 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 37 tokens with lr=0.010
[EMBEDDING] Gradient stats: 4736/4736 non-zero, sum=0.010, range=[-0.026, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 37 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.744, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-8.421099
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=49.395344
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.943 -0.195 0.536 1.209 0.139 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.752, range=[-0.106, 0.841]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.752
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=19.819954
[DECODER] After pos encoding: 1408/1408 non-zero, sum=90.550491
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.184 -0.255 2.580 1.256 0.351 
[DEBUG] Output range: [-2.380, 5.201]
[DEBUG] Output sample values: 1.252 3.452 5.201 3.884 3.982 
[LOSS] Gradient sum: 1.877
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=45.754883
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=97.123177
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.928 -0.196 0.554 1.218 0.142 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.268, range=[-0.106, 0.842]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.268
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-3.028639
[DECODER] After pos encoding: 768/768 non-zero, sum=35.461628
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.177 -0.257 2.596 1.262 0.347 
[DEBUG] Output range: [-2.580, 5.200]
[DEBUG] Output sample values: 1.255 3.441 5.200 3.886 3.980 
[LOSS] Gradient sum: 1.871
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.084, range=[-0.147, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
Epoca 97/100 - Loss: 5.9774

Época 98/100
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DEBUG] Encoder sample values: -0.917 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.045, range=[-0.106, 0.843]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.045
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.817736
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.550659
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -1.165 -0.251 2.598 1.259 0.359 
[DEBUG] Output range: [-2.238, 5.207]
[DEBUG] Output sample values: 1.261 3.448 5.207 3.883 3.983 
[LOSS] Gradient sum: 1.876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.050, range=[-0.110, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.768, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.006992
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.919350
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.922 -0.206 0.557 1.206 0.156 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.531, range=[-0.106, 0.844]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.531
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.636402
[DECODER] After pos encoding: 1152/1152 non-zero, sum=86.452881
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.171 -0.265 2.606 1.253 0.363 
[DEBUG] Output range: [-2.302, 5.208]
[DEBUG] Output sample values: 1.269 3.452 5.208 3.883 3.984 
[LOSS] Gradient sum: 1.875
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-3.163, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-35.789436
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=34.941017
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000010
[DEBUG] Encoder sample values: -0.935 -0.194 0.532 1.201 0.154 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.234, range=[-0.106, 0.845]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.234
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=2.646279
[DECODER] After pos encoding: 1408/1408 non-zero, sum=73.376778
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -1.183 -0.250 2.579 1.248 0.360 
[DEBUG] Output range: [-2.205, 5.200]
[DEBUG] Output sample values: 1.258 3.451 5.200 3.891 3.995 
[LOSS] Gradient sum: 1.882
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.057, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=0.639915
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=84.308220
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.933 -0.185 0.537 1.221 0.161 
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=5.382, range=[-0.106, 0.846]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1664/1664 non-zero, sum=5.382
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[DECODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=60.892178
[DECODER] After pos encoding: 1664/1664 non-zero, sum=144.560455
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000019
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1664/1664 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.179 -0.246 2.592 1.270 0.364 
[DEBUG] Output range: [-2.516, 5.203]
[DEBUG] Output sample values: 1.256 3.450 5.203 3.891 3.998 
[LOSS] Gradient sum: 1.881
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 13 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1664/1664 non-zero, sum=-0.011, range=[-0.068, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 13 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.186, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13.421194
[ENCODER] After pos encoding: 768/768 non-zero, sum=51.911469
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.919 -0.199 0.559 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.453, range=[-0.106, 0.847]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.453
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.756519
[DECODER] After pos encoding: 640/640 non-zero, sum=59.816769
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.166 -0.257 2.604 1.251 0.355 
[DEBUG] Output range: [-2.159, 5.205]
[DEBUG] Output sample values: 1.261 3.448 5.205 3.887 3.996 
[LOSS] Gradient sum: 1.864
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.112, range=[-0.176, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=8.267, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[ENCODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=93.532303
[ENCODER] After pos encoding: 4736/4736 non-zero, sum=334.300476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 0 output: 4736/4736 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000026
[DEBUG] Encoder sample values: -0.931 -0.164 0.544 1.221 0.158 
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=5.662, range=[-0.106, 0.849]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 4736/4736 non-zero, sum=5.662
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[DECODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=64.058990
[DECODER] After pos encoding: 4736/4736 non-zero, sum=304.826538
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 4736/4736 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 4736/4736 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.173 -0.224 2.662 1.265 0.359 
[DEBUG] Output range: [-2.676, 5.215]
[DEBUG] Output sample values: 1.263 3.445 5.215 3.905 4.011 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 37 tokens with lr=0.010
[EMBEDDING] Gradient stats: 4736/4736 non-zero, sum=0.010, range=[-0.026, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 37 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.744, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-8.421099
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=49.395344
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: -0.943 -0.195 0.536 1.209 0.139 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.757, range=[-0.106, 0.849]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.757
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=19.874949
[DECODER] After pos encoding: 1408/1408 non-zero, sum=90.605370
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.185 -0.257 2.591 1.255 0.351 
[DEBUG] Output range: [-2.380, 5.203]
[DEBUG] Output sample values: 1.253 3.454 5.203 3.884 4.001 
[LOSS] Gradient sum: 1.877
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=45.754883
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=97.123177
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -0.928 -0.196 0.554 1.218 0.142 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.262, range=[-0.106, 0.850]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.262
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-2.960703
[DECODER] After pos encoding: 768/768 non-zero, sum=35.529572
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -1.178 -0.258 2.607 1.261 0.347 
[DEBUG] Output range: [-2.579, 5.201]
[DEBUG] Output sample values: 1.255 3.438 5.201 3.886 3.999 
[LOSS] Gradient sum: 1.871
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.084, range=[-0.147, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
Epoca 98/100 - Loss: 5.9718

Época 99/100
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.917 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.039, range=[-0.106, 0.851]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.039
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.755295
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.613075
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.165 -0.253 2.610 1.258 0.359 
[DEBUG] Output range: [-2.238, 5.213]
[DEBUG] Output sample values: 1.262 3.445 5.213 3.883 4.002 
[LOSS] Gradient sum: 1.875
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.050, range=[-0.110, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.768, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.006992
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.919350
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.922 -0.206 0.557 1.206 0.156 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.537, range=[-0.106, 0.852]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.537
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.697281
[DECODER] After pos encoding: 1152/1152 non-zero, sum=86.513756
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000010
[DEBUG] Decoder sample values: -1.172 -0.266 2.617 1.252 0.362 
[DEBUG] Output range: [-2.302, 5.214]
[DEBUG] Output sample values: 1.270 3.448 5.214 3.881 4.003 
[LOSS] Gradient sum: 1.875
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-3.163, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-35.789436
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=34.941017
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000014
[DEBUG] Encoder sample values: -0.935 -0.193 0.532 1.201 0.154 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.239, range=[-0.106, 0.853]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.239
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=2.707694
[DECODER] After pos encoding: 1408/1408 non-zero, sum=73.438217
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000016
[DEBUG] Decoder sample values: -1.184 -0.252 2.591 1.247 0.360 
[DEBUG] Output range: [-2.205, 5.208]
[DEBUG] Output sample values: 1.259 3.447 5.208 3.889 4.017 
[LOSS] Gradient sum: 1.882
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.057, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=0.639915
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=84.308220
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.933 -0.185 0.537 1.221 0.161 
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=5.387, range=[-0.106, 0.854]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1664/1664 non-zero, sum=5.387
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[DECODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=60.947796
[DECODER] After pos encoding: 1664/1664 non-zero, sum=144.616135
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1664/1664 non-zero, sum=0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -1.180 -0.248 2.603 1.269 0.364 
[DEBUG] Output range: [-2.516, 5.209]
[DEBUG] Output sample values: 1.257 3.444 5.209 3.885 4.020 
[LOSS] Gradient sum: 1.881
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 13 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1664/1664 non-zero, sum=-0.011, range=[-0.068, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 13 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.186, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13.421194
[ENCODER] After pos encoding: 768/768 non-zero, sum=51.911469
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.919 -0.199 0.559 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.459, range=[-0.106, 0.855]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.459
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.824821
[DECODER] After pos encoding: 640/640 non-zero, sum=59.885078
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.167 -0.259 2.615 1.249 0.355 
[DEBUG] Output range: [-2.159, 5.211]
[DEBUG] Output sample values: 1.262 3.442 5.211 3.883 4.016 
[LOSS] Gradient sum: 1.864
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.112, range=[-0.176, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=8.267, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[ENCODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=93.532303
[ENCODER] After pos encoding: 4736/4736 non-zero, sum=334.300476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 0 output: 4736/4736 non-zero, sum=0.000020
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.931 -0.164 0.544 1.221 0.158 
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=5.665, range=[-0.106, 0.856]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 4736/4736 non-zero, sum=5.665
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[DECODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=64.089195
[DECODER] After pos encoding: 4736/4736 non-zero, sum=304.857788
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 4736/4736 non-zero, sum=-0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -1.173 -0.225 2.675 1.264 0.358 
[DEBUG] Output range: [-2.676, 5.224]
[DEBUG] Output sample values: 1.264 3.439 5.224 3.903 4.030 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 37 tokens with lr=0.010
[EMBEDDING] Gradient stats: 4736/4736 non-zero, sum=0.010, range=[-0.026, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 37 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.744, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-8.421099
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=49.395344
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000009
[DEBUG] Encoder sample values: -0.943 -0.194 0.536 1.209 0.139 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.762, range=[-0.106, 0.857]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.762
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=19.929911
[DECODER] After pos encoding: 1408/1408 non-zero, sum=90.660370
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000021
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -1.186 -0.259 2.603 1.254 0.351 
[DEBUG] Output range: [-2.380, 5.212]
[DEBUG] Output sample values: 1.254 3.449 5.212 3.881 4.021 
[LOSS] Gradient sum: 1.877
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=45.754883
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=97.123177
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.928 -0.196 0.554 1.218 0.142 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.256, range=[-0.106, 0.857]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.256
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-2.892834
[DECODER] After pos encoding: 768/768 non-zero, sum=35.597458
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -1.179 -0.260 2.618 1.260 0.347 
[DEBUG] Output range: [-2.578, 5.208]
[DEBUG] Output sample values: 1.256 3.436 5.208 3.884 4.021 
[LOSS] Gradient sum: 1.871
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.084, range=[-0.147, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
Epoca 99/100 - Loss: 5.9655

Época 100/100
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.917 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.034, range=[-0.106, 0.859]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=-1.034
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-11.692924
[DECODER] After pos encoding: 1024/1024 non-zero, sum=39.675446
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.166 -0.255 2.621 1.257 0.358 
[DEBUG] Output range: [-2.239, 5.215]
[DEBUG] Output sample values: 1.263 3.443 5.215 3.883 4.024 
[LOSS] Gradient sum: 1.875
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 8 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.050, range=[-0.110, 0.003]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-1.768, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-20.006992
[ENCODER] After pos encoding: 896/896 non-zero, sum=24.919350
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -0.922 -0.206 0.557 1.206 0.156 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.542, range=[-0.106, 0.860]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.542
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=28.758018
[DECODER] After pos encoding: 1152/1152 non-zero, sum=86.574516
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000012
[DEBUG] Decoder sample values: -1.173 -0.268 2.628 1.251 0.362 
[DEBUG] Output range: [-2.302, 5.220]
[DEBUG] Output sample values: 1.271 3.450 5.220 3.884 4.024 
[LOSS] Gradient sum: 1.875
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 9 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.039, range=[-0.098, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-3.163, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-35.789436
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=34.941017
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.935 -0.193 0.532 1.201 0.154 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.245, range=[-0.106, 0.861]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=0.245
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=2.769015
[DECODER] After pos encoding: 1408/1408 non-zero, sum=73.499374
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -1.185 -0.254 2.602 1.245 0.360 
[DEBUG] Output range: [-2.205, 5.213]
[DEBUG] Output sample values: 1.260 3.449 5.213 3.888 4.038 
[LOSS] Gradient sum: 1.882
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.057, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=0.639915
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=84.308220
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.933 -0.185 0.537 1.221 0.161 
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=5.392, range=[-0.106, 0.862]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1664/1664 non-zero, sum=5.392
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[DECODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=61.003448
[DECODER] After pos encoding: 1664/1664 non-zero, sum=144.671890
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1664/1664 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1664/1664 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.181 -0.249 2.614 1.268 0.364 
[DEBUG] Output range: [-2.515, 5.215]
[DEBUG] Output sample values: 1.258 3.448 5.215 3.887 4.042 
[LOSS] Gradient sum: 1.881
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 13 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1664/1664 non-zero, sum=-0.011, range=[-0.068, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 13 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.186, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13.421194
[ENCODER] After pos encoding: 768/768 non-zero, sum=51.911469
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.919 -0.199 0.559 1.205 0.146 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.465, range=[-0.106, 0.863]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=2.465
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.893036
[DECODER] After pos encoding: 640/640 non-zero, sum=59.953304
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.168 -0.261 2.626 1.248 0.355 
[DEBUG] Output range: [-2.160, 5.219]
[DEBUG] Output sample values: 1.263 3.447 5.219 3.884 4.036 
[LOSS] Gradient sum: 1.864
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 5 tokens with lr=0.010
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.112, range=[-0.176, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=8.267, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[ENCODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=93.532303
[ENCODER] After pos encoding: 4736/4736 non-zero, sum=334.300476
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 0 output: 4736/4736 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 4736/4736 non-zero
[ENCODER_LAYER] After self-attention: 4736/4736 non-zero
[ENCODER_LAYER] After norm1: 4736/4736 non-zero
[ENCODER_LAYER] After feedforward: 4736/4736 non-zero
[ENCODER_LAYER] Final output: 4736/4736 non-zero
[ENCODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000009
[DEBUG] Encoder sample values: -0.931 -0.164 0.544 1.221 0.158 
[EMBEDDING] Forward pass - seq_len=37, d_model=128
[EMBEDDING] 4736/4736 non-zero, sum=5.667, range=[-0.106, 0.864]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 4736/4736 non-zero, sum=5.667
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 4672/4736 non-zero, sum=240.767914
[DECODER] SCALED EMBEDS before add: 4736/4736 non-zero, sum=64.119469
[DECODER] After pos encoding: 4736/4736 non-zero, sum=304.887543
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 4736/4736 non-zero, sum=0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 4736/4736 non-zero, sum=-0.000021
[DEBUG] Decoder sample values: -1.174 -0.227 2.689 1.263 0.358 
[DEBUG] Output range: [-2.677, 5.227]
[DEBUG] Output sample values: 1.265 3.444 5.227 3.910 4.051 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 37 tokens with lr=0.010
[EMBEDDING] Gradient stats: 4736/4736 non-zero, sum=0.010, range=[-0.026, 0.001]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 37 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.744, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-8.421099
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=49.395344
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.943 -0.194 0.536 1.209 0.139 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.766, range=[-0.106, 0.865]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.766
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=19.984818
[DECODER] After pos encoding: 1408/1408 non-zero, sum=90.715302
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000012
[DEBUG] Decoder sample values: -1.187 -0.261 2.614 1.253 0.350 
[DEBUG] Output range: [-2.380, 5.215]
[DEBUG] Output sample values: 1.255 3.454 5.215 3.888 4.041 
[LOSS] Gradient sum: 1.876
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 11 tokens with lr=0.010
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.022, range=[-0.080, 0.002]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=45.754883
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=97.123177
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[DEBUG] Encoder sample values: -0.928 -0.196 0.554 1.218 0.142 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.250, range=[-0.106, 0.865]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.250
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-2.825061
[DECODER] After pos encoding: 768/768 non-zero, sum=35.665222
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.180 -0.262 2.629 1.259 0.346 
[DEBUG] Output range: [-2.577, 5.215]
[DEBUG] Output sample values: 1.257 3.445 5.215 3.892 4.037 
[LOSS] Gradient sum: 1.871
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.050
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[ATTENTION] Weights updated with lr=0.010
[FEEDFORWARD] Weights updated with lr=0.010
[EMBEDDING] Updating weights for 6 tokens with lr=0.010
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.084, range=[-0.147, 0.004]
[EMBEDDING] Sample weights after update: 0.00660022 -0.08695681 -0.08685043 -0.05086490 -0.07221132 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.01000000
Epoca 100/100 - Loss: 5.9589[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.918 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.914, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.914
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=10.344390
[DECODER] After pos encoding: 128/128 non-zero, sum=16.744389
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.171 -0.258 2.614 1.256 0.358 
[DEBUG] Output range: [-1.958, 5.217]
[DEBUG] Output sample values: 1.263 3.453 5.217 3.885 4.040 
[GEN] Step 0 - Best token: 4 (score: 4.0, target_len: 8) [Top scores: 4:4.0 23:2.1 6:2.0 1:2.0 81:1.8 ]
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.918 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.243, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.243
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=25.375410
[DECODER] After pos encoding: 256/256 non-zero, sum=38.181400
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.167 -0.255 2.623 1.254 0.359 
[DEBUG] Output range: [-2.151, 5.217]
[DEBUG] Output sample values: 1.263 3.453 5.217 3.887 4.040 
[GEN] Step 1 - Best token: 6 (score: 2.3, target_len: 8) [Top scores: 6:2.3 536:1.9 549:1.8 851:1.8 347:1.7 ]
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.918 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=3.340, range=[-0.105, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=3.340
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=37.783131
[DECODER] After pos encoding: 384/384 non-zero, sum=57.001179
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.167 -0.258 2.628 1.255 0.358 
[DEBUG] Output range: [-2.128, 5.218]
[DEBUG] Output sample values: 1.263 3.453 5.218 3.887 4.041 
[GEN] Step 2 - Best token: 1 (score: 1.9, target_len: 8) [Top scores: 1:1.9 869:1.8 245:1.8 267:1.7 224:1.7 ]
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.918 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=3.232, range=[-0.106, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=3.232
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=36.562000
[DECODER] After pos encoding: 512/512 non-zero, sum=62.198116
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.168 -0.258 2.628 1.256 0.358 
[DEBUG] Output range: [-2.512, 5.218]
[DEBUG] Output sample values: 1.263 3.453 5.218 3.887 4.041 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.220, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=2.484392
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=60.300873
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.918 -0.192 0.552 1.214 0.151 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=4.560, range=[-0.106, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=4.560
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=51.593006
[DECODER] After pos encoding: 640/640 non-zero, sum=83.653206
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000009
[DEBUG] Decoder sample values: -1.167 -0.258 2.629 1.256 0.358 
[DEBUG] Output range: [-2.512, 5.217]
[DEBUG] Output sample values: 1.263 3.453 5.217 3.887 4.041 
 | Test: <sos> a la <unk> a gatos

=== RESUMEN DE ENTRENAMIENTO ===
Pérdida inicial: 7.5022
Mejor pérdida: 5.9589
Mejora absoluta: 1.5433
Mejora porcentual: 20.5711%
¡Entrenamiento completado! Pérdida guardada en training_loss.txt

=== Pruebas de Traducción ===
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.253, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-14.174536
[ENCODER] After pos encoding: 384/384 non-zero, sum=5.043532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.922 -0.199 0.553 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.914, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.914
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=10.344390
[DECODER] After pos encoding: 128/128 non-zero, sum=16.744389
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -1.173 -0.262 2.613 1.251 0.356 
[DEBUG] Output range: [-1.954, 5.214]
[DEBUG] Output sample values: 1.262 3.455 5.214 3.887 4.040 
[GEN] Step 0 - Best token: 4 (score: 4.0, target_len: 2) [Top scores: 4:4.0 23:2.1 1:2.0 6:2.0 81:1.8 ]
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.253, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-14.174536
[ENCODER] After pos encoding: 384/384 non-zero, sum=5.043532
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.922 -0.199 0.553 1.206 0.146 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.243, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.243
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=25.375410
[DECODER] After pos encoding: 256/256 non-zero, sum=38.181400
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -1.174 -0.262 2.614 1.250 0.356 
[DEBUG] Output range: [-2.109, 5.214]
[DEBUG] Output sample values: 1.262 3.455 5.214 3.887 4.039 
[GEN] Step 1 - Best token: 6 (score: 2.3, target_len: 2) [Top scores: 6:2.3 536:2.0 904:1.8 81:1.8 379:1.7 ]
ENG: <sos> hello <eos>
ESP: <sos> a la <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.683, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-7.725162
[ENCODER] After pos encoding: 640/640 non-zero, sum=24.335054
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.924 -0.193 0.560 1.205 0.144 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.914, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.914
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=10.344390
[DECODER] After pos encoding: 128/128 non-zero, sum=16.744389
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.174 -0.257 2.616 1.249 0.355 
[DEBUG] Output range: [-1.950, 5.215]
[DEBUG] Output sample values: 1.258 3.452 5.215 3.887 4.040 
[GEN] Step 0 - Best token: 4 (score: 4.0, target_len: 4) [Top scores: 4:4.0 23:2.1 1:2.0 6:2.0 81:1.8 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.683, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-7.725162
[ENCODER] After pos encoding: 640/640 non-zero, sum=24.335054
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.924 -0.193 0.560 1.205 0.144 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.243, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.243
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=25.375410
[DECODER] After pos encoding: 256/256 non-zero, sum=38.181400
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.177 -0.254 2.624 1.247 0.353 
[DEBUG] Output range: [-2.115, 5.214]
[DEBUG] Output sample values: 1.258 3.452 5.214 3.888 4.042 
[GEN] Step 1 - Best token: 6 (score: 2.2, target_len: 4) [Top scores: 6:2.2 536:1.9 81:1.8 851:1.8 549:1.8 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.683, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-7.725162
[ENCODER] After pos encoding: 640/640 non-zero, sum=24.335054
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.924 -0.193 0.560 1.205 0.144 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=3.340, range=[-0.105, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=3.340
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=37.783131
[DECODER] After pos encoding: 384/384 non-zero, sum=57.001179
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000008
[DEBUG] Decoder sample values: -1.176 -0.256 2.629 1.246 0.354 
[DEBUG] Output range: [-2.112, 5.215]
[DEBUG] Output sample values: 1.257 3.451 5.215 3.889 4.040 
[GEN] Step 2 - Best token: 907 (score: 2.0, target_len: 4) [Top scores: 907:2.0 11:1.9 61:1.8 1:1.7 851:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.683, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-7.725162
[ENCODER] After pos encoding: 640/640 non-zero, sum=24.335054
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.924 -0.193 0.560 1.205 0.144 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=2.162, range=[-0.106, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=2.162
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=24.456402
[DECODER] After pos encoding: 512/512 non-zero, sum=50.092506
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.176 -0.255 2.632 1.246 0.354 
[DEBUG] Output range: [-2.206, 5.215]
[DEBUG] Output sample values: 1.257 3.451 5.215 3.889 4.040 
ENG: <sos> how are you <eos>
ESP: <sos> a la abogado mir <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.331, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.056111
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.692200
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.926 -0.200 0.550 1.212 0.148 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.914, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.914
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=10.344390
[DECODER] After pos encoding: 128/128 non-zero, sum=16.744389
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.176 -0.263 2.611 1.255 0.357 
[DEBUG] Output range: [-1.955, 5.214]
[DEBUG] Output sample values: 1.261 3.456 5.214 3.889 4.043 
[GEN] Step 0 - Best token: 4 (score: 4.0, target_len: 3) [Top scores: 4:4.0 23:2.1 1:2.0 6:2.0 81:1.8 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.331, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.056111
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.692200
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.926 -0.200 0.550 1.212 0.148 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.243, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.243
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=25.375410
[DECODER] After pos encoding: 256/256 non-zero, sum=38.181400
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.177 -0.262 2.612 1.255 0.357 
[DEBUG] Output range: [-2.625, 5.214]
[DEBUG] Output sample values: 1.261 3.457 5.214 3.889 4.043 
[GEN] Step 1 - Best token: 528 (score: 2.2, target_len: 3) [Top scores: 6:2.5 528:2.2 490:1.7 513:1.7 544:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.331, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.056111
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.692200
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.926 -0.200 0.550 1.212 0.148 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=3.449, range=[-0.105, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=3.449
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=39.019432
[DECODER] After pos encoding: 384/384 non-zero, sum=58.237465
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -1.176 -0.263 2.612 1.255 0.357 
[DEBUG] Output range: [-2.596, 5.214]
[DEBUG] Output sample values: 1.261 3.457 5.214 3.889 4.043 
[GEN] Step 2 - Best token: 6 (score: 2.2, target_len: 3) [Top scores: 6:2.2 549:2.1 473:2.0 1:2.0 38:2.0 ]
ENG: <sos> good morning <eos>
ESP: <sos> a entender la <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.005, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=0.060984
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.697105
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.919 -0.196 0.552 1.207 0.142 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.914, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.914
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=10.344390
[DECODER] After pos encoding: 128/128 non-zero, sum=16.744389
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.171 -0.259 2.612 1.252 0.354 
[DEBUG] Output range: [-1.953, 5.215]
[DEBUG] Output sample values: 1.261 3.453 5.215 3.887 4.041 
[GEN] Step 0 - Best token: 4 (score: 4.0, target_len: 3) [Top scores: 4:4.0 23:2.1 6:2.0 1:2.0 81:1.8 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.005, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=0.060984
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.697105
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.919 -0.196 0.552 1.207 0.142 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=2.243, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=2.243
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=25.375410
[DECODER] After pos encoding: 256/256 non-zero, sum=38.181400
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -1.171 -0.259 2.612 1.252 0.354 
[DEBUG] Output range: [-2.137, 5.215]
[DEBUG] Output sample values: 1.261 3.453 5.215 3.887 4.041 
[GEN] Step 1 - Best token: 6 (score: 2.2, target_len: 3) [Top scores: 6:2.2 536:1.9 81:1.8 379:1.8 851:1.8 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.005, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=0.060984
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.697105
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.919 -0.196 0.552 1.207 0.142 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=3.340, range=[-0.105, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=3.340
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=37.783131
[DECODER] After pos encoding: 384/384 non-zero, sum=57.001179
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.171 -0.259 2.615 1.251 0.353 
[DEBUG] Output range: [-2.188, 5.215]
[DEBUG] Output sample values: 1.261 3.452 5.215 3.887 4.041 
[GEN] Step 2 - Best token: 11 (score: 1.9, target_len: 3) [Top scores: 11:1.9 707:1.9 167:1.8 18:1.8 824:1.6 ]
ENG: <sos> thank you <eos>
ESP: <sos> a la es <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.139, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-12.881708
[ENCODER] After pos encoding: 640/640 non-zero, sum=19.178484
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.923 -0.199 0.555 1.208 0.149 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.914, range=[-0.104, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.914
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=10.344390
[DECODER] After pos encoding: 128/128 non-zero, sum=16.744389
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.174 -0.262 2.615 1.251 0.358 
[DEBUG] Output range: [-1.955, 5.217]
[DEBUG] Output sample values: 1.261 3.455 5.217 3.887 4.038 
[GEN] Step 0 - Best token: 23 (score: 2.1, target_len: 4) [Top scores: 4:4.0 23:2.1 6:2.0 1:2.0 81:1.8 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.139, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-12.881708
[ENCODER] After pos encoding: 640/640 non-zero, sum=19.178484
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.923 -0.199 0.555 1.208 0.149 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1.213, range=[-0.106, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1.213
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=13.725952
[DECODER] After pos encoding: 256/256 non-zero, sum=26.531967
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.174 -0.262 2.615 1.251 0.358 
[DEBUG] Output range: [-2.237, 5.217]
[DEBUG] Output sample values: 1.261 3.455 5.217 3.887 4.038 
[GEN] Step 1 - Best token: 6 (score: 2.3, target_len: 4) [Top scores: 6:2.3 741:2.1 739:2.1 611:2.1 255:2.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.139, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-12.881708
[ENCODER] After pos encoding: 640/640 non-zero, sum=19.178484
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.923 -0.199 0.555 1.208 0.149 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=2.310, range=[-0.106, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=2.310
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=26.133680
[DECODER] After pos encoding: 384/384 non-zero, sum=45.351742
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -1.174 -0.263 2.619 1.251 0.359 
[DEBUG] Output range: [-2.129, 5.326]
[DEBUG] Output sample values: 1.261 3.455 5.217 3.887 4.037 
[GEN] Step 2 - Best token: 4 (score: 3.6, target_len: 4) [Top scores: 4:3.6 1:2.2 347:2.0 549:1.9 38:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-1.139, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-12.881708
[ENCODER] After pos encoding: 640/640 non-zero, sum=19.178484
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.923 -0.199 0.555 1.208 0.149 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=3.638, range=[-0.106, 0.867]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=3.638
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=41.164684
[DECODER] After pos encoding: 512/512 non-zero, sum=66.800842
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -1.174 -0.262 2.622 1.251 0.358 
[DEBUG] Output range: [-2.135, 5.242]
[DEBUG] Output sample values: 1.261 3.455 5.218 3.887 4.037 
ENG: <sos> i love you <eos>
ESP: <sos> l la a vendr <eos>
---