Se truncaron las últimas líneas 5000 del resultado de transmisión.
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=19, d_model=128
[EMBEDDING] 2432/2432 non-zero, sum=-4.013, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2368/2432 non-zero, sum=122.624809
[ENCODER] SCALED EMBEDS before add: 2432/2432 non-zero, sum=-45.399075
[ENCODER] After pos encoding: 2432/2432 non-zero, sum=77.225716
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 0 output: 2432/2432 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 1 output: 2432/2432 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -0.887 0.823 -0.294 1.096 0.799 
[EMBEDDING] Forward pass - seq_len=20, d_model=128
[EMBEDDING] 2560/2560 non-zero, sum=4.505, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2560/2560 non-zero, sum=4.505
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2496/2560 non-zero, sum=129.138367
[DECODER] SCALED EMBEDS before add: 2560/2560 non-zero, sum=50.968937
[DECODER] After pos encoding: 2560/2560 non-zero, sum=180.107315
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2560/2560 non-zero, sum=-0.000027
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2560/2560 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.870 0.776 0.378 0.821 0.678 
[DEBUG] Output range: [-2.737, 2.302]
[DEBUG] Output sample values: -0.985 -0.828 -0.804 -0.280 0.106 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 20 tokens with lr=0.001
[EMBEDDING] Gradient stats: 2560/2560 non-zero, sum=-0.032, range=[-0.045, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 20 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.434, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=4.907328
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=62.723785
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.892 0.822 -0.306 1.099 0.806 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.969, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.969
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-10.958792
[DECODER] After pos encoding: 896/896 non-zero, sum=33.967567
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.874 0.776 0.372 0.828 0.683 
[DEBUG] Output range: [-2.177, 2.363]
[DEBUG] Output sample values: -0.984 -0.833 -0.791 -0.289 0.124 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.178, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.646505
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=76.014900
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.889 0.820 -0.299 1.094 0.816 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.277, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.277
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.132938
[DECODER] After pos encoding: 896/896 non-zero, sum=41.793388
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.871 0.774 0.375 0.821 0.690 
[DEBUG] Output range: [-2.215, 2.256]
[DEBUG] Output sample values: -0.979 -0.830 -0.797 -0.285 0.118 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.903, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=21.530188
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.346649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000013
[DEBUG] Encoder sample values: -0.896 0.824 -0.298 1.101 0.810 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.712, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.712
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.055750
[DECODER] After pos encoding: 1024/1024 non-zero, sum=59.424099
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: -0.875 0.777 0.376 0.826 0.685 
[DEBUG] Output range: [-2.703, 2.296]
[DEBUG] Output sample values: -0.980 -0.826 -0.797 -0.287 0.114 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
Epoca 53/60 - Loss: 7.9248

Época 54/60
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.869, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.869
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.833015
[DECODER] After pos encoding: 512/512 non-zero, sum=15.803116
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.871 0.774 0.375 0.822 0.689 
[DEBUG] Output range: [-2.034, 1.808]
[DEBUG] Output sample values: -0.982 -0.828 -0.798 -0.283 0.114 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 4 tokens with lr=0.001
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.167, range=[-0.225, 0.001]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.195, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.520287
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=44.296127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.901 0.816 -0.293 1.100 0.815 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.776, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.776
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=20.093466
[DECODER] After pos encoding: 1152/1152 non-zero, sum=77.909912
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.880 0.771 0.378 0.825 0.688 
[DEBUG] Output range: [-2.296, 2.182]
[DEBUG] Output sample values: -0.978 -0.827 -0.794 -0.288 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.574, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-6.489671
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=70.706779
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -0.891 0.821 -0.306 1.090 0.808 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.539, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.539
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=17.407488
[DECODER] After pos encoding: 1408/1408 non-zero, sum=88.137901
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.874 0.775 0.372 0.820 0.686 
[DEBUG] Output range: [-2.503, 2.567]
[DEBUG] Output sample values: -0.982 -0.829 -0.798 -0.285 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.701, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=41.866955
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=112.597473
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.891 0.814 -0.297 1.095 0.808 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.082, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.082
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=34.869167
[DECODER] After pos encoding: 1280/1280 non-zero, sum=99.139557
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.872 0.770 0.378 0.820 0.685 
[DEBUG] Output range: [-2.691, 2.269]
[DEBUG] Output sample values: -0.980 -0.830 -0.796 -0.282 0.112 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=19, d_model=128
[EMBEDDING] 2432/2432 non-zero, sum=-4.013, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2368/2432 non-zero, sum=122.624809
[ENCODER] SCALED EMBEDS before add: 2432/2432 non-zero, sum=-45.399075
[ENCODER] After pos encoding: 2432/2432 non-zero, sum=77.225716
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 0 output: 2432/2432 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 1 output: 2432/2432 non-zero, sum=-0.000011
[DEBUG] Encoder sample values: -0.888 0.823 -0.294 1.096 0.799 
[EMBEDDING] Forward pass - seq_len=20, d_model=128
[EMBEDDING] 2560/2560 non-zero, sum=4.506, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2560/2560 non-zero, sum=4.506
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2496/2560 non-zero, sum=129.138367
[DECODER] SCALED EMBEDS before add: 2560/2560 non-zero, sum=50.976532
[DECODER] After pos encoding: 2560/2560 non-zero, sum=180.114929
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2560/2560 non-zero, sum=0.000044
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2560/2560 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -0.870 0.775 0.381 0.821 0.678 
[DEBUG] Output range: [-2.737, 2.302]
[DEBUG] Output sample values: -0.985 -0.826 -0.802 -0.278 0.107 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 20 tokens with lr=0.001
[EMBEDDING] Gradient stats: 2560/2560 non-zero, sum=-0.032, range=[-0.045, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 20 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.434, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=4.907328
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=62.723785
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.892 0.822 -0.306 1.099 0.806 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.968, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.968
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-10.951091
[DECODER] After pos encoding: 896/896 non-zero, sum=33.975258
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000008
[DEBUG] Decoder sample values: -0.874 0.776 0.375 0.828 0.683 
[DEBUG] Output range: [-2.177, 2.363]
[DEBUG] Output sample values: -0.984 -0.831 -0.790 -0.286 0.125 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.178, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.646505
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=76.014900
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.889 0.820 -0.299 1.094 0.816 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.276, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.276
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.125258
[DECODER] After pos encoding: 896/896 non-zero, sum=41.801079
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000012
[DEBUG] Decoder sample values: -0.871 0.774 0.378 0.820 0.689 
[DEBUG] Output range: [-2.215, 2.256]
[DEBUG] Output sample values: -0.979 -0.828 -0.795 -0.283 0.118 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.903, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=21.530188
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.346649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -0.896 0.824 -0.298 1.101 0.810 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.713, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.713
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.064012
[DECODER] After pos encoding: 1024/1024 non-zero, sum=59.432407
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.876 0.777 0.379 0.826 0.685 
[DEBUG] Output range: [-2.703, 2.296]
[DEBUG] Output sample values: -0.980 -0.824 -0.795 -0.285 0.114 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
Epoca 54/60 - Loss: 7.9237

Época 55/60
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.868, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.868
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.824360
[DECODER] After pos encoding: 512/512 non-zero, sum=15.811770
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.871 0.774 0.378 0.822 0.688 
[DEBUG] Output range: [-2.034, 1.808]
[DEBUG] Output sample values: -0.982 -0.826 -0.796 -0.280 0.114 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 4 tokens with lr=0.001
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.167, range=[-0.225, 0.001]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.195, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.520287
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=44.296127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -0.901 0.816 -0.293 1.100 0.815 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.777, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.777
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=20.101374
[DECODER] After pos encoding: 1152/1152 non-zero, sum=77.917740
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -0.880 0.770 0.382 0.825 0.687 
[DEBUG] Output range: [-2.296, 2.183]
[DEBUG] Output sample values: -0.978 -0.825 -0.792 -0.285 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.574, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-6.489671
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=70.706779
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.891 0.821 -0.306 1.090 0.808 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.539, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.539
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=17.414652
[DECODER] After pos encoding: 1408/1408 non-zero, sum=88.145035
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.874 0.775 0.375 0.820 0.686 
[DEBUG] Output range: [-2.503, 2.567]
[DEBUG] Output sample values: -0.982 -0.827 -0.796 -0.283 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.701, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=41.866955
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=112.597473
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.891 0.814 -0.297 1.095 0.808 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.083, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.083
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=34.876011
[DECODER] After pos encoding: 1280/1280 non-zero, sum=99.146408
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000013
[DEBUG] Decoder sample values: -0.872 0.770 0.381 0.820 0.685 
[DEBUG] Output range: [-2.691, 2.269]
[DEBUG] Output sample values: -0.980 -0.827 -0.794 -0.279 0.112 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=19, d_model=128
[EMBEDDING] 2432/2432 non-zero, sum=-4.013, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2368/2432 non-zero, sum=122.624809
[ENCODER] SCALED EMBEDS before add: 2432/2432 non-zero, sum=-45.399075
[ENCODER] After pos encoding: 2432/2432 non-zero, sum=77.225716
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 0 output: 2432/2432 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 1 output: 2432/2432 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: -0.888 0.823 -0.294 1.096 0.799 
[EMBEDDING] Forward pass - seq_len=20, d_model=128
[EMBEDDING] 2560/2560 non-zero, sum=4.506, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2560/2560 non-zero, sum=4.506
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2496/2560 non-zero, sum=129.138367
[DECODER] SCALED EMBEDS before add: 2560/2560 non-zero, sum=50.984055
[DECODER] After pos encoding: 2560/2560 non-zero, sum=180.122467
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2560/2560 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2560/2560 non-zero, sum=-0.000016
[DEBUG] Decoder sample values: -0.870 0.775 0.384 0.821 0.678 
[DEBUG] Output range: [-2.737, 2.302]
[DEBUG] Output sample values: -0.985 -0.824 -0.800 -0.275 0.107 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 20 tokens with lr=0.001
[EMBEDDING] Gradient stats: 2560/2560 non-zero, sum=-0.032, range=[-0.045, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 20 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.434, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=4.907328
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=62.723785
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.892 0.822 -0.306 1.099 0.806 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.967, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.967
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-10.943399
[DECODER] After pos encoding: 896/896 non-zero, sum=33.982990
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.874 0.776 0.378 0.828 0.683 
[DEBUG] Output range: [-2.177, 2.363]
[DEBUG] Output sample values: -0.984 -0.829 -0.788 -0.284 0.125 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.178, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.646505
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=76.014900
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.889 0.820 -0.299 1.094 0.816 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.276, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.276
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.117593
[DECODER] After pos encoding: 896/896 non-zero, sum=41.808739
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.872 0.773 0.381 0.820 0.689 
[DEBUG] Output range: [-2.214, 2.256]
[DEBUG] Output sample values: -0.979 -0.825 -0.793 -0.280 0.119 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.903, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=21.530188
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.346649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: -0.896 0.824 -0.298 1.101 0.810 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.713, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.713
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.072316
[DECODER] After pos encoding: 1024/1024 non-zero, sum=59.440689
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.876 0.777 0.382 0.826 0.685 
[DEBUG] Output range: [-2.704, 2.296]
[DEBUG] Output sample values: -0.980 -0.822 -0.793 -0.282 0.115 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
Epoca 55/60 - Loss: 7.9227

Época 56/60
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.868, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.868
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.815689
[DECODER] After pos encoding: 512/512 non-zero, sum=15.820448
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000009
[DEBUG] Decoder sample values: -0.871 0.774 0.381 0.821 0.688 
[DEBUG] Output range: [-2.034, 1.808]
[DEBUG] Output sample values: -0.982 -0.824 -0.794 -0.278 0.115 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 4 tokens with lr=0.001
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.167, range=[-0.225, 0.001]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.195, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.520287
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=44.296127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.901 0.816 -0.293 1.100 0.815 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.777, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.777
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=20.109217
[DECODER] After pos encoding: 1152/1152 non-zero, sum=77.925674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -0.880 0.770 0.385 0.825 0.687 
[DEBUG] Output range: [-2.296, 2.183]
[DEBUG] Output sample values: -0.978 -0.823 -0.791 -0.283 0.117 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.574, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-6.489671
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=70.706779
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.891 0.821 -0.306 1.090 0.808 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.540, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.540
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=17.421837
[DECODER] After pos encoding: 1408/1408 non-zero, sum=88.152321
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000013
[DEBUG] Decoder sample values: -0.874 0.775 0.378 0.820 0.685 
[DEBUG] Output range: [-2.503, 2.567]
[DEBUG] Output sample values: -0.982 -0.824 -0.794 -0.280 0.117 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.701, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=41.866955
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=112.597473
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.891 0.814 -0.297 1.095 0.808 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.083, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.083
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=34.882858
[DECODER] After pos encoding: 1280/1280 non-zero, sum=99.153412
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000010
[DEBUG] Decoder sample values: -0.872 0.769 0.384 0.820 0.684 
[DEBUG] Output range: [-2.691, 2.269]
[DEBUG] Output sample values: -0.980 -0.825 -0.792 -0.277 0.113 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=19, d_model=128
[EMBEDDING] 2432/2432 non-zero, sum=-4.013, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2368/2432 non-zero, sum=122.624809
[ENCODER] SCALED EMBEDS before add: 2432/2432 non-zero, sum=-45.399075
[ENCODER] After pos encoding: 2432/2432 non-zero, sum=77.225716
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 0 output: 2432/2432 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 1 output: 2432/2432 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.888 0.823 -0.294 1.096 0.799 
[EMBEDDING] Forward pass - seq_len=20, d_model=128
[EMBEDDING] 2560/2560 non-zero, sum=4.507, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2560/2560 non-zero, sum=4.507
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2496/2560 non-zero, sum=129.138367
[DECODER] SCALED EMBEDS before add: 2560/2560 non-zero, sum=50.991646
[DECODER] After pos encoding: 2560/2560 non-zero, sum=180.129868
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2560/2560 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2560/2560 non-zero, sum=-0.000027
[DEBUG] Decoder sample values: -0.870 0.775 0.388 0.821 0.677 
[DEBUG] Output range: [-2.737, 2.302]
[DEBUG] Output sample values: -0.985 -0.822 -0.798 -0.273 0.108 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 20 tokens with lr=0.001
[EMBEDDING] Gradient stats: 2560/2560 non-zero, sum=-0.032, range=[-0.045, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 20 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.434, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=4.907328
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=62.723785
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.892 0.822 -0.306 1.099 0.806 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.967, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.967
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-10.935710
[DECODER] After pos encoding: 896/896 non-zero, sum=33.990646
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.874 0.776 0.381 0.828 0.682 
[DEBUG] Output range: [-2.178, 2.363]
[DEBUG] Output sample values: -0.984 -0.827 -0.786 -0.281 0.126 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.178, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.646505
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=76.014900
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.889 0.820 -0.299 1.094 0.816 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.275, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.275
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.109927
[DECODER] After pos encoding: 896/896 non-zero, sum=41.816399
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -0.872 0.773 0.384 0.820 0.689 
[DEBUG] Output range: [-2.214, 2.256]
[DEBUG] Output sample values: -0.980 -0.823 -0.791 -0.278 0.119 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.903, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=21.530188
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.346649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DEBUG] Encoder sample values: -0.896 0.824 -0.298 1.101 0.810 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.714, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.714
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.080624
[DECODER] After pos encoding: 1024/1024 non-zero, sum=59.449047
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -0.876 0.776 0.385 0.826 0.684 
[DEBUG] Output range: [-2.704, 2.297]
[DEBUG] Output sample values: -0.980 -0.820 -0.792 -0.280 0.115 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
Epoca 56/60 - Loss: 7.9217

Época 57/60
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.867, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.867
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.807024
[DECODER] After pos encoding: 512/512 non-zero, sum=15.829104
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -0.871 0.774 0.384 0.821 0.688 
[DEBUG] Output range: [-2.034, 1.808]
[DEBUG] Output sample values: -0.982 -0.822 -0.793 -0.275 0.115 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 4 tokens with lr=0.001
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.167, range=[-0.225, 0.001]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.195, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.520287
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=44.296127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.901 0.816 -0.293 1.100 0.815 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.778, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.778
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=20.117094
[DECODER] After pos encoding: 1152/1152 non-zero, sum=77.933533
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -0.880 0.770 0.388 0.825 0.687 
[DEBUG] Output range: [-2.296, 2.183]
[DEBUG] Output sample values: -0.978 -0.821 -0.789 -0.280 0.117 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.574, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-6.489671
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=70.706779
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.891 0.821 -0.306 1.090 0.808 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.541
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=17.429037
[DECODER] After pos encoding: 1408/1408 non-zero, sum=88.159569
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -0.874 0.774 0.381 0.820 0.685 
[DEBUG] Output range: [-2.503, 2.566]
[DEBUG] Output sample values: -0.983 -0.822 -0.793 -0.278 0.117 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.701, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=41.866955
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=112.597473
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000010
[DEBUG] Encoder sample values: -0.891 0.814 -0.297 1.095 0.808 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.084, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.084
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=34.889698
[DECODER] After pos encoding: 1280/1280 non-zero, sum=99.160187
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.872 0.769 0.387 0.820 0.684 
[DEBUG] Output range: [-2.691, 2.269]
[DEBUG] Output sample values: -0.980 -0.823 -0.791 -0.274 0.113 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=19, d_model=128
[EMBEDDING] 2432/2432 non-zero, sum=-4.013, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2368/2432 non-zero, sum=122.624809
[ENCODER] SCALED EMBEDS before add: 2432/2432 non-zero, sum=-45.399075
[ENCODER] After pos encoding: 2432/2432 non-zero, sum=77.225716
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 0 output: 2432/2432 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 1 output: 2432/2432 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -0.888 0.823 -0.294 1.096 0.799 
[EMBEDDING] Forward pass - seq_len=20, d_model=128
[EMBEDDING] 2560/2560 non-zero, sum=4.508, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2560/2560 non-zero, sum=4.508
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2496/2560 non-zero, sum=129.138367
[DECODER] SCALED EMBEDS before add: 2560/2560 non-zero, sum=50.999264
[DECODER] After pos encoding: 2560/2560 non-zero, sum=180.137360
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2560/2560 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2560/2560 non-zero, sum=0.000018
[DEBUG] Decoder sample values: -0.870 0.775 0.391 0.821 0.677 
[DEBUG] Output range: [-2.737, 2.302]
[DEBUG] Output sample values: -0.985 -0.820 -0.797 -0.270 0.108 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 20 tokens with lr=0.001
[EMBEDDING] Gradient stats: 2560/2560 non-zero, sum=-0.032, range=[-0.045, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 20 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.434, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=4.907328
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=62.723785
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000013
[DEBUG] Encoder sample values: -0.892 0.822 -0.306 1.099 0.806 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.966, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.966
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-10.928015
[DECODER] After pos encoding: 896/896 non-zero, sum=33.998344
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.874 0.776 0.384 0.828 0.682 
[DEBUG] Output range: [-2.178, 2.363]
[DEBUG] Output sample values: -0.984 -0.825 -0.785 -0.279 0.126 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.178, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.646505
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=76.014900
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000011
[DEBUG] Encoder sample values: -0.889 0.820 -0.299 1.094 0.816 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.274, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.274
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.102267
[DECODER] After pos encoding: 896/896 non-zero, sum=41.824062
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.872 0.773 0.387 0.820 0.688 
[DEBUG] Output range: [-2.214, 2.256]
[DEBUG] Output sample values: -0.980 -0.821 -0.790 -0.275 0.120 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.903, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=21.530188
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.346649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: -0.896 0.824 -0.298 1.101 0.810 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.715, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.715
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.088898
[DECODER] After pos encoding: 1024/1024 non-zero, sum=59.457275
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.876 0.776 0.389 0.826 0.684 
[DEBUG] Output range: [-2.704, 2.297]
[DEBUG] Output sample values: -0.980 -0.818 -0.790 -0.277 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
Epoca 57/60 - Loss: 7.9208

Época 58/60
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.866, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.866
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.798362
[DECODER] After pos encoding: 512/512 non-zero, sum=15.837769
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.871 0.773 0.388 0.821 0.687 
[DEBUG] Output range: [-2.034, 1.808]
[DEBUG] Output sample values: -0.982 -0.820 -0.791 -0.273 0.115 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 4 tokens with lr=0.001
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.167, range=[-0.225, 0.001]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.195, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.520287
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=44.296127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.901 0.816 -0.293 1.100 0.815 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.779, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.779
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=20.124952
[DECODER] After pos encoding: 1152/1152 non-zero, sum=77.941368
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.881 0.770 0.391 0.825 0.686 
[DEBUG] Output range: [-2.296, 2.183]
[DEBUG] Output sample values: -0.978 -0.819 -0.787 -0.278 0.117 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.574, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-6.489671
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=70.706779
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000012
[DEBUG] Encoder sample values: -0.891 0.821 -0.306 1.090 0.808 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.541
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=17.436251
[DECODER] After pos encoding: 1408/1408 non-zero, sum=88.166687
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -0.874 0.774 0.385 0.819 0.685 
[DEBUG] Output range: [-2.503, 2.566]
[DEBUG] Output sample values: -0.983 -0.820 -0.791 -0.276 0.117 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.701, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=41.866955
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=112.597473
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: -0.891 0.814 -0.297 1.095 0.808 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.084, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.084
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=34.896545
[DECODER] After pos encoding: 1280/1280 non-zero, sum=99.166931
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -0.872 0.769 0.391 0.820 0.683 
[DEBUG] Output range: [-2.691, 2.269]
[DEBUG] Output sample values: -0.980 -0.821 -0.789 -0.272 0.114 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=19, d_model=128
[EMBEDDING] 2432/2432 non-zero, sum=-4.013, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2368/2432 non-zero, sum=122.624809
[ENCODER] SCALED EMBEDS before add: 2432/2432 non-zero, sum=-45.399075
[ENCODER] After pos encoding: 2432/2432 non-zero, sum=77.225716
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 0 output: 2432/2432 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 1 output: 2432/2432 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.888 0.823 -0.294 1.096 0.799 
[EMBEDDING] Forward pass - seq_len=20, d_model=128
[EMBEDDING] 2560/2560 non-zero, sum=4.508, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2560/2560 non-zero, sum=4.508
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2496/2560 non-zero, sum=129.138367
[DECODER] SCALED EMBEDS before add: 2560/2560 non-zero, sum=51.006767
[DECODER] After pos encoding: 2560/2560 non-zero, sum=180.145035
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2560/2560 non-zero, sum=-0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2560/2560 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.870 0.775 0.394 0.821 0.677 
[DEBUG] Output range: [-2.737, 2.302]
[DEBUG] Output sample values: -0.985 -0.818 -0.795 -0.268 0.109 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 20 tokens with lr=0.001
[EMBEDDING] Gradient stats: 2560/2560 non-zero, sum=-0.032, range=[-0.045, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 20 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.434, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=4.907328
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=62.723785
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DEBUG] Encoder sample values: -0.892 0.822 -0.306 1.099 0.806 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.965, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.965
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-10.920324
[DECODER] After pos encoding: 896/896 non-zero, sum=34.006008
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.874 0.776 0.388 0.827 0.681 
[DEBUG] Output range: [-2.178, 2.363]
[DEBUG] Output sample values: -0.984 -0.823 -0.783 -0.277 0.126 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.178, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.646505
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=76.014900
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000012
[DEBUG] Encoder sample values: -0.889 0.820 -0.299 1.094 0.816 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.274, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.274
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.094594
[DECODER] After pos encoding: 896/896 non-zero, sum=41.831753
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000010
[DEBUG] Decoder sample values: -0.872 0.773 0.390 0.820 0.688 
[DEBUG] Output range: [-2.213, 2.256]
[DEBUG] Output sample values: -0.980 -0.819 -0.788 -0.273 0.120 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.903, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=21.530188
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.346649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.896 0.824 -0.298 1.101 0.810 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.716, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.716
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.097186
[DECODER] After pos encoding: 1024/1024 non-zero, sum=59.465523
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.876 0.776 0.392 0.826 0.684 
[DEBUG] Output range: [-2.704, 2.297]
[DEBUG] Output sample values: -0.980 -0.816 -0.788 -0.275 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
Epoca 58/60 - Loss: 7.9197

Época 59/60
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.865, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.865
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.789695
[DECODER] After pos encoding: 512/512 non-zero, sum=15.846438
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.871 0.773 0.391 0.821 0.687 
[DEBUG] Output range: [-2.035, 1.808]
[DEBUG] Output sample values: -0.982 -0.818 -0.789 -0.271 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 4 tokens with lr=0.001
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.167, range=[-0.225, 0.001]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.195, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.520287
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=44.296127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.901 0.816 -0.293 1.100 0.815 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.780, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.780
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=20.132830
[DECODER] After pos encoding: 1152/1152 non-zero, sum=77.949242
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -0.881 0.770 0.394 0.825 0.686 
[DEBUG] Output range: [-2.296, 2.183]
[DEBUG] Output sample values: -0.978 -0.817 -0.785 -0.276 0.118 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.574, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-6.489671
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=70.706779
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000010
[DEBUG] Encoder sample values: -0.891 0.821 -0.306 1.090 0.808 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.542, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.542
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=17.443432
[DECODER] After pos encoding: 1408/1408 non-zero, sum=88.173851
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000011
[DEBUG] Decoder sample values: -0.874 0.774 0.388 0.819 0.684 
[DEBUG] Output range: [-2.503, 2.566]
[DEBUG] Output sample values: -0.983 -0.819 -0.788 -0.273 0.118 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.701, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=41.866955
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=112.597473
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: -0.891 0.814 -0.297 1.095 0.808 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.085, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.085
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=34.903419
[DECODER] After pos encoding: 1280/1280 non-zero, sum=99.173927
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -0.873 0.769 0.394 0.820 0.683 
[DEBUG] Output range: [-2.691, 2.269]
[DEBUG] Output sample values: -0.980 -0.820 -0.786 -0.270 0.114 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=19, d_model=128
[EMBEDDING] 2432/2432 non-zero, sum=-4.013, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2368/2432 non-zero, sum=122.624809
[ENCODER] SCALED EMBEDS before add: 2432/2432 non-zero, sum=-45.399075
[ENCODER] After pos encoding: 2432/2432 non-zero, sum=77.225716
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 0 output: 2432/2432 non-zero, sum=0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 1 output: 2432/2432 non-zero, sum=-0.000022
[DEBUG] Encoder sample values: -0.888 0.823 -0.294 1.096 0.799 
[EMBEDDING] Forward pass - seq_len=20, d_model=128
[EMBEDDING] 2560/2560 non-zero, sum=4.509, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2560/2560 non-zero, sum=4.509
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2496/2560 non-zero, sum=129.138367
[DECODER] SCALED EMBEDS before add: 2560/2560 non-zero, sum=51.014423
[DECODER] After pos encoding: 2560/2560 non-zero, sum=180.152557
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2560/2560 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2560/2560 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -0.870 0.775 0.397 0.821 0.676 
[DEBUG] Output range: [-2.737, 2.302]
[DEBUG] Output sample values: -0.985 -0.816 -0.792 -0.266 0.109 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 20 tokens with lr=0.001
[EMBEDDING] Gradient stats: 2560/2560 non-zero, sum=-0.032, range=[-0.045, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 20 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.434, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=4.907328
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=62.723785
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.892 0.822 -0.306 1.099 0.806 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.965, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.965
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-10.912656
[DECODER] After pos encoding: 896/896 non-zero, sum=34.013687
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -0.874 0.775 0.391 0.827 0.681 
[DEBUG] Output range: [-2.178, 2.364]
[DEBUG] Output sample values: -0.984 -0.821 -0.780 -0.274 0.127 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.178, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.646505
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=76.014900
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -0.889 0.820 -0.299 1.094 0.816 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.273, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.273
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.086928
[DECODER] After pos encoding: 896/896 non-zero, sum=41.839378
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.872 0.773 0.394 0.820 0.688 
[DEBUG] Output range: [-2.213, 2.256]
[DEBUG] Output sample values: -0.980 -0.818 -0.785 -0.271 0.120 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.903, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=21.530188
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.346649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -0.896 0.824 -0.298 1.101 0.810 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.716, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.716
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.105485
[DECODER] After pos encoding: 1024/1024 non-zero, sum=59.473862
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -0.876 0.776 0.395 0.825 0.683 
[DEBUG] Output range: [-2.704, 2.297]
[DEBUG] Output sample values: -0.980 -0.814 -0.786 -0.273 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
Epoca 59/60 - Loss: 7.9187

Época 60/60
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.865, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.865
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.781020
[DECODER] After pos encoding: 512/512 non-zero, sum=15.855114
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.871 0.773 0.394 0.821 0.686 
[DEBUG] Output range: [-2.035, 1.808]
[DEBUG] Output sample values: -0.982 -0.816 -0.787 -0.268 0.116 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 4 tokens with lr=0.001
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.167, range=[-0.225, 0.001]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.195, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-13.520287
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=44.296127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000011
[DEBUG] Encoder sample values: -0.901 0.816 -0.293 1.100 0.815 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.780, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1.780
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=20.140669
[DECODER] After pos encoding: 1152/1152 non-zero, sum=77.957085
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.881 0.770 0.397 0.825 0.686 
[DEBUG] Output range: [-2.296, 2.183]
[DEBUG] Output sample values: -0.978 -0.815 -0.783 -0.273 0.118 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 9 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.574, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-6.489671
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=70.706779
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -0.892 0.821 -0.306 1.090 0.808 
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.542, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1408/1408 non-zero, sum=1.542
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[DECODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=17.450623
[DECODER] After pos encoding: 1408/1408 non-zero, sum=88.181137
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1408/1408 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.874 0.774 0.391 0.819 0.684 
[DEBUG] Output range: [-2.503, 2.566]
[DEBUG] Output sample values: -0.983 -0.817 -0.787 -0.271 0.118 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 11 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1408/1408 non-zero, sum=-0.024, range=[-0.082, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 11 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=3.701, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=41.866955
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=112.597473
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.891 0.814 -0.297 1.095 0.808 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.086, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.086
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=34.910259
[DECODER] After pos encoding: 1280/1280 non-zero, sum=99.180710
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000014
[DEBUG] Decoder sample values: -0.873 0.769 0.397 0.820 0.683 
[DEBUG] Output range: [-2.691, 2.269]
[DEBUG] Output sample values: -0.980 -0.818 -0.785 -0.267 0.114 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 10 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.032, range=[-0.090, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=19, d_model=128
[EMBEDDING] 2432/2432 non-zero, sum=-4.013, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 2368/2432 non-zero, sum=122.624809
[ENCODER] SCALED EMBEDS before add: 2432/2432 non-zero, sum=-45.399075
[ENCODER] After pos encoding: 2432/2432 non-zero, sum=77.225716
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 0 output: 2432/2432 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 2432/2432 non-zero
[ENCODER_LAYER] After self-attention: 2432/2432 non-zero
[ENCODER_LAYER] After norm1: 2432/2432 non-zero
[ENCODER_LAYER] After feedforward: 2432/2432 non-zero
[ENCODER_LAYER] Final output: 2432/2432 non-zero
[ENCODER] Layer 1 output: 2432/2432 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: -0.888 0.823 -0.294 1.096 0.799 
[EMBEDDING] Forward pass - seq_len=20, d_model=128
[EMBEDDING] 2560/2560 non-zero, sum=4.510, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2560/2560 non-zero, sum=4.510
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 2496/2560 non-zero, sum=129.138367
[DECODER] SCALED EMBEDS before add: 2560/2560 non-zero, sum=51.021893
[DECODER] After pos encoding: 2560/2560 non-zero, sum=180.160248
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2560/2560 non-zero, sum=-0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2560/2560 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: -0.871 0.775 0.400 0.821 0.676 
[DEBUG] Output range: [-2.737, 2.302]
[DEBUG] Output sample values: -0.985 -0.814 -0.791 -0.263 0.109 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 20 tokens with lr=0.001
[EMBEDDING] Gradient stats: 2560/2560 non-zero, sum=-0.032, range=[-0.045, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 20 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.434, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=4.907328
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=62.723785
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.892 0.822 -0.306 1.099 0.806 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.964, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.964
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-10.904951
[DECODER] After pos encoding: 896/896 non-zero, sum=34.021381
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -0.874 0.775 0.394 0.827 0.681 
[DEBUG] Output range: [-2.178, 2.364]
[DEBUG] Output sample values: -0.984 -0.819 -0.779 -0.272 0.127 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=2.178, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=24.646505
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=76.014900
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000012
[DEBUG] Encoder sample values: -0.889 0.820 -0.299 1.094 0.816 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.272, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=-0.272
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-3.079256
[DECODER] After pos encoding: 896/896 non-zero, sum=41.847054
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.872 0.773 0.397 0.820 0.687 
[DEBUG] Output range: [-2.212, 2.256]
[DEBUG] Output sample values: -0.980 -0.815 -0.784 -0.269 0.121 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 7 tokens with lr=0.001
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.071, range=[-0.129, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1.903, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=21.530188
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=79.346649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.896 0.824 -0.298 1.101 0.810 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.717, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=0.717
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.113770
[DECODER] After pos encoding: 1024/1024 non-zero, sum=59.482124
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.876 0.776 0.398 0.825 0.683 
[DEBUG] Output range: [-2.704, 2.297]
[DEBUG] Output sample values: -0.980 -0.812 -0.784 -0.270 0.117 
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 2x learning rate: 0.002
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[ATTENTION] Weights updated with lr=0.001
[FEEDFORWARD] Weights updated with lr=0.001
[EMBEDDING] Updating weights for 8 tokens with lr=0.001
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.055, range=[-0.112, 0.000]
[EMBEDDING] Sample weights after update: -0.02295951 -0.07912247 0.06928300 0.07962411 -0.03171565 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00100000
Epoca 60/60 - Loss: 7.9176[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.238, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.238
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.696671
[DECODER] After pos encoding: 128/128 non-zero, sum=9.096674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.871 0.773 0.397 0.821 0.686 
[DEBUG] Output range: [-1.945, 1.809]
[DEBUG] Output sample values: -0.982 -0.814 -0.785 -0.266 0.116 
[GEN] Step 0 - Best token: 266 (score: 1.8, target_len: 4) [Top scores: 266:1.8 814:1.8 953:1.7 760:1.6 604:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.112, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.112
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-12.578751
[DECODER] After pos encoding: 256/256 non-zero, sum=0.227279
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.871 0.773 0.397 0.821 0.686 
[DEBUG] Output range: [-1.945, 2.086]
[DEBUG] Output sample values: -0.982 -0.814 -0.785 -0.266 0.116 
[GEN] Step 1 - Best token: 494 (score: 2.1, target_len: 4) [Top scores: 494:2.1 760:1.9 388:1.7 953:1.6 814:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.599, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.599
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-6.772992
[DECODER] After pos encoding: 384/384 non-zero, sum=12.445083
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.871 0.773 0.397 0.821 0.686 
[DEBUG] Output range: [-2.089, 2.117]
[DEBUG] Output sample values: -0.982 -0.814 -0.785 -0.266 0.116 
[GEN] Step 2 - Best token: 758 (score: 1.9, target_len: 4) [Top scores: 758:1.9 950:1.7 25:1.7 561:1.6 764:1.5 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.998, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-11.288066
[ENCODER] After pos encoding: 640/640 non-zero, sum=20.772127
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.889 0.820 -0.300 1.095 0.813 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.219, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.219
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-2.475734
[DECODER] After pos encoding: 512/512 non-zero, sum=23.160397
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -0.871 0.773 0.397 0.821 0.686 
[DEBUG] Output range: [-2.479, 2.373]
[DEBUG] Output sample values: -0.982 -0.814 -0.785 -0.266 0.116 
 | Test: <sos> llegar encanta recuerdo diccionario <eos>

=== RESUMEN DE ENTRENAMIENTO ===
Pérdida inicial: 7.9795
Mejor pérdida: 7.9176
Mejora absoluta: 0.0619
Mejora porcentual: 0.7761%
¡Entrenamiento completado! Pérdida guardada en training_loss.txt

=== Pruebas de Traducción ===
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.623, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=7.053222
[ENCODER] After pos encoding: 384/384 non-zero, sum=26.271301
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -0.891 0.819 -0.301 1.097 0.811 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.238, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.238
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.696671
[DECODER] After pos encoding: 128/128 non-zero, sum=9.096674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -0.872 0.773 0.397 0.822 0.683 
[DEBUG] Output range: [-1.944, 1.810]
[DEBUG] Output sample values: -0.981 -0.814 -0.785 -0.267 0.119 
[GEN] Step 0 - Best token: 814 (score: 1.8, target_len: 2) [Top scores: 266:1.8 814:1.8 953:1.7 760:1.6 604:1.6 ]
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.623, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=7.053222
[ENCODER] After pos encoding: 384/384 non-zero, sum=26.271301
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -0.891 0.819 -0.301 1.097 0.811 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.122, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.122
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-1.381512
[DECODER] After pos encoding: 256/256 non-zero, sum=11.424518
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: -0.872 0.773 0.397 0.822 0.683 
[DEBUG] Output range: [-1.994, 2.115]
[DEBUG] Output sample values: -0.981 -0.814 -0.785 -0.267 0.119 
[GEN] Step 1 - Best token: 439 (score: 2.0, target_len: 2) [Top scores: 439:2.0 264:1.8 234:1.8 160:1.7 793:1.6 ]
ENG: <sos> hello <eos>
ESP: <sos> barco unidos <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.733, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-8.292391
[ENCODER] After pos encoding: 640/640 non-zero, sum=23.767799
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -0.891 0.819 -0.301 1.095 0.810 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.238, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.238
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.696671
[DECODER] After pos encoding: 128/128 non-zero, sum=9.096674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.872 0.772 0.396 0.821 0.682 
[DEBUG] Output range: [-1.944, 1.810]
[DEBUG] Output sample values: -0.980 -0.814 -0.784 -0.268 0.118 
[GEN] Step 0 - Best token: 266 (score: 1.8, target_len: 4) [Top scores: 266:1.8 814:1.8 953:1.7 760:1.6 604:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.733, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-8.292391
[ENCODER] After pos encoding: 640/640 non-zero, sum=23.767799
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -0.891 0.819 -0.301 1.095 0.810 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.112, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.112
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-12.578751
[DECODER] After pos encoding: 256/256 non-zero, sum=0.227279
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.872 0.772 0.396 0.821 0.682 
[DEBUG] Output range: [-1.944, 1.943]
[DEBUG] Output sample values: -0.980 -0.814 -0.784 -0.268 0.118 
[GEN] Step 1 - Best token: 388 (score: 1.7, target_len: 4) [Top scores: 494:1.9 760:1.8 388:1.7 604:1.6 814:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.733, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-8.292391
[ENCODER] After pos encoding: 640/640 non-zero, sum=23.767799
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -0.891 0.819 -0.301 1.095 0.810 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.429, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-1.429
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-16.162462
[DECODER] After pos encoding: 384/384 non-zero, sum=3.055623
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.872 0.772 0.396 0.821 0.682 
[DEBUG] Output range: [-2.086, 2.148]
[DEBUG] Output sample values: -0.980 -0.814 -0.784 -0.268 0.118 
[GEN] Step 2 - Best token: 244 (score: 1.7, target_len: 4) [Top scores: 244:1.7 494:1.6 929:1.5 730:1.5 999:1.5 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.733, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-8.292391
[ENCODER] After pos encoding: 640/640 non-zero, sum=23.767799
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -0.891 0.819 -0.301 1.095 0.810 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-2.612, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-2.612
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-29.555277
[DECODER] After pos encoding: 512/512 non-zero, sum=-3.919132
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000009
[DEBUG] Decoder sample values: -0.872 0.772 0.396 0.821 0.682 
[DEBUG] Output range: [-2.151, 2.216]
[DEBUG] Output sample values: -0.980 -0.814 -0.784 -0.268 0.118 
ENG: <sos> how are you <eos>
ESP: <sos> llegar lado muchas encanta <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.320, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.619789
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.255905
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.892 0.820 -0.303 1.095 0.812 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.238, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.238
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.696671
[DECODER] After pos encoding: 128/128 non-zero, sum=9.096674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: -0.874 0.774 0.396 0.820 0.685 
[DEBUG] Output range: [-1.944, 1.810]
[DEBUG] Output sample values: -0.981 -0.813 -0.785 -0.266 0.118 
[GEN] Step 0 - Best token: 814 (score: 1.8, target_len: 3) [Top scores: 266:1.8 814:1.8 953:1.7 760:1.6 604:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.320, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.619789
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.255905
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.892 0.820 -0.303 1.095 0.812 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.122, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.122
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-1.381512
[DECODER] After pos encoding: 256/256 non-zero, sum=11.424518
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.874 0.774 0.396 0.820 0.685 
[DEBUG] Output range: [-2.364, 1.810]
[DEBUG] Output sample values: -0.981 -0.813 -0.785 -0.266 0.118 
[GEN] Step 1 - Best token: 977 (score: 1.7, target_len: 3) [Top scores: 977:1.7 411:1.7 874:1.6 23:1.6 902:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.320, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.619789
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.255905
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.892 0.820 -0.303 1.095 0.812 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.367, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=0.367
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=4.149604
[DECODER] After pos encoding: 384/384 non-zero, sum=23.367678
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.874 0.774 0.396 0.820 0.685 
[DEBUG] Output range: [-2.302, 1.929]
[DEBUG] Output sample values: -0.981 -0.813 -0.785 -0.266 0.118 
[GEN] Step 2 - Best token: 12 (score: 1.6, target_len: 3) [Top scores: 12:1.6 242:1.6 251:1.6 23:1.6 173:1.5 ]
ENG: <sos> good morning <eos>
ESP: <sos> barco bosque tom <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-0.494248
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.141872
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.890 0.817 -0.300 1.097 0.810 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.238, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.238
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.696671
[DECODER] After pos encoding: 128/128 non-zero, sum=9.096674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.872 0.771 0.397 0.822 0.683 
[DEBUG] Output range: [-1.944, 1.810]
[DEBUG] Output sample values: -0.983 -0.814 -0.785 -0.268 0.118 
[GEN] Step 0 - Best token: 266 (score: 1.8, target_len: 3) [Top scores: 266:1.8 814:1.8 953:1.7 760:1.6 604:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-0.494248
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.141872
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.890 0.817 -0.300 1.097 0.810 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.112, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.112
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-12.578751
[DECODER] After pos encoding: 256/256 non-zero, sum=0.227279
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -0.872 0.771 0.397 0.822 0.683 
[DEBUG] Output range: [-1.944, 2.002]
[DEBUG] Output sample values: -0.983 -0.814 -0.785 -0.268 0.118 
[GEN] Step 1 - Best token: 494 (score: 2.0, target_len: 3) [Top scores: 494:2.0 760:1.9 388:1.8 690:1.7 604:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-0.494248
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.141872
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.890 0.817 -0.300 1.097 0.810 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.599, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.599
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-6.772992
[DECODER] After pos encoding: 384/384 non-zero, sum=12.445083
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -0.872 0.771 0.397 0.822 0.683 
[DEBUG] Output range: [-1.944, 2.496]
[DEBUG] Output sample values: -0.983 -0.814 -0.785 -0.268 0.118 
[GEN] Step 2 - Best token: 213 (score: 1.9, target_len: 3) [Top scores: 213:1.9 760:1.8 987:1.7 993:1.7 550:1.7 ]
ENG: <sos> thank you <eos>
ESP: <sos> llegar encanta fuera <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.892, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.092062
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.152290
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.889 0.822 -0.298 1.095 0.810 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.238, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.238
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.696671
[DECODER] After pos encoding: 128/128 non-zero, sum=9.096674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.871 0.775 0.399 0.821 0.683 
[DEBUG] Output range: [-1.945, 1.809]
[DEBUG] Output sample values: -0.982 -0.813 -0.786 -0.268 0.117 
[GEN] Step 0 - Best token: 266 (score: 1.8, target_len: 4) [Top scores: 266:1.8 814:1.8 953:1.7 760:1.6 604:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.892, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.092062
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.152290
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.889 0.822 -0.298 1.095 0.810 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-1.112, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-1.112
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-12.578751
[DECODER] After pos encoding: 256/256 non-zero, sum=0.227279
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.871 0.775 0.399 0.821 0.683 
[DEBUG] Output range: [-1.998, 2.004]
[DEBUG] Output sample values: -0.982 -0.813 -0.786 -0.268 0.116 
[GEN] Step 1 - Best token: 604 (score: 1.8, target_len: 4) [Top scores: 494:2.0 760:1.8 604:1.8 690:1.7 388:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.892, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.092062
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.152290
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.889 0.822 -0.298 1.095 0.810 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.951, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.951
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-10.758103
[DECODER] After pos encoding: 384/384 non-zero, sum=8.459972
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.871 0.775 0.399 0.821 0.683 
[DEBUG] Output range: [-2.140, 2.118]
[DEBUG] Output sample values: -0.982 -0.813 -0.786 -0.268 0.116 
[GEN] Step 2 - Best token: 139 (score: 1.9, target_len: 4) [Top scores: 139:1.9 760:1.7 690:1.6 617:1.5 94:1.5 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.892, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.092062
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.152290
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.889 0.822 -0.298 1.095 0.810 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.449, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-1.449
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-16.395882
[DECODER] After pos encoding: 512/512 non-zero, sum=9.240260
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -0.871 0.775 0.399 0.821 0.683 
[DEBUG] Output range: [-2.131, 2.142]
[DEBUG] Output sample values: -0.982 -0.813 -0.786 -0.268 0.116 
ENG: <sos> i love you <eos>
ESP: <sos> llegar tocar mundo j <eos>
---