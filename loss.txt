Se truncaron las últimas líneas 5000 del resultado de transmisión.
[DEBUG] Encoder sample values: 1.485 0.403 0.808 -0.093 1.365 
[EMBEDDING] Forward pass - seq_len=16, d_model=128
[EMBEDDING] 2048/2048 non-zero, sum=4.322, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2048/2048 non-zero, sum=4.322
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1984/2048 non-zero, sum=103.119827
[DECODER] SCALED EMBEDS before add: 2048/2048 non-zero, sum=48.898136
[DECODER] After pos encoding: 2048/2048 non-zero, sum=152.017868
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2048/2048 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2048/2048 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -0.291 0.775 2.460 0.298 0.205 
[DEBUG] Output range: [-2.480, 5.021]
[DEBUG] Output sample values: -0.467 0.686 4.027 2.480 0.934 
[LOSS] Gradient sum: 1.892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 16 tokens with lr=0.006
[EMBEDDING] Gradient stats: 2048/2048 non-zero, sum=-0.054, range=[-0.059, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 16 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.675, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.947577
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.873852
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000009
[DEBUG] Encoder sample values: 1.493 0.395 0.798 -0.094 1.358 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.027, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.027
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-0.300332
[DECODER] After pos encoding: 768/768 non-zero, sum=38.189938
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000000
[DEBUG] Decoder sample values: 0.701 0.537 1.932 0.068 0.297 
[DEBUG] Output range: [-2.442, 4.136]
[DEBUG] Output sample values: 0.105 0.949 4.023 2.441 0.526 
[LOSS] Gradient sum: 1.888
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 6 tokens with lr=0.006
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.093, range=[-0.155, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.065, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-0.736160
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=57.080311
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 1.490 0.409 0.796 -0.088 1.372 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.149, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.149
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=24.315130
[DECODER] After pos encoding: 1152/1152 non-zero, sum=82.131561
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -1.265 1.234 1.102 0.838 -0.549 
[DEBUG] Output range: [-2.134, 4.378]
[DEBUG] Output sample values: 1.365 1.805 3.610 2.726 1.015 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.044, range=[-0.104, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.229, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=2.587343
[ENCODER] After pos encoding: 896/896 non-zero, sum=47.513676
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: 1.481 0.412 0.798 -0.086 1.369 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.382, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.382
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.261265
[DECODER] After pos encoding: 640/640 non-zero, sum=70.321449
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: 0.235 1.400 1.404 0.263 0.250 
[DEBUG] Output range: [-2.188, 4.913]
[DEBUG] Output sample values: 0.179 1.048 3.657 2.919 0.809 
[LOSS] Gradient sum: 1.887
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 5 tokens with lr=0.006
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.124, range=[-0.187, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
Epoca 143/150 - Loss: 6.0363 | LR: 5.512e-03

Época 144/150
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.455, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.455
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=39.094082
[DECODER] After pos encoding: 896/896 non-zero, sum=84.020401
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: 0.471 0.903 1.779 0.498 0.419 
[DEBUG] Output range: [-2.227, 4.699]
[DEBUG] Output sample values: -0.189 0.815 3.790 2.220 0.503 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.467, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=27.914465
[ENCODER] After pos encoding: 896/896 non-zero, sum=72.840790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 1.488 0.399 0.807 -0.083 1.365 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.847, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.847
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.580816
[DECODER] After pos encoding: 896/896 non-zero, sum=54.507137
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: 0.417 0.755 2.477 -0.035 0.487 
[DEBUG] Output range: [-2.292, 4.326]
[DEBUG] Output sample values: 0.160 0.903 3.714 2.357 0.780 
[LOSS] Gradient sum: 1.891
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.073, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.284, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-25.843428
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=31.973015
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 1.492 0.404 0.807 -0.081 1.376 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.451, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=0.451
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=5.106351
[DECODER] After pos encoding: 1152/1152 non-zero, sum=62.922787
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Decoder sample values: 0.593 0.895 1.919 1.318 1.047 
[DEBUG] Output range: [-2.284, 4.482]
[DEBUG] Output sample values: 0.123 0.787 4.065 2.129 0.452 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.103, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.276, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=14.435802
[ENCODER] After pos encoding: 640/640 non-zero, sum=46.495991
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000003
[DEBUG] Encoder sample values: 1.506 0.407 0.809 -0.101 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.906, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.906
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10.247532
[DECODER] After pos encoding: 896/896 non-zero, sum=55.173866
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DEBUG] Decoder sample values: 1.001 1.219 2.263 0.361 0.928 
[DEBUG] Output range: [-2.153, 4.707]
[DEBUG] Output sample values: 0.079 0.503 4.298 1.973 0.207 
[LOSS] Gradient sum: 1.879
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.072, range=[-0.131, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.848, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.598532
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.329018
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: 1.485 0.403 0.808 -0.093 1.365 
[EMBEDDING] Forward pass - seq_len=16, d_model=128
[EMBEDDING] 2048/2048 non-zero, sum=4.321, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2048/2048 non-zero, sum=4.321
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1984/2048 non-zero, sum=103.119827
[DECODER] SCALED EMBEDS before add: 2048/2048 non-zero, sum=48.884651
[DECODER] After pos encoding: 2048/2048 non-zero, sum=152.004791
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2048/2048 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2048/2048 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -0.290 0.775 2.461 0.297 0.203 
[DEBUG] Output range: [-2.480, 5.021]
[DEBUG] Output sample values: -0.468 0.701 4.028 2.482 0.941 
[LOSS] Gradient sum: 1.892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 16 tokens with lr=0.006
[EMBEDDING] Gradient stats: 2048/2048 non-zero, sum=-0.054, range=[-0.059, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 16 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.675, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.947577
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.873852
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 1.493 0.395 0.798 -0.094 1.358 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.027, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.027
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-0.308586
[DECODER] After pos encoding: 768/768 non-zero, sum=38.181675
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: 0.701 0.537 1.932 0.066 0.296 
[DEBUG] Output range: [-2.442, 4.133]
[DEBUG] Output sample values: 0.105 0.960 4.025 2.446 0.531 
[LOSS] Gradient sum: 1.888
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 6 tokens with lr=0.006
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.093, range=[-0.155, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.065, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-0.736160
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=57.080311
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: 1.490 0.409 0.796 -0.088 1.372 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.148, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.148
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=24.302729
[DECODER] After pos encoding: 1152/1152 non-zero, sum=82.119209
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000012
[DEBUG] Decoder sample values: -1.264 1.234 1.103 0.837 -0.550 
[DEBUG] Output range: [-2.134, 4.378]
[DEBUG] Output sample values: 1.365 1.818 3.614 2.717 1.020 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.044, range=[-0.104, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.229, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=2.587343
[ENCODER] After pos encoding: 896/896 non-zero, sum=47.513676
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 1.481 0.412 0.798 -0.086 1.369 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.381, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.381
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.253307
[DECODER] After pos encoding: 640/640 non-zero, sum=70.313446
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000011
[DEBUG] Decoder sample values: 0.235 1.401 1.404 0.262 0.249 
[DEBUG] Output range: [-2.188, 4.916]
[DEBUG] Output sample values: 0.179 1.059 3.664 2.924 0.814 
[LOSS] Gradient sum: 1.887
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 5 tokens with lr=0.006
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.124, range=[-0.187, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
Epoca 144/150 - Loss: 6.0298 | LR: 5.512e-03

Época 145/150
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.455, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.455
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=39.085659
[DECODER] After pos encoding: 896/896 non-zero, sum=84.012009
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000005
[DEBUG] Decoder sample values: 0.471 0.903 1.780 0.497 0.418 
[DEBUG] Output range: [-2.228, 4.701]
[DEBUG] Output sample values: -0.190 0.828 3.793 2.224 0.508 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.467, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=27.914465
[ENCODER] After pos encoding: 896/896 non-zero, sum=72.840790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DEBUG] Encoder sample values: 1.488 0.399 0.807 -0.083 1.365 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.846, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.846
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.571885
[DECODER] After pos encoding: 896/896 non-zero, sum=54.498219
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.417 0.755 2.478 -0.036 0.485 
[DEBUG] Output range: [-2.292, 4.329]
[DEBUG] Output sample values: 0.159 0.915 3.719 2.362 0.786 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.073, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.284, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-25.843428
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=31.973015
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DEBUG] Encoder sample values: 1.492 0.404 0.807 -0.081 1.376 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.450, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=0.450
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=5.094586
[DECODER] After pos encoding: 1152/1152 non-zero, sum=62.910980
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: 0.593 0.896 1.919 1.317 1.046 
[DEBUG] Output range: [-2.284, 4.482]
[DEBUG] Output sample values: 0.123 0.799 4.061 2.136 0.457 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.103, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.276, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=14.435802
[ENCODER] After pos encoding: 640/640 non-zero, sum=46.495991
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 1.506 0.407 0.809 -0.101 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.905, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.905
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10.236393
[DECODER] After pos encoding: 896/896 non-zero, sum=55.162720
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000008
[DEBUG] Decoder sample values: 1.002 1.219 2.263 0.359 0.927 
[DEBUG] Output range: [-2.154, 4.713]
[DEBUG] Output sample values: 0.079 0.516 4.299 1.975 0.211 
[LOSS] Gradient sum: 1.879
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.072, range=[-0.131, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.848, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.598532
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.329018
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000023
[DEBUG] Encoder sample values: 1.485 0.403 0.808 -0.093 1.365 
[EMBEDDING] Forward pass - seq_len=16, d_model=128
[EMBEDDING] 2048/2048 non-zero, sum=4.320, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2048/2048 non-zero, sum=4.320
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1984/2048 non-zero, sum=103.119827
[DECODER] SCALED EMBEDS before add: 2048/2048 non-zero, sum=48.871216
[DECODER] After pos encoding: 2048/2048 non-zero, sum=151.991058
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2048/2048 non-zero, sum=0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2048/2048 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -0.290 0.775 2.461 0.296 0.202 
[DEBUG] Output range: [-2.480, 5.028]
[DEBUG] Output sample values: -0.468 0.710 4.025 2.489 0.946 
[LOSS] Gradient sum: 1.892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 16 tokens with lr=0.006
[EMBEDDING] Gradient stats: 2048/2048 non-zero, sum=-0.054, range=[-0.059, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 16 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.675, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.947577
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.873852
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 1.493 0.395 0.798 -0.094 1.358 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.028, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.028
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-0.316867
[DECODER] After pos encoding: 768/768 non-zero, sum=38.173389
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: 0.701 0.537 1.933 0.065 0.295 
[DEBUG] Output range: [-2.443, 4.135]
[DEBUG] Output sample values: 0.105 0.969 4.027 2.446 0.538 
[LOSS] Gradient sum: 1.888
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 6 tokens with lr=0.006
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.093, range=[-0.155, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.065, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-0.736160
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=57.080311
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: 1.491 0.409 0.796 -0.088 1.372 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.147, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.147
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=24.290285
[DECODER] After pos encoding: 1152/1152 non-zero, sum=82.106712
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -1.264 1.234 1.103 0.836 -0.551 
[DEBUG] Output range: [-2.134, 4.382]
[DEBUG] Output sample values: 1.365 1.831 3.615 2.722 1.026 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.104, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.229, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=2.587343
[ENCODER] After pos encoding: 896/896 non-zero, sum=47.513676
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000011
[DEBUG] Encoder sample values: 1.481 0.412 0.798 -0.086 1.369 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.380, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.380
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.245300
[DECODER] After pos encoding: 640/640 non-zero, sum=70.305412
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 0.236 1.401 1.404 0.260 0.248 
[DEBUG] Output range: [-2.188, 4.914]
[DEBUG] Output sample values: 0.179 1.068 3.667 2.928 0.821 
[LOSS] Gradient sum: 1.887
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 5 tokens with lr=0.006
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.124, range=[-0.187, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
Epoca 145/150 - Loss: 6.0237 | LR: 5.512e-03

Época 146/150
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.454, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.454
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=39.077225
[DECODER] After pos encoding: 896/896 non-zero, sum=84.003555
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: 0.472 0.904 1.780 0.496 0.417 
[DEBUG] Output range: [-2.229, 4.703]
[DEBUG] Output sample values: -0.190 0.835 3.800 2.235 0.514 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.467, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=27.914465
[ENCODER] After pos encoding: 896/896 non-zero, sum=72.840790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000007
[DEBUG] Encoder sample values: 1.488 0.399 0.807 -0.083 1.365 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.845, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.845
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.562963
[DECODER] After pos encoding: 896/896 non-zero, sum=54.489265
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: 0.417 0.755 2.478 -0.037 0.484 
[DEBUG] Output range: [-2.292, 4.337]
[DEBUG] Output sample values: 0.159 0.926 3.727 2.372 0.791 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.073, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.284, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-25.843428
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=31.973015
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DEBUG] Encoder sample values: 1.492 0.404 0.807 -0.081 1.376 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.449, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=0.449
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=5.082798
[DECODER] After pos encoding: 1152/1152 non-zero, sum=62.899261
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[DEBUG] Decoder sample values: 0.594 0.896 1.920 1.315 1.045 
[DEBUG] Output range: [-2.284, 4.486]
[DEBUG] Output sample values: 0.123 0.811 4.069 2.142 0.462 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.103, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.276, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=14.435802
[ENCODER] After pos encoding: 640/640 non-zero, sum=46.495991
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 1.506 0.407 0.809 -0.101 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.904, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.904
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10.225212
[DECODER] After pos encoding: 896/896 non-zero, sum=55.151501
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 1.002 1.220 2.264 0.358 0.925 
[DEBUG] Output range: [-2.154, 4.711]
[DEBUG] Output sample values: 0.078 0.525 4.306 1.984 0.218 
[LOSS] Gradient sum: 1.879
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.072, range=[-0.131, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.848, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.598532
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.329018
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000020
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: 1.485 0.403 0.808 -0.093 1.365 
[EMBEDDING] Forward pass - seq_len=16, d_model=128
[EMBEDDING] 2048/2048 non-zero, sum=4.318, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2048/2048 non-zero, sum=4.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1984/2048 non-zero, sum=103.119827
[DECODER] SCALED EMBEDS before add: 2048/2048 non-zero, sum=48.857746
[DECODER] After pos encoding: 2048/2048 non-zero, sum=151.977737
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2048/2048 non-zero, sum=0.000020
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2048/2048 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -0.290 0.776 2.461 0.294 0.201 
[DEBUG] Output range: [-2.480, 5.037]
[DEBUG] Output sample values: -0.468 0.726 4.033 2.499 0.953 
[LOSS] Gradient sum: 1.892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 16 tokens with lr=0.006
[EMBEDDING] Gradient stats: 2048/2048 non-zero, sum=-0.054, range=[-0.059, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 16 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.675, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.947577
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.873852
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 1.493 0.395 0.798 -0.094 1.358 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.029, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.029
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-0.325163
[DECODER] After pos encoding: 768/768 non-zero, sum=38.165092
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Decoder sample values: 0.702 0.538 1.933 0.064 0.293 
[DEBUG] Output range: [-2.443, 4.133]
[DEBUG] Output sample values: 0.105 0.983 4.037 2.451 0.542 
[LOSS] Gradient sum: 1.888
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 6 tokens with lr=0.006
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.093, range=[-0.155, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.065, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-0.736160
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=57.080311
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 1.491 0.409 0.796 -0.088 1.372 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.146, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.146
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=24.277834
[DECODER] After pos encoding: 1152/1152 non-zero, sum=82.094299
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -1.264 1.235 1.103 0.834 -0.552 
[DEBUG] Output range: [-2.134, 4.384]
[DEBUG] Output sample values: 1.365 1.843 3.620 2.725 1.032 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.104, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.229, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=2.587343
[ENCODER] After pos encoding: 896/896 non-zero, sum=47.513676
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.481 0.412 0.798 -0.086 1.369 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.380, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.380
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.237255
[DECODER] After pos encoding: 640/640 non-zero, sum=70.297462
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Decoder sample values: 0.236 1.401 1.405 0.259 0.246 
[DEBUG] Output range: [-2.188, 4.916]
[DEBUG] Output sample values: 0.178 1.083 3.674 2.931 0.826 
[LOSS] Gradient sum: 1.887
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 5 tokens with lr=0.006
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.124, range=[-0.187, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
Epoca 146/150 - Loss: 6.0161 | LR: 5.512e-03

Época 147/150
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.453, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.453
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=39.068787
[DECODER] After pos encoding: 896/896 non-zero, sum=83.995102
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DEBUG] Decoder sample values: 0.472 0.904 1.780 0.495 0.415 
[DEBUG] Output range: [-2.230, 4.707]
[DEBUG] Output sample values: -0.190 0.852 3.805 2.236 0.519 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.467, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=27.914465
[ENCODER] After pos encoding: 896/896 non-zero, sum=72.840790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: 1.488 0.399 0.807 -0.083 1.365 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.844, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.844
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.553988
[DECODER] After pos encoding: 896/896 non-zero, sum=54.480331
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: 0.418 0.756 2.478 -0.039 0.483 
[DEBUG] Output range: [-2.291, 4.340]
[DEBUG] Output sample values: 0.159 0.940 3.739 2.366 0.796 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.073, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.284, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-25.843428
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=31.973015
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: 1.492 0.404 0.807 -0.081 1.376 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.448, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=0.448
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=5.071003
[DECODER] After pos encoding: 1152/1152 non-zero, sum=62.887451
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Decoder sample values: 0.594 0.896 1.920 1.314 1.043 
[DEBUG] Output range: [-2.284, 4.487]
[DEBUG] Output sample values: 0.123 0.826 4.074 2.136 0.466 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.103, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.276, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=14.435802
[ENCODER] After pos encoding: 640/640 non-zero, sum=46.495991
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: 1.506 0.407 0.809 -0.101 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.903, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.903
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10.214017
[DECODER] After pos encoding: 896/896 non-zero, sum=55.140347
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 1.003 1.220 2.264 0.357 0.924 
[DEBUG] Output range: [-2.155, 4.716]
[DEBUG] Output sample values: 0.078 0.541 4.314 1.980 0.222 
[LOSS] Gradient sum: 1.879
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.072, range=[-0.131, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.848, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.598532
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.329018
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 1.485 0.403 0.808 -0.093 1.365 
[EMBEDDING] Forward pass - seq_len=16, d_model=128
[EMBEDDING] 2048/2048 non-zero, sum=4.317, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2048/2048 non-zero, sum=4.317
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1984/2048 non-zero, sum=103.119827
[DECODER] SCALED EMBEDS before add: 2048/2048 non-zero, sum=48.844257
[DECODER] After pos encoding: 2048/2048 non-zero, sum=151.964020
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2048/2048 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2048/2048 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -0.289 0.776 2.461 0.293 0.199 
[DEBUG] Output range: [-2.480, 5.036]
[DEBUG] Output sample values: -0.468 0.740 4.033 2.491 0.958 
[LOSS] Gradient sum: 1.892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 16 tokens with lr=0.006
[EMBEDDING] Gradient stats: 2048/2048 non-zero, sum=-0.054, range=[-0.059, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 16 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.675, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.947577
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.873852
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DEBUG] Encoder sample values: 1.493 0.395 0.798 -0.094 1.358 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.029, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.029
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-0.333490
[DECODER] After pos encoding: 768/768 non-zero, sum=38.156788
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000007
[DEBUG] Decoder sample values: 0.702 0.538 1.933 0.063 0.292 
[DEBUG] Output range: [-2.443, 4.132]
[DEBUG] Output sample values: 0.104 0.995 4.041 2.451 0.549 
[LOSS] Gradient sum: 1.888
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 6 tokens with lr=0.006
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.093, range=[-0.154, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.065, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-0.736160
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=57.080311
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 1.491 0.409 0.796 -0.088 1.372 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.145, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.145
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=24.265364
[DECODER] After pos encoding: 1152/1152 non-zero, sum=82.081795
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.263 1.235 1.103 0.833 -0.553 
[DEBUG] Output range: [-2.134, 4.388]
[DEBUG] Output sample values: 1.364 1.856 3.620 2.728 1.037 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.104, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.229, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=2.587343
[ENCODER] After pos encoding: 896/896 non-zero, sum=47.513676
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000007
[DEBUG] Encoder sample values: 1.481 0.412 0.797 -0.086 1.369 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.379, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.379
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.229206
[DECODER] After pos encoding: 640/640 non-zero, sum=70.289406
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: 0.237 1.401 1.405 0.258 0.245 
[DEBUG] Output range: [-2.187, 4.921]
[DEBUG] Output sample values: 0.178 1.097 3.681 2.928 0.831 
[LOSS] Gradient sum: 1.887
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 5 tokens with lr=0.006
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.124, range=[-0.187, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
Epoca 147/150 - Loss: 6.0088 | LR: 5.512e-03

Época 148/150
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.452, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.452
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=39.060287
[DECODER] After pos encoding: 896/896 non-zero, sum=83.986649
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: 0.473 0.904 1.780 0.493 0.414 
[DEBUG] Output range: [-2.231, 4.713]
[DEBUG] Output sample values: -0.190 0.866 3.805 2.235 0.525 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.467, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=27.914465
[ENCODER] After pos encoding: 896/896 non-zero, sum=72.840790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: 1.488 0.399 0.807 -0.083 1.365 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.844, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.844
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.545002
[DECODER] After pos encoding: 896/896 non-zero, sum=54.471340
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 0.418 0.756 2.478 -0.040 0.481 
[DEBUG] Output range: [-2.291, 4.346]
[DEBUG] Output sample values: 0.159 0.951 3.735 2.365 0.803 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.073, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.284, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-25.843428
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=31.973015
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: 1.492 0.404 0.807 -0.081 1.376 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.447, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=0.447
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=5.059176
[DECODER] After pos encoding: 1152/1152 non-zero, sum=62.875652
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: 0.595 0.897 1.920 1.313 1.042 
[DEBUG] Output range: [-2.285, 4.498]
[DEBUG] Output sample values: 0.122 0.840 4.081 2.132 0.473 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.103, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.276, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=14.435802
[ENCODER] After pos encoding: 640/640 non-zero, sum=46.495991
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DEBUG] Encoder sample values: 1.506 0.407 0.809 -0.101 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.902, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.902
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10.202819
[DECODER] After pos encoding: 896/896 non-zero, sum=55.129154
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000013
[DEBUG] Decoder sample values: 1.003 1.220 2.264 0.356 0.923 
[DEBUG] Output range: [-2.156, 4.714]
[DEBUG] Output sample values: 0.078 0.552 4.316 1.975 0.228 
[LOSS] Gradient sum: 1.879
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.072, range=[-0.131, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.848, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.598532
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.329018
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.485 0.403 0.808 -0.093 1.365 
[EMBEDDING] Forward pass - seq_len=16, d_model=128
[EMBEDDING] 2048/2048 non-zero, sum=4.316, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2048/2048 non-zero, sum=4.316
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1984/2048 non-zero, sum=103.119827
[DECODER] SCALED EMBEDS before add: 2048/2048 non-zero, sum=48.830772
[DECODER] After pos encoding: 2048/2048 non-zero, sum=151.950516
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2048/2048 non-zero, sum=0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2048/2048 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.289 0.776 2.462 0.292 0.198 
[DEBUG] Output range: [-2.480, 5.043]
[DEBUG] Output sample values: -0.469 0.750 4.038 2.488 0.964 
[LOSS] Gradient sum: 1.892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 16 tokens with lr=0.006
[EMBEDDING] Gradient stats: 2048/2048 non-zero, sum=-0.054, range=[-0.059, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 16 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.675, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.947577
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.873852
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: 1.493 0.395 0.798 -0.094 1.358 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.030, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.030
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-0.341824
[DECODER] After pos encoding: 768/768 non-zero, sum=38.148426
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Decoder sample values: 0.703 0.538 1.933 0.062 0.291 
[DEBUG] Output range: [-2.443, 4.139]
[DEBUG] Output sample values: 0.104 1.006 4.043 2.450 0.556 
[LOSS] Gradient sum: 1.888
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 6 tokens with lr=0.006
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.093, range=[-0.154, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.065, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-0.736160
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=57.080311
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000018
[DEBUG] Encoder sample values: 1.491 0.409 0.796 -0.088 1.372 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.144, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.144
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=24.252876
[DECODER] After pos encoding: 1152/1152 non-zero, sum=82.069336
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000010
[DEBUG] Decoder sample values: -1.263 1.235 1.104 0.832 -0.554 
[DEBUG] Output range: [-2.134, 4.386]
[DEBUG] Output sample values: 1.364 1.869 3.621 2.721 1.043 
[LOSS] Gradient sum: 1.885
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.104, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.229, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=2.587343
[ENCODER] After pos encoding: 896/896 non-zero, sum=47.513676
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 1.481 0.412 0.797 -0.086 1.369 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.378, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.378
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.221146
[DECODER] After pos encoding: 640/640 non-zero, sum=70.281380
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000014
[DEBUG] Decoder sample values: 0.237 1.402 1.405 0.257 0.244 
[DEBUG] Output range: [-2.187, 4.921]
[DEBUG] Output sample values: 0.178 1.108 3.679 2.923 0.837 
[LOSS] Gradient sum: 1.887
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 5 tokens with lr=0.006
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.124, range=[-0.187, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
Epoca 148/150 - Loss: 6.0029 | LR: 5.512e-03

Época 149/150
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.452, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.452
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=39.051819
[DECODER] After pos encoding: 896/896 non-zero, sum=83.978149
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000005
[DEBUG] Decoder sample values: 0.474 0.905 1.781 0.492 0.413 
[DEBUG] Output range: [-2.232, 4.709]
[DEBUG] Output sample values: -0.191 0.877 3.808 2.236 0.532 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.467, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=27.914465
[ENCODER] After pos encoding: 896/896 non-zero, sum=72.840790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 1.488 0.399 0.807 -0.083 1.365 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.843, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.843
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.536011
[DECODER] After pos encoding: 896/896 non-zero, sum=54.462341
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: 0.419 0.756 2.478 -0.041 0.480 
[DEBUG] Output range: [-2.291, 4.351]
[DEBUG] Output sample values: 0.159 0.961 3.740 2.370 0.810 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.073, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.284, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-25.843428
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=31.973015
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000009
[DEBUG] Encoder sample values: 1.492 0.404 0.806 -0.081 1.376 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.446, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=0.446
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=5.047333
[DECODER] After pos encoding: 1152/1152 non-zero, sum=62.863758
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: 0.595 0.897 1.921 1.312 1.041 
[DEBUG] Output range: [-2.285, 4.505]
[DEBUG] Output sample values: 0.122 0.851 4.090 2.140 0.479 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.103, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.276, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=14.435802
[ENCODER] After pos encoding: 640/640 non-zero, sum=46.495991
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: 1.506 0.407 0.809 -0.101 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.901, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.901
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10.191601
[DECODER] After pos encoding: 896/896 non-zero, sum=55.117920
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: 1.004 1.220 2.264 0.355 0.921 
[DEBUG] Output range: [-2.157, 4.737]
[DEBUG] Output sample values: 0.078 0.566 4.323 1.984 0.235 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.072, range=[-0.131, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.848, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.598532
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.329018
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000012
[DEBUG] Encoder sample values: 1.485 0.403 0.808 -0.092 1.365 
[EMBEDDING] Forward pass - seq_len=16, d_model=128
[EMBEDDING] 2048/2048 non-zero, sum=4.315, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2048/2048 non-zero, sum=4.315
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1984/2048 non-zero, sum=103.119827
[DECODER] SCALED EMBEDS before add: 2048/2048 non-zero, sum=48.817253
[DECODER] After pos encoding: 2048/2048 non-zero, sum=151.937103
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2048/2048 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2048/2048 non-zero, sum=-0.000012
[DEBUG] Decoder sample values: -0.288 0.776 2.462 0.291 0.197 
[DEBUG] Output range: [-2.480, 5.050]
[DEBUG] Output sample values: -0.469 0.761 4.048 2.499 0.970 
[LOSS] Gradient sum: 1.892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 16 tokens with lr=0.006
[EMBEDDING] Gradient stats: 2048/2048 non-zero, sum=-0.054, range=[-0.059, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 16 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.675, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.947577
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.873852
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 1.493 0.395 0.797 -0.094 1.358 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.031, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.031
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-0.350189
[DECODER] After pos encoding: 768/768 non-zero, sum=38.140099
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000001
[DEBUG] Decoder sample values: 0.703 0.538 1.934 0.061 0.290 
[DEBUG] Output range: [-2.443, 4.143]
[DEBUG] Output sample values: 0.104 1.019 4.051 2.457 0.563 
[LOSS] Gradient sum: 1.888
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 6 tokens with lr=0.006
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.093, range=[-0.154, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.065, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-0.736160
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=57.080311
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 1.491 0.409 0.796 -0.088 1.372 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.143, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.143
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=24.240366
[DECODER] After pos encoding: 1152/1152 non-zero, sum=82.056831
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -1.263 1.235 1.104 0.831 -0.556 
[DEBUG] Output range: [-2.134, 4.394]
[DEBUG] Output sample values: 1.364 1.883 3.632 2.726 1.048 
[LOSS] Gradient sum: 1.885
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.104, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.229, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=2.587343
[ENCODER] After pos encoding: 896/896 non-zero, sum=47.513676
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: 1.481 0.412 0.797 -0.086 1.369 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.378, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.378
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.213043
[DECODER] After pos encoding: 640/640 non-zero, sum=70.273247
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DEBUG] Decoder sample values: 0.238 1.402 1.405 0.256 0.242 
[DEBUG] Output range: [-2.187, 4.924]
[DEBUG] Output sample values: 0.178 1.122 3.689 2.936 0.844 
[LOSS] Gradient sum: 1.887
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 5 tokens with lr=0.006
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.124, range=[-0.187, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
Epoca 149/150 - Loss: 5.9959 | LR: 5.512e-03

Época 150/150
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=3.451, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=3.451
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=39.043289
[DECODER] After pos encoding: 896/896 non-zero, sum=83.969612
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000011
[DEBUG] Decoder sample values: 0.474 0.905 1.781 0.491 0.411 
[DEBUG] Output range: [-2.233, 4.709]
[DEBUG] Output sample values: -0.191 0.890 3.818 2.247 0.539 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=2.467, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=27.914465
[ENCODER] After pos encoding: 896/896 non-zero, sum=72.840790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: 1.488 0.399 0.807 -0.083 1.365 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.842, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.842
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9.526973
[DECODER] After pos encoding: 896/896 non-zero, sum=54.453300
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.419 0.756 2.478 -0.042 0.479 
[DEBUG] Output range: [-2.291, 4.351]
[DEBUG] Output sample values: 0.158 0.974 3.748 2.379 0.817 
[LOSS] Gradient sum: 1.890
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.073, range=[-0.133, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.284, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-25.843428
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=31.973015
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 1.492 0.404 0.806 -0.081 1.376 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.445, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=0.445
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=5.035464
[DECODER] After pos encoding: 1152/1152 non-zero, sum=62.851929
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.596 0.897 1.921 1.311 1.039 
[DEBUG] Output range: [-2.285, 4.512]
[DEBUG] Output sample values: 0.122 0.864 4.099 2.147 0.483 
[LOSS] Gradient sum: 1.889
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.103, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.276, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=14.435802
[ENCODER] After pos encoding: 640/640 non-zero, sum=46.495991
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: 1.506 0.407 0.809 -0.101 1.370 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.900, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=0.900
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10.180342
[DECODER] After pos encoding: 896/896 non-zero, sum=55.106659
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DEBUG] Decoder sample values: 1.004 1.221 2.264 0.353 0.920 
[DEBUG] Output range: [-2.158, 4.757]
[DEBUG] Output sample values: 0.077 0.578 4.333 1.994 0.241 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 7 tokens with lr=0.006
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.072, range=[-0.131, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.848, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.598532
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.329018
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 1.485 0.403 0.808 -0.092 1.365 
[EMBEDDING] Forward pass - seq_len=16, d_model=128
[EMBEDDING] 2048/2048 non-zero, sum=4.314, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 2048/2048 non-zero, sum=4.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1984/2048 non-zero, sum=103.119827
[DECODER] SCALED EMBEDS before add: 2048/2048 non-zero, sum=48.803711
[DECODER] After pos encoding: 2048/2048 non-zero, sum=151.923508
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 2048/2048 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 2048/2048 non-zero, sum=-0.000016
[DEBUG] Decoder sample values: -0.288 0.776 2.462 0.289 0.195 
[DEBUG] Output range: [-2.480, 5.045]
[DEBUG] Output sample values: -0.469 0.777 4.056 2.506 0.975 
[LOSS] Gradient sum: 1.892
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 16 tokens with lr=0.006
[EMBEDDING] Gradient stats: 2048/2048 non-zero, sum=-0.054, range=[-0.059, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 16 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.675, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=18.947577
[ENCODER] After pos encoding: 896/896 non-zero, sum=63.873852
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: 1.493 0.395 0.797 -0.094 1.358 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.032, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=-0.032
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-0.358596
[DECODER] After pos encoding: 768/768 non-zero, sum=38.131664
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DEBUG] Decoder sample values: 0.704 0.538 1.934 0.059 0.288 
[DEBUG] Output range: [-2.444, 4.147]
[DEBUG] Output sample values: 0.104 1.029 4.057 2.463 0.569 
[LOSS] Gradient sum: 1.888
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 6 tokens with lr=0.006
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.092, range=[-0.154, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.065, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-0.736160
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=57.080311
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000012
[DEBUG] Encoder sample values: 1.491 0.409 0.796 -0.088 1.372 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.141, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=2.141
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=24.227831
[DECODER] After pos encoding: 1152/1152 non-zero, sum=82.044258
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -1.263 1.236 1.104 0.830 -0.557 
[DEBUG] Output range: [-2.134, 4.394]
[DEBUG] Output sample values: 1.364 1.898 3.636 2.727 1.054 
[LOSS] Gradient sum: 1.885
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 9 tokens with lr=0.006
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.043, range=[-0.104, 0.001]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.229, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=2.587343
[ENCODER] After pos encoding: 896/896 non-zero, sum=47.513676
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 1.481 0.412 0.797 -0.086 1.369 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=3.377, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=3.377
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=38.204929
[DECODER] After pos encoding: 640/640 non-zero, sum=70.265114
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DEBUG] Decoder sample values: 0.238 1.402 1.405 0.254 0.241 
[DEBUG] Output range: [-2.187, 4.921]
[DEBUG] Output sample values: 0.178 1.133 3.692 2.936 0.850 
[LOSS] Gradient sum: 1.887
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 8x learning rate: 0.044
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[ATTENTION] Weights updated with lr=0.006
[FEEDFORWARD] Weights updated with lr=0.006
[EMBEDDING] Updating weights for 5 tokens with lr=0.006
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.123, range=[-0.187, 0.002]
[EMBEDDING] Sample weights after update: -0.00607266 0.06729878 -0.07583863 -0.01923650 -0.09519514 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00551250
Epoca 150/150 - Loss: 5.9899 | LR: 5.512e-03[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.119, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.119
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-1.348960
[DECODER] After pos encoding: 128/128 non-zero, sum=5.051042
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000000
[DEBUG] Decoder sample values: 1.064 0.702 1.446 0.158 1.014 
[DEBUG] Output range: [-2.018, 3.781]
[DEBUG] Output sample values: -0.046 0.827 3.781 2.277 0.213 
[GEN] Step 0 - Best token: 9 (score: 3.3, target_len: 7) [Top scores: 9:3.3 17:2.3 42:2.1 28:1.9 239:1.8 ]
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.628, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.628
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-7.104583
[DECODER] After pos encoding: 256/256 non-zero, sum=5.701447
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DEBUG] Decoder sample values: 1.033 0.735 1.484 0.141 0.996 
[DEBUG] Output range: [-2.060, 3.961]
[DEBUG] Output sample values: -0.034 0.820 3.773 2.282 0.224 
[GEN] Step 1 - Best token: 42 (score: 2.7, target_len: 7) [Top scores: 17:2.8 42:2.7 302:2.0 769:1.7 678:1.6 ]
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.927, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.927
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-10.492952
[DECODER] After pos encoding: 384/384 non-zero, sum=8.725123
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: 1.100 0.965 1.756 0.450 0.643 
[DEBUG] Output range: [-2.163, 3.775]
[DEBUG] Output sample values: -0.189 0.822 3.775 2.166 0.308 
[GEN] Step 2 - Best token: 17 (score: 2.3, target_len: 7) [Top scores: 17:2.3 28:2.1 609:2.0 948:1.6 963:1.6 ]
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.660, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.660
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-7.472587
[DECODER] After pos encoding: 512/512 non-zero, sum=18.163546
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000007
[DEBUG] Decoder sample values: 1.010 0.940 1.802 0.387 0.661 
[DEBUG] Output range: [-2.254, 4.023]
[DEBUG] Output sample values: -0.182 0.781 3.812 2.181 0.371 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.333, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-3.772214
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=47.596176
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 1.483 0.399 0.796 -0.090 1.370 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.679, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=-0.679
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-7.686790
[DECODER] After pos encoding: 640/640 non-zero, sum=24.373407
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DEBUG] Decoder sample values: 0.802 0.969 1.749 0.420 0.702 
[DEBUG] Output range: [-2.275, 4.235]
[DEBUG] Output sample values: -0.195 0.860 3.791 2.309 0.446 
 | Test: <sos> el tiene se sus el

=== RESUMEN DE ENTRENAMIENTO ===
Pérdida inicial: 7.7527
Mejor pérdida: 5.9899
Mejora absoluta: 1.7628
Mejora porcentual: 22.7383%
¡Entrenamiento completado! Pérdida guardada en training_loss.txt

=== Pruebas de Traducción ===
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.758, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=8.579517
[ENCODER] After pos encoding: 384/384 non-zero, sum=27.797590
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: 1.486 0.398 0.801 -0.087 1.365 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.119, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.119
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-1.348960
[DECODER] After pos encoding: 128/128 non-zero, sum=5.051042
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 1.067 0.703 1.452 0.159 1.011 
[DEBUG] Output range: [-2.020, 3.782]
[DEBUG] Output sample values: -0.044 0.824 3.782 2.273 0.211 
[GEN] Step 0 - Best token: 17 (score: 2.4, target_len: 2) [Top scores: 9:3.3 17:2.4 42:2.1 28:1.9 239:1.8 ]
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.758, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=8.579517
[ENCODER] After pos encoding: 384/384 non-zero, sum=27.797590
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: 1.486 0.398 0.801 -0.087 1.365 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.148, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.148
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=1.671405
[DECODER] After pos encoding: 256/256 non-zero, sum=14.477434
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000001
[DEBUG] Decoder sample values: 1.034 0.742 1.489 0.171 0.972 
[DEBUG] Output range: [-1.999, 3.788]
[DEBUG] Output sample values: -0.030 0.811 3.788 2.251 0.217 
[GEN] Step 1 - Best token: 9 (score: 3.7, target_len: 2) [Top scores: 9:3.7 677:2.2 28:2.1 423:1.9 77:1.9 ]
ENG: <sos> hello <eos>
ESP: <sos> se el <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.325, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-3.672499
[ENCODER] After pos encoding: 640/640 non-zero, sum=28.387684
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 1.476 0.394 0.800 -0.076 1.361 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.119, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.119
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-1.348960
[DECODER] After pos encoding: 128/128 non-zero, sum=5.051042
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: 1.055 0.698 1.452 0.170 1.010 
[DEBUG] Output range: [-2.020, 3.783]
[DEBUG] Output sample values: -0.049 0.829 3.783 2.283 0.214 
[GEN] Step 0 - Best token: 17 (score: 2.3, target_len: 4) [Top scores: 9:3.3 17:2.3 42:2.1 28:1.9 239:1.8 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.325, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-3.672499
[ENCODER] After pos encoding: 640/640 non-zero, sum=28.387684
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 1.476 0.394 0.800 -0.076 1.361 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.148, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.148
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=1.671405
[DECODER] After pos encoding: 256/256 non-zero, sum=14.477434
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000004
[DEBUG] Decoder sample values: 0.863 0.674 1.894 -0.170 1.195 
[DEBUG] Output range: [-2.016, 3.770]
[DEBUG] Output sample values: -0.266 0.614 3.750 2.625 0.212 
[GEN] Step 1 - Best token: 9 (score: 3.8, target_len: 4) [Top scores: 9:3.8 140:2.0 28:1.9 350:1.9 42:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.325, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-3.672499
[ENCODER] After pos encoding: 640/640 non-zero, sum=28.387684
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 1.476 0.394 0.800 -0.076 1.361 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.361, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.361
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-4.084213
[DECODER] After pos encoding: 384/384 non-zero, sum=15.133860
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.716 0.671 1.913 -0.034 1.053 
[DEBUG] Output range: [-2.148, 4.309]
[DEBUG] Output sample values: -0.290 0.665 3.798 2.674 0.277 
[GEN] Step 2 - Best token: 42 (score: 2.2, target_len: 4) [Top scores: 42:2.2 827:1.8 302:1.7 4:1.7 388:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.325, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-3.672499
[ENCODER] After pos encoding: 640/640 non-zero, sum=28.387684
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 1.476 0.394 0.800 -0.076 1.361 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.660, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.660
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-7.472580
[DECODER] After pos encoding: 512/512 non-zero, sum=18.163549
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000000
[DEBUG] Decoder sample values: 0.699 0.677 1.912 -0.009 1.038 
[DEBUG] Output range: [-2.082, 4.367]
[DEBUG] Output sample values: -0.281 0.668 3.813 2.676 0.287 
ENG: <sos> how are you <eos>
ESP: <sos> se el tiene dos <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.939, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=10.625090
[ENCODER] After pos encoding: 512/512 non-zero, sum=36.261200
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: 1.486 0.395 0.804 -0.084 1.366 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.119, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.119
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-1.348960
[DECODER] After pos encoding: 128/128 non-zero, sum=5.051042
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000004
[DEBUG] Decoder sample values: 1.065 0.701 1.453 0.162 1.012 
[DEBUG] Output range: [-2.022, 3.781]
[DEBUG] Output sample values: -0.045 0.825 3.781 2.273 0.214 
[GEN] Step 0 - Best token: 9 (score: 3.3, target_len: 3) [Top scores: 9:3.3 17:2.4 42:2.1 28:1.9 239:1.8 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.939, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=10.625090
[ENCODER] After pos encoding: 512/512 non-zero, sum=36.261200
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: 1.486 0.395 0.804 -0.084 1.366 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.628, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.628
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-7.104583
[DECODER] After pos encoding: 256/256 non-zero, sum=5.701447
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000003
[DEBUG] Decoder sample values: 0.950 0.777 1.684 0.262 0.866 
[DEBUG] Output range: [-2.051, 3.936]
[DEBUG] Output sample values: -0.081 0.825 3.739 2.216 0.302 
[GEN] Step 1 - Best token: 17 (score: 3.5, target_len: 3) [Top scores: 17:3.5 42:2.5 8:2.1 4:2.0 902:1.8 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.939, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=10.625090
[ENCODER] After pos encoding: 512/512 non-zero, sum=36.261200
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: 1.486 0.395 0.804 -0.084 1.366 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.361, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.361
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-4.084221
[DECODER] After pos encoding: 384/384 non-zero, sum=15.133860
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000006
[DEBUG] Decoder sample values: 0.898 0.782 1.724 0.273 0.869 
[DEBUG] Output range: [-2.167, 4.131]
[DEBUG] Output sample values: -0.071 0.813 3.745 2.199 0.339 
[GEN] Step 2 - Best token: 794 (score: 1.9, target_len: 3) [Top scores: 794:1.9 42:1.8 4:1.7 504:1.7 8:1.6 ]
ENG: <sos> good morning <eos>
ESP: <sos> el se siendo <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.347, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.237611
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.873726
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.483 0.392 0.800 -0.090 1.365 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.119, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.119
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-1.348960
[DECODER] After pos encoding: 128/128 non-zero, sum=5.051042
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DEBUG] Decoder sample values: 1.064 0.698 1.449 0.158 1.013 
[DEBUG] Output range: [-2.020, 3.785]
[DEBUG] Output sample values: -0.042 0.828 3.785 2.277 0.213 
[GEN] Step 0 - Best token: 9 (score: 3.3, target_len: 3) [Top scores: 9:3.3 17:2.3 42:2.1 28:1.9 239:1.8 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.347, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.237611
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.873726
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.483 0.392 0.800 -0.090 1.365 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.628, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.628
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-7.104583
[DECODER] After pos encoding: 256/256 non-zero, sum=5.701447
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000002
[DEBUG] Decoder sample values: 1.026 0.679 1.470 0.134 0.972 
[DEBUG] Output range: [-2.005, 3.820]
[DEBUG] Output sample values: -0.038 0.855 3.800 2.272 0.237 
[GEN] Step 1 - Best token: 42 (score: 1.8, target_len: 3) [Top scores: 17:2.5 225:2.4 42:1.8 159:1.7 8:1.7 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.347, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=15.237611
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.873726
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.483 0.392 0.800 -0.090 1.365 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.927, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.927
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-10.492952
[DECODER] After pos encoding: 384/384 non-zero, sum=8.725123
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.998 0.684 1.483 0.157 0.960 
[DEBUG] Output range: [-2.197, 4.284]
[DEBUG] Output sample values: -0.030 0.854 3.818 2.280 0.249 
[GEN] Step 2 - Best token: 17 (score: 2.3, target_len: 3) [Top scores: 17:2.3 92:1.7 48:1.7 28:1.7 319:1.6 ]
ENG: <sos> thank you <eos>
ESP: <sos> el tiene se <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.955, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.116095
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.176273
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.480 0.405 0.797 -0.085 1.374 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=-0.119, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=-0.119
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=-1.348960
[DECODER] After pos encoding: 128/128 non-zero, sum=5.051042
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 1.060 0.709 1.448 0.162 1.020 
[DEBUG] Output range: [-2.022, 3.782]
[DEBUG] Output sample values: -0.040 0.825 3.782 2.278 0.213 
[GEN] Step 0 - Best token: 9 (score: 3.3, target_len: 4) [Top scores: 9:3.3 17:2.3 42:2.1 28:1.9 239:1.8 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.955, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.116095
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.176273
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.480 0.405 0.797 -0.085 1.374 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.628, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.628
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-7.104583
[DECODER] After pos encoding: 256/256 non-zero, sum=5.701447
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: 1.048 0.822 1.484 0.153 0.993 
[DEBUG] Output range: [-2.043, 4.158]
[DEBUG] Output sample values: -0.038 0.818 3.830 2.298 0.219 
[GEN] Step 1 - Best token: 17 (score: 2.3, target_len: 4) [Top scores: 17:2.3 69:2.1 42:2.0 463:1.7 388:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.955, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.116095
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.176273
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.480 0.405 0.797 -0.085 1.374 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.361, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.361
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-4.084221
[DECODER] After pos encoding: 384/384 non-zero, sum=15.133860
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: 0.875 0.889 1.577 0.190 1.071 
[DEBUG] Output range: [-2.012, 4.128]
[DEBUG] Output sample values: 0.044 0.747 3.784 2.277 0.247 
[GEN] Step 2 - Best token: 464 (score: 1.9, target_len: 4) [Top scores: 464:1.9 77:1.8 28:1.8 148:1.7 766:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.955, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.116095
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.176273
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 1.480 0.405 0.797 -0.085 1.374 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.450, range=[-0.106, 0.250]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-0.450
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-5.089121
[DECODER] After pos encoding: 512/512 non-zero, sum=20.547012
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 0.853 0.889 1.586 0.209 1.059 
[DEBUG] Output range: [-2.067, 4.249]
[DEBUG] Output sample values: 0.050 0.748 3.800 2.284 0.257 
ENG: <sos> i love you <eos>
ESP: <sos> el se cansado plan <eos>
---