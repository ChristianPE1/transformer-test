Se han truncado las últimas 5000 líneas del flujo de salida.
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 716492672.000
[ATTENTION] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=143298528.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=143298528.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000090
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=711075328.000, range=[-228854704.000, 2558926336.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=711075328.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=8045158912.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=8045158912.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 716492672.000
[ATTENTION] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=143298528.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=143298528.00000000
Epoca 493/500 - Loss: 6.7836
⚠️  Pérdida estancada por 386 épocas

Época 494/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000011
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=809788992.000, range=[-230309712.000, 2572597248.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=809788992.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9161681920.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=9161681920.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000067
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=794337920.000, range=[-231971072.000, 2591355904.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=794337920.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=8986858496.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=8986858496.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=924048192.000, range=[-233371200.000, 2605838080.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=924048192.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10454139904.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=10454139904.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000036
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=881875072.000, range=[-235032560.000, 2624596736.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=881875072.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=9977083904.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=9977083904.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000025
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=825942464.000, range=[-236607696.000, 2640889088.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=825942464.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=9344616448.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=9344616448.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000064
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=849729664.000, range=[-237438368.000, 2650268416.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=849729664.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9613321216.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=9613321216.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000054
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=965960256.000, range=[-237440928.000, 2666148096.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=965960256.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=10928615424.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=10928615424.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000092
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=755700160.000, range=[-239240432.000, 2688172032.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=755700160.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=8549917184.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=8549917184.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
Epoca 494/500 - Loss: 6.7836
⚠️  Pérdida estancada por 387 épocas

Época 495/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=860643968.000, range=[-240768192.000, 2702526464.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=860643968.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9737000960.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=9737000960.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000053
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=844055360.000, range=[-242512608.000, 2722223104.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=844055360.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9549550592.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=9549550592.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000025
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000060
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=981181184.000, range=[-243982736.000, 2737429248.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=981181184.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11101021184.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=11101021184.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000046
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=935928320.000, range=[-245727152.000, 2757125888.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=935928320.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=10588640256.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=10588640256.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000026
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=878339072.000, range=[-247381040.000, 2774232832.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=878339072.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=9937475584.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=9937475584.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=902753408.000, range=[-248253248.000, 2784081152.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=902753408.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10213365760.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10213365760.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000028
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1025120384.000, range=[-248255936.000, 2800754688.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1025120384.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=11597699072.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=11597699072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000068
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=802536576.000, range=[-250145408.000, 2823879680.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=802536576.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9079530496.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=9079530496.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
Epoca 495/500 - Loss: 6.7836
⚠️  Pérdida estancada por 388 épocas

Época 496/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000023
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=914053248.000, range=[-251749552.000, 2838951936.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=914053248.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10340981760.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=10340981760.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000015
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=896262528.000, range=[-253581200.000, 2859633408.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=896262528.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10140017664.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10140017664.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000061
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1041215616.000, range=[-255124832.000, 2875599872.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1041215616.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11779734528.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=11779734528.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000023
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=992672704.000, range=[-256956480.000, 2896281344.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=992672704.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11230810112.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=11230810112.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000049
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000049
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=933337600.000, range=[-258693072.000, 2914243584.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=933337600.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=10559722496.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=10559722496.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000042
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=958402304.000, range=[-259608896.000, 2924584192.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=958402304.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10843625472.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10843625472.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000027
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1087207552.000, range=[-259611712.000, 2942091520.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1087207552.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12300877824.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=12300877824.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000000
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=851693824.000, range=[-261595664.000, 2966372864.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=851693824.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9636092928.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=9636092928.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
Epoca 496/500 - Loss: 6.7836
⚠️  Pérdida estancada por 389 épocas

Época 497/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000047
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=970102656.000, range=[-263280016.000, 2982198528.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=970102656.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10975651840.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=10975651840.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000040
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=951052544.000, range=[-265203248.000, 3003913984.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=951052544.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10760051712.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10760051712.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000047
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1104193664.000, range=[-266824064.000, 3020678912.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1104193664.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=12492657664.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=12492657664.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000046
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1052323904.000, range=[-268747296.000, 3042394368.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1052323904.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11905703936.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=11905703936.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000075
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=991165952.000, range=[-270570720.000, 3061254912.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=991165952.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=11213042688.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=11213042688.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000084
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1016908032.000, range=[-271532320.000, 3072112640.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1016908032.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11505007616.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=11505007616.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1152453632.000, range=[-271535296.000, 3090495232.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1152453632.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13038737408.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=13038737408.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000091
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=903367168.000, range=[-273618432.000, 3115990528.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=903367168.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10220589056.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10220589056.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
Epoca 497/500 - Loss: 6.7836
⚠️  Pérdida estancada por 390 épocas

Época 498/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1028974400.000, range=[-275387008.000, 3132607488.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1028974400.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11641467904.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=11641467904.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000040
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1008640512.000, range=[-277406400.000, 3155408640.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1008640512.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11411183616.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=11411183616.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000062
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1170314880.000, range=[-279108256.000, 3173011712.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1170314880.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=13240900608.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=13240900608.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000010
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1114931328.000, range=[-281127648.000, 3195812864.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1114931328.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=12613798912.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=12613798912.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000033
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000074
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=1051871680.000, range=[-283042240.000, 3215616256.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=1051871680.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=11899508736.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=11899508736.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000022
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000021
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1078306432.000, range=[-284051936.000, 3227016960.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1078306432.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12199502848.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12199502848.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000040
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1220977280.000, range=[-284055040.000, 3246318848.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1220977280.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13813667840.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=13813667840.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000068
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=957564224.000, range=[-286242336.000, 3273089024.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=957564224.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10833653760.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10833653760.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
Epoca 498/500 - Loss: 6.7836
⚠️  Pérdida estancada por 391 épocas

Época 499/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000011
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1090771712.000, range=[-288099328.000, 3290536960.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1090771712.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=12341029888.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=12341029888.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000028
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1069073536.000, range=[-290219680.000, 3314478336.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1069073536.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12094916608.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12094916608.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000046
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1239769344.000, range=[-292006624.000, 3332961536.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1239769344.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14026952704.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=14026952704.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1180596352.000, range=[-294126976.000, 3356902912.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1180596352.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13357385728.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=13357385728.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000099
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=1115580032.000, range=[-296137280.000, 3377696512.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=1115580032.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=12620327936.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=12620327936.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000063
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1142755456.000, range=[-297197472.000, 3389667072.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1142755456.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12928883712.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12928883712.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000040
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1292861056.000, range=[-297200736.000, 3409934080.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1292861056.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=14627569664.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=14627569664.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000069
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1014535104.000, range=[-299497408.000, 3438042624.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1014535104.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11478045696.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=11478045696.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
Epoca 499/500 - Loss: 6.7836
⚠️  Pérdida estancada por 392 épocas

Época 500/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1155697792.000, range=[-301447264.000, 3456363008.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1155697792.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=13075156992.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=13075156992.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000014
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1132496000.000, range=[-303673632.000, 3481501440.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1132496000.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12812791808.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12812791808.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000061
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1312745216.000, range=[-305549920.000, 3500908800.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1312745216.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14851642368.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=14851642368.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1249619456.000, range=[-307776288.000, 3526047232.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1249619456.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=14137734144.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=14137734144.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000076
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=1182435456.000, range=[-309887136.000, 3547880448.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=1182435456.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=13377641472.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=13377641472.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000025
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000062
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1210425088.000, range=[-311000320.000, 3560449536.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1210425088.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13694745600.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=13694745600.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000012
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1368398720.000, range=[-311003744.000, 3581729792.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1368398720.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=15481899008.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=15481899008.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000092
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1074328704.000, range=[-313415232.000, 3611243776.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1074328704.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12154329088.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12154329088.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
Epoca 500/500 - Loss: 6.7836[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 628 (score: 3.0, target_len: 5) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1548330112.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1548330112.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17517604864.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17517604864.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 10 (score: 3.0, target_len: 5) [Top scores: 17:3.0 10:3.0 7:3.0 1:1.5 628:-1.0 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1527029376.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1527029376.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17276643328.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17276643328.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 17 (score: 3.0, target_len: 5) [Top scores: 17:3.0 7:3.0 1:1.5 628:0.0 10:-1.0 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1503308544.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1503308544.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=17008376832.000000
[DECODER] After pos encoding: 512/512 non-zero, sum=17008376832.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1434722560.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1434722560.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=16232437760.000000
[DECODER] After pos encoding: 640/640 non-zero, sum=16232437760.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/640 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/640 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
 | Test: <sos> dicen en se que dicen <eos>
⚠️  Pérdida estancada por 393 épocas

=== RESUMEN DE ENTRENAMIENTO ===
Pérdida inicial: 7.6365
Mejor pérdida: 4.2839
Mejora absoluta: 3.3527
Mejora porcentual: 43.9033%
¡Entrenamiento completado! Pérdida guardada en training_loss.txt

=== Pruebas de Traducción ===
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.657, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=7.433064
[ENCODER] After pos encoding: 384/384 non-zero, sum=26.651138
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000013
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 628 (score: 3.0, target_len: 2) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.657, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=7.433064
[ENCODER] After pos encoding: 384/384 non-zero, sum=26.651138
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000013
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1548330112.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1548330112.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17517604864.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17517604864.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 10 (score: 3.0, target_len: 2) [Top scores: 17:3.0 10:3.0 7:3.0 1:1.5 628:-1.0 ]
ENG: <sos> hello <eos>
ESP: <sos> dicen en <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.395, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.096992
[ENCODER] After pos encoding: 640/640 non-zero, sum=59.157219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 17 (score: 3.0, target_len: 4) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.395, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.096992
[ENCODER] After pos encoding: 640/640 non-zero, sum=59.157219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1571922432.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1571922432.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17784543232.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17784543232.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 10 (score: 3.0, target_len: 4) [Top scores: 628:3.0 10:3.0 7:3.0 1:1.5 17:-1.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.395, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.096992
[ENCODER] After pos encoding: 640/640 non-zero, sum=59.157219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1550621696.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1550621696.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17543581696.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17543581696.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 628 (score: 3.0, target_len: 4) [Top scores: 628:3.0 7:3.0 1:1.5 17:0.0 10:-1.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.395, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.096992
[ENCODER] After pos encoding: 640/640 non-zero, sum=59.157219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1503308544.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1503308544.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=17008384000.000000
[DECODER] After pos encoding: 512/512 non-zero, sum=17008384000.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
ENG: <sos> how are you <eos>
ESP: <sos> se en dicen que <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.118, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-1.336728
[ENCODER] After pos encoding: 512/512 non-zero, sum=24.299410
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 628 (score: 3.0, target_len: 3) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.118, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-1.336728
[ENCODER] After pos encoding: 512/512 non-zero, sum=24.299410
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1548330112.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1548330112.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17517604864.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17517604864.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 17 (score: 3.0, target_len: 3) [Top scores: 17:3.0 10:3.0 7:3.0 1:1.5 628:-1.0 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.118, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-1.336728
[ENCODER] After pos encoding: 512/512 non-zero, sum=24.299410
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1524609280.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1524609280.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17249409024.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17249409024.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 10 (score: 3.0, target_len: 3) [Top scores: 10:3.0 7:3.0 1:1.5 628:0.0 17:-1.0 ]
ENG: <sos> good morning <eos>
ESP: <sos> dicen se en <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.273, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=14.401515
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.037640
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 10 (score: 3.0, target_len: 3) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.273, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=14.401515
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.037640
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1574342528.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1574342528.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17811777536.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17811777536.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 17 (score: 3.0, target_len: 3) [Top scores: 628:3.0 17:3.0 7:3.0 1:1.5 10:-1.0 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.273, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=14.401515
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.037640
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1550621696.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1550621696.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17543581696.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17543581696.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 628 (score: 3.0, target_len: 3) [Top scores: 628:3.0 7:3.0 1:1.5 10:0.0 17:-1.0 ]
ENG: <sos> thank you <eos>
ESP: <sos> en se dicen <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.534, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=6.043063
[ENCODER] After pos encoding: 640/640 non-zero, sum=38.103271
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 17 (score: 3.0, target_len: 4) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.534, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=6.043063
[ENCODER] After pos encoding: 640/640 non-zero, sum=38.103271
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1571922432.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1571922432.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17784543232.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17784543232.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 10 (score: 3.0, target_len: 4) [Top scores: 628:3.0 10:3.0 7:3.0 1:1.5 17:-1.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.534, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=6.043063
[ENCODER] After pos encoding: 640/640 non-zero, sum=38.103271
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1550621696.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1550621696.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17543581696.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17543581696.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 628 (score: 3.0, target_len: 4) [Top scores: 628:3.0 7:3.0 1:1.5 17:0.0 10:-1.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.534, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=6.043063
[ENCODER] After pos encoding: 640/640 non-zero, sum=38.103271
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1503308544.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1503308544.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=17008384000.000000
[DECODER] After pos encoding: 512/512 non-zero, sum=17008384000.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
ENG: <sos> i love you <eos>
ESP: <sos> se en dicen que <eos>
---