Se han truncado las últimas 5000 líneas del flujo de salida.
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 716492672.000
[ATTENTION] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=143298528.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=143298528.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000090
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=711075328.000, range=[-228854704.000, 2558926336.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=711075328.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=8045158912.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=8045158912.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 716492672.000
[ATTENTION] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] Weights updated with lr=143298528.000
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=143298528.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=143298528.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=143298528.00000000
Epoca 493/500 - Loss: 6.7836
⚠️  Pérdida estancada por 386 épocas

Época 494/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000011
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=809788992.000, range=[-230309712.000, 2572597248.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=809788992.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9161681920.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=9161681920.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000067
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=794337920.000, range=[-231971072.000, 2591355904.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=794337920.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=8986858496.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=8986858496.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=924048192.000, range=[-233371200.000, 2605838080.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=924048192.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10454139904.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=10454139904.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000036
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=881875072.000, range=[-235032560.000, 2624596736.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=881875072.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=9977083904.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=9977083904.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000025
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=825942464.000, range=[-236607696.000, 2640889088.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=825942464.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=9344616448.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=9344616448.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000064
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=849729664.000, range=[-237438368.000, 2650268416.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=849729664.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9613321216.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=9613321216.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000054
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=965960256.000, range=[-237440928.000, 2666148096.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=965960256.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=10928615424.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=10928615424.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000092
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=755700160.000, range=[-239240432.000, 2688172032.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=755700160.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=8549917184.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=8549917184.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 752317184.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] Weights updated with lr=150463440.000
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=150463440.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=150463440.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=150463440.00000000
Epoca 494/500 - Loss: 6.7836
⚠️  Pérdida estancada por 387 épocas

Época 495/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=860643968.000, range=[-240768192.000, 2702526464.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=860643968.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=9737000960.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=9737000960.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000053
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=844055360.000, range=[-242512608.000, 2722223104.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=844055360.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9549550592.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=9549550592.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000025
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000060
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=981181184.000, range=[-243982736.000, 2737429248.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=981181184.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11101021184.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=11101021184.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000046
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=935928320.000, range=[-245727152.000, 2757125888.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=935928320.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=10588640256.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=10588640256.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000026
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=878339072.000, range=[-247381040.000, 2774232832.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=878339072.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=9937475584.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=9937475584.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=902753408.000, range=[-248253248.000, 2784081152.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=902753408.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10213365760.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10213365760.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000028
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1025120384.000, range=[-248255936.000, 2800754688.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1025120384.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=11597699072.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=11597699072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000068
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=802536576.000, range=[-250145408.000, 2823879680.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=802536576.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9079530496.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=9079530496.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 789933056.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] Weights updated with lr=157986608.000
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=157986608.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=157986608.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=157986608.00000000
Epoca 495/500 - Loss: 6.7836
⚠️  Pérdida estancada por 388 épocas

Época 496/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000023
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=914053248.000, range=[-251749552.000, 2838951936.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=914053248.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10340981760.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=10340981760.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000015
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=896262528.000, range=[-253581200.000, 2859633408.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=896262528.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10140017664.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10140017664.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000061
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1041215616.000, range=[-255124832.000, 2875599872.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1041215616.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11779734528.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=11779734528.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000023
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=992672704.000, range=[-256956480.000, 2896281344.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=992672704.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11230810112.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=11230810112.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000049
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000049
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=933337600.000, range=[-258693072.000, 2914243584.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=933337600.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=10559722496.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=10559722496.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000042
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=958402304.000, range=[-259608896.000, 2924584192.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=958402304.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10843625472.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10843625472.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000027
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1087207552.000, range=[-259611712.000, 2942091520.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1087207552.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12300877824.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=12300877824.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000000
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=851693824.000, range=[-261595664.000, 2966372864.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=851693824.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=9636092928.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=9636092928.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 829429696.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] Weights updated with lr=165885936.000
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=165885936.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=165885936.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=165885936.00000000
Epoca 496/500 - Loss: 6.7836
⚠️  Pérdida estancada por 389 épocas

Época 497/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000047
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=970102656.000, range=[-263280016.000, 2982198528.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=970102656.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=10975651840.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=10975651840.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000040
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=951052544.000, range=[-265203248.000, 3003913984.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=951052544.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10760051712.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10760051712.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000047
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1104193664.000, range=[-266824064.000, 3020678912.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1104193664.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=12492657664.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=12492657664.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000046
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1052323904.000, range=[-268747296.000, 3042394368.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1052323904.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11905703936.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=11905703936.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000075
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=991165952.000, range=[-270570720.000, 3061254912.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=991165952.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=11213042688.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=11213042688.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000084
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1016908032.000, range=[-271532320.000, 3072112640.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1016908032.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11505007616.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=11505007616.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1152453632.000, range=[-271535296.000, 3090495232.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1152453632.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13038737408.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=13038737408.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000016
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000091
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=903367168.000, range=[-273618432.000, 3115990528.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=903367168.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10220589056.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10220589056.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 870901120.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] Weights updated with lr=174180224.000
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=174180224.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=174180224.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=174180224.00000000
Epoca 497/500 - Loss: 6.7836
⚠️  Pérdida estancada por 390 épocas

Época 498/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1028974400.000, range=[-275387008.000, 3132607488.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1028974400.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=11641467904.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=11641467904.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000040
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1008640512.000, range=[-277406400.000, 3155408640.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1008640512.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11411183616.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=11411183616.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000062
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1170314880.000, range=[-279108256.000, 3173011712.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1170314880.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=13240900608.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=13240900608.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000010
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1114931328.000, range=[-281127648.000, 3195812864.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1114931328.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=12613798912.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=12613798912.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000033
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000074
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=1051871680.000, range=[-283042240.000, 3215616256.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=1051871680.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=11899508736.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=11899508736.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000022
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000021
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1078306432.000, range=[-284051936.000, 3227016960.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1078306432.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12199502848.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12199502848.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000040
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1220977280.000, range=[-284055040.000, 3246318848.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1220977280.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=13813667840.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=13813667840.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000068
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=957564224.000, range=[-286242336.000, 3273089024.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=957564224.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=10833653760.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=10833653760.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 914446144.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] Weights updated with lr=182889232.000
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=182889232.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=182889232.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=182889232.00000000
Epoca 498/500 - Loss: 6.7836
⚠️  Pérdida estancada por 391 épocas

Época 499/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000011
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1090771712.000, range=[-288099328.000, 3290536960.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1090771712.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=12341029888.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=12341029888.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000028
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1069073536.000, range=[-290219680.000, 3314478336.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1069073536.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12094916608.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12094916608.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000046
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1239769344.000, range=[-292006624.000, 3332961536.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1239769344.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14026952704.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=14026952704.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1180596352.000, range=[-294126976.000, 3356902912.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1180596352.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=13357385728.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=13357385728.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=-0.000099
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=1115580032.000, range=[-296137280.000, 3377696512.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=1115580032.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=12620327936.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=12620327936.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000063
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1142755456.000, range=[-297197472.000, 3389667072.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1142755456.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12928883712.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12928883712.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000040
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1292861056.000, range=[-297200736.000, 3409934080.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1292861056.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=14627569664.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=14627569664.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000069
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1014535104.000, range=[-299497408.000, 3438042624.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1014535104.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11478045696.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=11478045696.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 960168384.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] Weights updated with lr=192033680.000
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=192033680.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=192033680.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=192033680.00000000
Epoca 499/500 - Loss: 6.7836
⚠️  Pérdida estancada por 392 épocas

Época 500/500
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1155697792.000, range=[-301447264.000, 3456363008.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1155697792.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=13075156992.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=13075156992.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.812
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1.250, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14.139421
[ENCODER] After pos encoding: 896/896 non-zero, sum=59.065735
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000014
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1132496000.000, range=[-303673632.000, 3481501440.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1132496000.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12812791808.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12812791808.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.825
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.017, range=[-0.096, 0.009]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=0.749, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=8.477091
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=59.845463
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000061
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=1312745216.000, range=[-305549920.000, 3500908800.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=1312745216.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=14851642368.000000
[DECODER] After pos encoding: 896/896 non-zero, sum=14851642368.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/896 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.856
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 7 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.037, range=[-0.125, 0.011]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1.087, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=12.298789
[ENCODER] After pos encoding: 768/768 non-zero, sum=50.789024
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000034
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1249619456.000, range=[-307776288.000, 3526047232.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1249619456.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=14137734144.000000
[DECODER] After pos encoding: 1024/1024 non-zero, sum=14137734144.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1024 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.857
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 8 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.033, range=[-0.108, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=13, d_model=128
[EMBEDDING] 1664/1664 non-zero, sum=0.541, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1600/1664 non-zero, sum=83.668442
[ENCODER] SCALED EMBEDS before add: 1664/1664 non-zero, sum=6.122672
[ENCODER] After pos encoding: 1664/1664 non-zero, sum=89.791046
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 0 output: 1664/1664 non-zero, sum=-0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1664/1664 non-zero
[ENCODER_LAYER] After self-attention: 1664/1664 non-zero
[ENCODER_LAYER] After norm1: 1664/1664 non-zero
[ENCODER_LAYER] After feedforward: 1664/1664 non-zero
[ENCODER_LAYER] Final output: 1664/1664 non-zero
[ENCODER] Layer 1 output: 1664/1664 non-zero, sum=0.000076
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=1182435456.000, range=[-309887136.000, 3547880448.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=1182435456.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=13377641472.000000
[DECODER] After pos encoding: 1792/1792 non-zero, sum=13377641472.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1792 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.878
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 14 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.002, range=[-0.062, 0.006]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=2.357, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=26.663883
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=97.394272
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000025
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000062
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1210425088.000, range=[-311000320.000, 3560449536.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1210425088.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=13694745600.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=13694745600.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 -3.000 -3.000 3.000 
[LOSS] Gradient sum: 1.886
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.106, 0.007]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-2.228, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-25.208996
[ENCODER] After pos encoding: 896/896 non-zero, sum=19.717331
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000012
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=1368398720.000, range=[-311003744.000, 3581729792.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=1368398720.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=15481899008.000000
[DECODER] After pos encoding: 768/768 non-zero, sum=15481899008.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/768 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 3.000 
[LOSS] Gradient sum: 1.852
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 6 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.043, range=[-0.146, 0.012]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=2.070, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=23.415342
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=100.611748
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000092
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=1074328704.000, range=[-313415232.000, 3611243776.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=1074328704.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=12154329088.000000
[DECODER] After pos encoding: 1152/1152 non-zero, sum=12154329088.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 -3.000 3.000 3.000 -3.000 
[LOSS] Gradient sum: 1.859
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 1008176768.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] Weights updated with lr=201635360.000
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[ATTENTION] Weights updated with lr=201635360.000
[FEEDFORWARD] ERROR: NaN/Inf detected in W1 weights or gradients! Reinitializing...
[EMBEDDING] Updating weights for 9 tokens with lr=201635360.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.095, 0.010]
[EMBEDDING] Sample weights after update: -0.03408219 0.04277521 0.08405980 0.09888393 -0.00916866 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=201635360.00000000
Epoca 500/500 - Loss: 6.7836[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 628 (score: 3.0, target_len: 5) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1548330112.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1548330112.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17517604864.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17517604864.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 10 (score: 3.0, target_len: 5) [Top scores: 17:3.0 10:3.0 7:3.0 1:1.5 628:-1.0 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1527029376.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1527029376.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17276643328.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17276643328.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 17 (score: 3.0, target_len: 5) [Top scores: 17:3.0 7:3.0 1:1.5 628:0.0 10:-1.0 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1503308544.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1503308544.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=17008376832.000000
[DECODER] After pos encoding: 512/512 non-zero, sum=17008376832.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-1.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-12.746957
[ENCODER] After pos encoding: 768/768 non-zero, sum=25.743296
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000024
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1434722560.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1434722560.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=16232437760.000000
[DECODER] After pos encoding: 640/640 non-zero, sum=16232437760.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/640 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/640 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
 | Test: <sos> dicen en se que dicen <eos>
⚠️  Pérdida estancada por 393 épocas

=== RESUMEN DE ENTRENAMIENTO ===
Pérdida inicial: 7.6365
Mejor pérdida: 4.2839
Mejora absoluta: 3.3527
Mejora porcentual: 43.9033%
¡Entrenamiento completado! Pérdida guardada en training_loss.txt

=== Pruebas de Traducción ===
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.657, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=7.433064
[ENCODER] After pos encoding: 384/384 non-zero, sum=26.651138
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000013
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Proces

Streaming output truncated to the last 5000 lines.
[DEBUG] Encoder sample values: -0.033 1.515 0.096 -1.245 0.647 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.561, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.561
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.284641
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.555161
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -1.357 -0.178 1.243 0.245 -0.851 
[DEBUG] Output range: [-2.412, 2.134]
[DEBUG] Output sample values: 0.365 1.205 -0.157 -0.266 0.807 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 10 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.034, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.612276
[ENCODER] After pos encoding: 768/768 non-zero, sum=64.102531
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.025 1.513 0.101 -1.242 0.649 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.536, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.536
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.375666
[DECODER] After pos encoding: 640/640 non-zero, sum=49.435886
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.367 1.460 0.392 -1.123 0.499 
[DEBUG] Output range: [-2.167, 2.107]
[DEBUG] Output sample values: 0.273 1.691 -0.232 0.319 0.199 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 5 tokens with lr=0.000
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.128, range=[-0.190, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.144, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=46.886948
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=98.255203
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000015
[DEBUG] Encoder sample values: -0.023 1.512 0.105 -1.230 0.657 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.823, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.823
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=54.567417
[DECODER] After pos encoding: 896/896 non-zero, sum=99.493767
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000012
[DEBUG] Decoder sample values: -0.366 1.453 0.394 -1.118 0.501 
[DEBUG] Output range: [-2.445, 2.160]
[DEBUG] Output sample values: 0.270 1.692 -0.230 0.320 0.192 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 7 tokens with lr=0.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.136, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.754, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=42.477318
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=106.747765
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: -0.023 1.522 0.103 -1.242 0.660 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.318, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=48.846977
[DECODER] After pos encoding: 1152/1152 non-zero, sum=106.663338
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000008
[DEBUG] Decoder sample values: -0.366 1.463 0.395 -1.126 0.508 
[DEBUG] Output range: [-2.365, 2.149]
[DEBUG] Output sample values: 0.269 1.692 -0.232 0.316 0.198 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
Epoca 143/150 - Loss: 7.6087 | LR: 2.635e-04

Época 144/150
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.125, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.125
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=35.360683
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.729088
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -0.372 1.468 0.390 -1.122 0.521 
[DEBUG] Output range: [-2.191, 2.147]
[DEBUG] Output sample values: 0.276 1.687 -0.235 0.316 0.200 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-20.048616
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=44.221790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.037 1.530 0.105 -1.247 0.666 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.814, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.814
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-20.526728
[DECODER] After pos encoding: 1152/1152 non-zero, sum=37.289700
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.376 1.469 0.400 -1.123 0.513 
[DEBUG] Output range: [-2.158, 2.210]
[DEBUG] Output sample values: 0.275 1.686 -0.234 0.326 0.195 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.190, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=13.466152
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=84.196617
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.026 1.501 0.108 -1.243 0.658 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.035, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.035
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11.714162
[DECODER] After pos encoding: 1024/1024 non-zero, sum=63.082577
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000013
[DEBUG] Decoder sample values: -0.367 1.451 0.398 -1.126 0.503 
[DEBUG] Output range: [-2.478, 2.256]
[DEBUG] Output sample values: 0.268 1.686 -0.229 0.317 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.858, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.703296
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.433815
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000017
[DEBUG] Encoder sample values: -0.031 1.522 0.104 -1.247 0.661 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=6.163, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=6.163
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=69.721153
[DECODER] After pos encoding: 1152/1152 non-zero, sum=127.537674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.373 1.465 0.396 -1.125 0.511 
[DEBUG] Output range: [-2.175, 2.477]
[DEBUG] Output sample values: 0.275 1.682 -0.230 0.316 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.483, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-5.462055
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=45.906338
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.033 1.515 0.096 -1.245 0.647 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.561, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.561
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.286915
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.557426
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000008
[DEBUG] Decoder sample values: -1.208 0.129 1.403 -0.057 -0.576 
[DEBUG] Output range: [-2.446, 2.373]
[DEBUG] Output sample values: 0.390 1.414 -0.243 -0.192 0.713 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 10 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.034, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.612276
[ENCODER] After pos encoding: 768/768 non-zero, sum=64.102531
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.025 1.513 0.101 -1.242 0.649 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.536, range=[-0.105, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.536
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.377993
[DECODER] After pos encoding: 640/640 non-zero, sum=49.438183
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.367 1.460 0.393 -1.123 0.498 
[DEBUG] Output range: [-2.167, 2.107]
[DEBUG] Output sample values: 0.273 1.692 -0.231 0.321 0.199 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 5 tokens with lr=0.000
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.128, range=[-0.190, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.144, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=46.886948
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=98.255203
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.023 1.512 0.105 -1.230 0.657 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.823, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.823
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=54.569649
[DECODER] After pos encoding: 896/896 non-zero, sum=99.495949
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.366 1.453 0.395 -1.118 0.501 
[DEBUG] Output range: [-2.445, 2.161]
[DEBUG] Output sample values: 0.270 1.693 -0.228 0.321 0.193 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 7 tokens with lr=0.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.136, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.754, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=42.477318
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=106.747765
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000010
[DEBUG] Encoder sample values: -0.023 1.522 0.103 -1.242 0.660 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.318, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=48.849182
[DECODER] After pos encoding: 1152/1152 non-zero, sum=106.665588
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.366 1.463 0.396 -1.125 0.508 
[DEBUG] Output range: [-2.365, 2.149]
[DEBUG] Output sample values: 0.269 1.693 -0.230 0.317 0.198 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
Epoca 144/150 - Loss: 7.5939 | LR: 2.635e-04

Época 145/150
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000016
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.126, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.126
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=35.362881
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.731300
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.372 1.468 0.391 -1.122 0.521 
[DEBUG] Output range: [-2.191, 2.147]
[DEBUG] Output sample values: 0.276 1.688 -0.233 0.317 0.200 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-20.048616
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=44.221790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.037 1.530 0.105 -1.247 0.666 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.814, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.814
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-20.524361
[DECODER] After pos encoding: 1152/1152 non-zero, sum=37.292076
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -0.376 1.469 0.401 -1.123 0.513 
[DEBUG] Output range: [-2.158, 2.210]
[DEBUG] Output sample values: 0.275 1.687 -0.232 0.327 0.195 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.190, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=13.466152
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=84.196617
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.026 1.501 0.108 -1.243 0.658 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.036, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.036
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11.716534
[DECODER] After pos encoding: 1024/1024 non-zero, sum=63.084942
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000017
[DEBUG] Decoder sample values: -0.367 1.451 0.399 -1.126 0.503 
[DEBUG] Output range: [-2.478, 2.256]
[DEBUG] Output sample values: 0.268 1.688 -0.228 0.318 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.858, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.703296
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.433815
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.031 1.522 0.104 -1.247 0.661 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=6.163, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=6.163
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=69.723396
[DECODER] After pos encoding: 1152/1152 non-zero, sum=127.539909
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000011
[DEBUG] Decoder sample values: -0.373 1.465 0.397 -1.125 0.511 
[DEBUG] Output range: [-2.175, 2.477]
[DEBUG] Output sample values: 0.275 1.684 -0.228 0.318 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.483, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-5.462055
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=45.906338
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -0.033 1.515 0.096 -1.245 0.647 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.561, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.561
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.289093
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.559570
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -1.357 -0.178 1.245 0.245 -0.851 
[DEBUG] Output range: [-2.412, 2.134]
[DEBUG] Output sample values: 0.365 1.207 -0.154 -0.263 0.808 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 10 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.034, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.612276
[ENCODER] After pos encoding: 768/768 non-zero, sum=64.102531
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.025 1.513 0.101 -1.242 0.649 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.536, range=[-0.105, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.536
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.380318
[DECODER] After pos encoding: 640/640 non-zero, sum=49.440517
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.367 1.460 0.394 -1.123 0.498 
[DEBUG] Output range: [-2.167, 2.107]
[DEBUG] Output sample values: 0.273 1.693 -0.229 0.322 0.199 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 5 tokens with lr=0.000
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.128, range=[-0.190, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.144, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=46.886948
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=98.255203
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[DEBUG] Encoder sample values: -0.023 1.512 0.105 -1.230 0.657 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.824, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.824
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=54.571880
[DECODER] After pos encoding: 896/896 non-zero, sum=99.498283
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -0.366 1.453 0.396 -1.118 0.501 
[DEBUG] Output range: [-2.445, 2.161]
[DEBUG] Output sample values: 0.270 1.694 -0.227 0.323 0.193 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 7 tokens with lr=0.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.136, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.754, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=42.477318
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=106.747765
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000011
[DEBUG] Encoder sample values: -0.023 1.522 0.103 -1.242 0.660 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.318, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=48.851418
[DECODER] After pos encoding: 1152/1152 non-zero, sum=106.667839
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -0.366 1.463 0.397 -1.125 0.508 
[DEBUG] Output range: [-2.365, 2.149]
[DEBUG] Output sample values: 0.269 1.694 -0.229 0.319 0.198 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
Epoca 145/150 - Loss: 7.6075 | LR: 2.635e-04

Época 146/150
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000010
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.126, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.126
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=35.365139
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.733513
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000010
[DEBUG] Decoder sample values: -0.372 1.468 0.392 -1.122 0.521 
[DEBUG] Output range: [-2.191, 2.147]
[DEBUG] Output sample values: 0.276 1.689 -0.232 0.318 0.200 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-20.048616
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=44.221790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000022
[DEBUG] Encoder sample values: -0.037 1.530 0.105 -1.247 0.666 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.814, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.814
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-20.521992
[DECODER] After pos encoding: 1152/1152 non-zero, sum=37.294437
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.376 1.469 0.402 -1.123 0.513 
[DEBUG] Output range: [-2.158, 2.210]
[DEBUG] Output sample values: 0.275 1.688 -0.231 0.328 0.195 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.190, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=13.466152
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=84.196617
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.026 1.501 0.108 -1.243 0.658 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.036, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.036
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11.718906
[DECODER] After pos encoding: 1024/1024 non-zero, sum=63.087322
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -0.367 1.451 0.400 -1.125 0.503 
[DEBUG] Output range: [-2.478, 2.256]
[DEBUG] Output sample values: 0.268 1.689 -0.227 0.320 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.858, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.703296
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.433815
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: -0.031 1.522 0.104 -1.247 0.661 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=6.163, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=6.163
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=69.725655
[DECODER] After pos encoding: 1152/1152 non-zero, sum=127.542175
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -0.373 1.465 0.398 -1.124 0.511 
[DEBUG] Output range: [-2.175, 2.477]
[DEBUG] Output sample values: 0.275 1.685 -0.227 0.319 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.483, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-5.462055
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=45.906338
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.033 1.515 0.096 -1.245 0.647 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.561, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.561
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.291317
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.561752
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -1.357 -0.178 1.246 0.245 -0.851 
[DEBUG] Output range: [-2.412, 2.134]
[DEBUG] Output sample values: 0.364 1.208 -0.152 -0.262 0.808 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 10 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.034, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.612276
[ENCODER] After pos encoding: 768/768 non-zero, sum=64.102531
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: -0.025 1.513 0.101 -1.242 0.649 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.536, range=[-0.105, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.536
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.382622
[DECODER] After pos encoding: 640/640 non-zero, sum=49.442825
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -0.367 1.460 0.395 -1.122 0.498 
[DEBUG] Output range: [-2.167, 2.107]
[DEBUG] Output sample values: 0.273 1.694 -0.228 0.323 0.200 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 5 tokens with lr=0.000
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.128, range=[-0.190, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.144, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=46.886948
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=98.255203
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000003
[DEBUG] Encoder sample values: -0.023 1.512 0.105 -1.230 0.657 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.824, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.824
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=54.574142
[DECODER] After pos encoding: 896/896 non-zero, sum=99.500511
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -0.366 1.453 0.397 -1.118 0.501 
[DEBUG] Output range: [-2.445, 2.162]
[DEBUG] Output sample values: 0.270 1.695 -0.226 0.324 0.193 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 7 tokens with lr=0.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.136, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.754, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=42.477318
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=106.747765
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.023 1.522 0.103 -1.242 0.660 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.318, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=48.853600
[DECODER] After pos encoding: 1152/1152 non-zero, sum=106.670074
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.366 1.463 0.398 -1.125 0.508 
[DEBUG] Output range: [-2.365, 2.149]
[DEBUG] Output sample values: 0.269 1.695 -0.228 0.320 0.198 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
Epoca 146/150 - Loss: 7.6069 | LR: 2.635e-04

Época 147/150
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.126, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.126
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=35.367355
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.735725
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[DEBUG] Decoder sample values: -0.372 1.468 0.393 -1.122 0.520 
[DEBUG] Output range: [-2.191, 2.147]
[DEBUG] Output sample values: 0.276 1.690 -0.231 0.320 0.200 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-20.048616
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=44.221790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.037 1.530 0.105 -1.247 0.666 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.814, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.814
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-20.519613
[DECODER] After pos encoding: 1152/1152 non-zero, sum=37.296841
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.376 1.469 0.402 -1.123 0.513 
[DEBUG] Output range: [-2.158, 2.210]
[DEBUG] Output sample values: 0.275 1.689 -0.230 0.330 0.196 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.190, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=13.466152
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=84.196617
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000016
[DEBUG] Encoder sample values: -0.026 1.501 0.108 -1.243 0.658 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.036, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.036
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11.721298
[DECODER] After pos encoding: 1024/1024 non-zero, sum=63.089684
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.367 1.451 0.401 -1.125 0.503 
[DEBUG] Output range: [-2.478, 2.256]
[DEBUG] Output sample values: 0.268 1.690 -0.225 0.321 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.858, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.703296
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.433815
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000022
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.031 1.522 0.104 -1.247 0.661 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=6.163, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=6.163
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=69.727890
[DECODER] After pos encoding: 1152/1152 non-zero, sum=127.544411
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000012
[DEBUG] Decoder sample values: -0.373 1.465 0.399 -1.124 0.511 
[DEBUG] Output range: [-2.175, 2.477]
[DEBUG] Output sample values: 0.275 1.686 -0.225 0.320 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.483, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-5.462055
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=45.906338
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: -0.033 1.515 0.096 -1.245 0.647 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.561, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.561
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.293495
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.564026
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -1.357 -0.178 1.247 0.245 -0.851 
[DEBUG] Output range: [-2.412, 2.134]
[DEBUG] Output sample values: 0.364 1.209 -0.151 -0.261 0.808 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 10 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.034, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.612276
[ENCODER] After pos encoding: 768/768 non-zero, sum=64.102531
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.025 1.513 0.101 -1.242 0.649 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.537, range=[-0.105, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.537
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.384945
[DECODER] After pos encoding: 640/640 non-zero, sum=49.445198
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.367 1.460 0.396 -1.122 0.498 
[DEBUG] Output range: [-2.167, 2.107]
[DEBUG] Output sample values: 0.273 1.695 -0.227 0.325 0.200 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 5 tokens with lr=0.000
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.128, range=[-0.190, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.144, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=46.886948
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=98.255203
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000000
[DEBUG] Encoder sample values: -0.023 1.512 0.105 -1.230 0.657 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.824, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.824
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=54.576416
[DECODER] After pos encoding: 896/896 non-zero, sum=99.502754
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.366 1.453 0.398 -1.118 0.501 
[DEBUG] Output range: [-2.445, 2.164]
[DEBUG] Output sample values: 0.270 1.696 -0.224 0.325 0.193 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 7 tokens with lr=0.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.136, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.754, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=42.477318
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=106.747765
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.023 1.522 0.103 -1.242 0.660 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.318, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=48.855835
[DECODER] After pos encoding: 1152/1152 non-zero, sum=106.672287
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000013
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.366 1.463 0.399 -1.125 0.508 
[DEBUG] Output range: [-2.365, 2.149]
[DEBUG] Output sample values: 0.269 1.697 -0.226 0.321 0.198 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
Epoca 147/150 - Loss: 7.6063 | LR: 2.635e-04

Época 148/150
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.126, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.126
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=35.369587
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.738045
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.372 1.468 0.394 -1.122 0.520 
[DEBUG] Output range: [-2.191, 2.147]
[DEBUG] Output sample values: 0.276 1.692 -0.229 0.321 0.200 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-20.048616
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=44.221790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: -0.037 1.530 0.105 -1.247 0.666 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.813, range=[-0.106, 0.107]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.813
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-20.517252
[DECODER] After pos encoding: 1152/1152 non-zero, sum=37.299171
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -0.376 1.469 0.403 -1.123 0.513 
[DEBUG] Output range: [-2.158, 2.210]
[DEBUG] Output sample values: 0.275 1.690 -0.228 0.331 0.196 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.190, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=13.466152
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=84.196617
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: -0.026 1.501 0.108 -1.243 0.658 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.036, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.036
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11.723661
[DECODER] After pos encoding: 1024/1024 non-zero, sum=63.092068
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -0.367 1.451 0.402 -1.125 0.503 
[DEBUG] Output range: [-2.478, 2.256]
[DEBUG] Output sample values: 0.268 1.691 -0.224 0.322 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.858, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.703296
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.433815
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000039
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.031 1.522 0.104 -1.247 0.661 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=6.163, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=6.163
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=69.730110
[DECODER] After pos encoding: 1152/1152 non-zero, sum=127.546585
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -0.373 1.465 0.400 -1.124 0.511 
[DEBUG] Output range: [-2.175, 2.477]
[DEBUG] Output sample values: 0.275 1.687 -0.224 0.322 0.194 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.483, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-5.462055
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=45.906338
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.033 1.515 0.096 -1.245 0.647 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.562, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.562
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.295761
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.566185
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -1.357 -0.178 1.249 0.245 -0.851 
[DEBUG] Output range: [-2.412, 2.134]
[DEBUG] Output sample values: 0.364 1.210 -0.150 -0.260 0.808 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 10 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.034, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.612276
[ENCODER] After pos encoding: 768/768 non-zero, sum=64.102531
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.025 1.513 0.101 -1.242 0.649 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.537, range=[-0.105, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.537
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.387270
[DECODER] After pos encoding: 640/640 non-zero, sum=49.447517
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.367 1.460 0.397 -1.122 0.498 
[DEBUG] Output range: [-2.167, 2.107]
[DEBUG] Output sample values: 0.273 1.696 -0.225 0.326 0.200 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 5 tokens with lr=0.000
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.128, range=[-0.190, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.144, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=46.886948
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=98.255203
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000016
[DEBUG] Encoder sample values: -0.023 1.512 0.105 -1.230 0.657 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.824, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.824
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=54.578682
[DECODER] After pos encoding: 896/896 non-zero, sum=99.505119
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.366 1.453 0.399 -1.118 0.501 
[DEBUG] Output range: [-2.445, 2.164]
[DEBUG] Output sample values: 0.270 1.697 -0.222 0.327 0.193 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 7 tokens with lr=0.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.136, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.754, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=42.477318
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=106.747765
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000015
[DEBUG] Encoder sample values: -0.023 1.522 0.103 -1.242 0.660 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.318, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=48.858055
[DECODER] After pos encoding: 1152/1152 non-zero, sum=106.674492
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.366 1.463 0.400 -1.125 0.508 
[DEBUG] Output range: [-2.365, 2.149]
[DEBUG] Output sample values: 0.269 1.697 -0.225 0.323 0.198 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
Epoca 148/150 - Loss: 7.6057 | LR: 2.635e-04

Época 149/150
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000009
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.126, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.126
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=35.371853
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.740295
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000010
[DEBUG] Decoder sample values: -0.372 1.468 0.395 -1.121 0.520 
[DEBUG] Output range: [-2.191, 2.147]
[DEBUG] Output sample values: 0.276 1.692 -0.228 0.323 0.200 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-20.048616
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=44.221790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.037 1.530 0.105 -1.247 0.666 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.813, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.813
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-20.514860
[DECODER] After pos encoding: 1152/1152 non-zero, sum=37.301548
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.376 1.469 0.404 -1.122 0.513 
[DEBUG] Output range: [-2.158, 2.210]
[DEBUG] Output sample values: 0.275 1.692 -0.227 0.333 0.196 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.190, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=13.466152
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=84.196617
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000001
[DEBUG] Encoder sample values: -0.026 1.501 0.108 -1.243 0.658 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.036, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.036
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11.726042
[DECODER] After pos encoding: 1024/1024 non-zero, sum=63.094425
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000013
[DEBUG] Decoder sample values: -0.367 1.451 0.403 -1.125 0.503 
[DEBUG] Output range: [-2.478, 2.256]
[DEBUG] Output sample values: 0.268 1.692 -0.222 0.324 0.195 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.858, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.703296
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.433815
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.031 1.522 0.104 -1.247 0.661 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=6.164, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=6.164
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=69.732307
[DECODER] After pos encoding: 1152/1152 non-zero, sum=127.548744
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -0.373 1.465 0.401 -1.124 0.511 
[DEBUG] Output range: [-2.175, 2.477]
[DEBUG] Output sample values: 0.275 1.688 -0.222 0.324 0.195 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.483, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-5.462055
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=45.906338
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000006
[DEBUG] Encoder sample values: -0.033 1.515 0.096 -1.245 0.647 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.562, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.562
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.297970
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.568367
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000011
[DEBUG] Decoder sample values: -1.207 0.128 1.412 -0.057 -0.576 
[DEBUG] Output range: [-2.445, 2.440]
[DEBUG] Output sample values: 0.390 1.419 -0.235 -0.185 0.714 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 10 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.034, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.612276
[ENCODER] After pos encoding: 768/768 non-zero, sum=64.102531
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Encoder sample values: -0.025 1.513 0.101 -1.242 0.649 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.537, range=[-0.105, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.537
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.389593
[DECODER] After pos encoding: 640/640 non-zero, sum=49.449810
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -0.367 1.460 0.397 -1.122 0.498 
[DEBUG] Output range: [-2.167, 2.107]
[DEBUG] Output sample values: 0.273 1.697 -0.224 0.328 0.200 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 5 tokens with lr=0.000
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.128, range=[-0.190, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.144, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=46.886948
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=98.255203
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.023 1.512 0.105 -1.230 0.657 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.824, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.824
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=54.580944
[DECODER] After pos encoding: 896/896 non-zero, sum=99.507332
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.366 1.453 0.400 -1.118 0.501 
[DEBUG] Output range: [-2.445, 2.165]
[DEBUG] Output sample values: 0.270 1.698 -0.221 0.329 0.193 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 7 tokens with lr=0.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.136, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.754, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=42.477318
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=106.747765
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.023 1.522 0.103 -1.242 0.660 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.319, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.319
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=48.860306
[DECODER] After pos encoding: 1152/1152 non-zero, sum=106.676750
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000009
[DEBUG] Decoder sample values: -0.366 1.463 0.400 -1.125 0.508 
[DEBUG] Output range: [-2.365, 2.149]
[DEBUG] Output sample values: 0.269 1.699 -0.223 0.325 0.199 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
Epoca 149/150 - Loss: 7.5961 | LR: 2.635e-04

Época 150/150
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=3.127, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=3.127
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=35.374073
[DECODER] After pos encoding: 1024/1024 non-zero, sum=86.742432
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -0.372 1.468 0.396 -1.121 0.520 
[DEBUG] Output range: [-2.191, 2.147]
[DEBUG] Output sample values: 0.276 1.694 -0.226 0.325 0.200 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-1.772, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-20.048616
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=44.221790
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.037 1.530 0.105 -1.247 0.666 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.813, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=-1.813
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-20.512508
[DECODER] After pos encoding: 1152/1152 non-zero, sum=37.303925
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: -0.376 1.469 0.405 -1.122 0.513 
[DEBUG] Output range: [-2.158, 2.210]
[DEBUG] Output sample values: 0.275 1.693 -0.225 0.334 0.196 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=1.190, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=13.466152
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=84.196617
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000009
[DEBUG] Encoder sample values: -0.026 1.501 0.108 -1.243 0.658 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=1.037, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=1.037
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=11.728403
[DECODER] After pos encoding: 1024/1024 non-zero, sum=63.096832
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: -0.367 1.451 0.404 -1.125 0.503 
[DEBUG] Output range: [-2.478, 2.256]
[DEBUG] Output sample values: 0.268 1.693 -0.221 0.326 0.195 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 8 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.058, range=[-0.119, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=0.858, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=9.703296
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=80.433815
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000020
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000015
[DEBUG] Encoder sample values: -0.031 1.522 0.104 -1.247 0.661 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=6.164, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=6.164
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=69.734558
[DECODER] After pos encoding: 1152/1152 non-zero, sum=127.551064
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000012
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.373 1.465 0.402 -1.124 0.511 
[DEBUG] Output range: [-2.175, 2.477]
[DEBUG] Output sample values: 0.275 1.689 -0.221 0.325 0.195 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.483, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-5.462055
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=45.906338
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000009
[DEBUG] Encoder sample values: -0.033 1.515 0.096 -1.245 0.647 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.562, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=3.562
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=40.300186
[DECODER] After pos encoding: 1280/1280 non-zero, sum=104.570549
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -1.357 -0.178 1.251 0.245 -0.851 
[DEBUG] Output range: [-2.412, 2.134]
[DEBUG] Output sample values: 0.364 1.212 -0.147 -0.256 0.808 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 10 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.034, range=[-0.095, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=2.264, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=25.612276
[ENCODER] After pos encoding: 768/768 non-zero, sum=64.102531
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.025 1.513 0.101 -1.242 0.649 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=1.537, range=[-0.105, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=1.537
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=17.391914
[DECODER] After pos encoding: 640/640 non-zero, sum=49.452126
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000011
[DEBUG] Decoder sample values: -0.367 1.460 0.398 -1.122 0.498 
[DEBUG] Output range: [-2.167, 2.107]
[DEBUG] Output sample values: 0.273 1.698 -0.222 0.330 0.200 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 5 tokens with lr=0.000
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.128, range=[-0.190, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=4.144, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=46.886948
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=98.255203
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.023 1.512 0.105 -1.230 0.657 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=4.825, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=4.825
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=54.583164
[DECODER] After pos encoding: 896/896 non-zero, sum=99.509537
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.366 1.453 0.401 -1.118 0.501 
[DEBUG] Output range: [-2.445, 2.167]
[DEBUG] Output sample values: 0.270 1.699 -0.220 0.330 0.193 
[LOSS] Gradient sum: 1.898
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 7 tokens with lr=0.000
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.074, range=[-0.136, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=3.754, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=42.477318
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=106.747765
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: -0.023 1.522 0.103 -1.242 0.660 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.319, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.319
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=48.862534
[DECODER] After pos encoding: 1152/1152 non-zero, sum=106.679016
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.366 1.463 0.401 -1.125 0.508 
[DEBUG] Output range: [-2.365, 2.149]
[DEBUG] Output sample values: 0.269 1.700 -0.222 0.326 0.199 
[LOSS] Gradient sum: 1.899
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.001
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[ATTENTION] Weights updated with lr=0.000
[FEEDFORWARD] Weights updated with lr=0.000
[EMBEDDING] Updating weights for 9 tokens with lr=0.000
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.045, range=[-0.106, 0.000]
[EMBEDDING] Sample weights after update: -0.00217650 0.03916871 0.10259034 -0.00631183 0.01751227 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.00026352
Epoca 150/150 - Loss: 7.6045 | LR: 2.635e-04 [Estancado:6][EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000014
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.181, range=[-0.102, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.181
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.043731
[DECODER] After pos encoding: 128/128 non-zero, sum=8.443730
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.372 1.468 0.396 -1.121 0.520 
[DEBUG] Output range: [-2.158, 2.030]
[DEBUG] Output sample values: 0.275 1.695 -0.225 0.326 0.200 
[GEN] Step 0 - Best token: 547 (score: 1.8, target_len: 8) [Top scores: 795:1.9 880:1.8 547:1.8 976:1.6 452:1.6 ]
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000014
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.074, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.074
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=0.832081
[DECODER] After pos encoding: 256/256 non-zero, sum=13.638104
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.372 1.468 0.396 -1.121 0.520 
[DEBUG] Output range: [-2.158, 2.030]
[DEBUG] Output sample values: 0.276 1.695 -0.225 0.326 0.201 
[GEN] Step 1 - Best token: 107 (score: 1.8, target_len: 8) [Top scores: 107:1.8 255:1.7 569:1.7 880:1.6 882:1.6 ]
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000014
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.099, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.099
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-1.119301
[DECODER] After pos encoding: 384/384 non-zero, sum=18.098764
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.372 1.468 0.396 -1.121 0.520 
[DEBUG] Output range: [-2.158, 2.030]
[DEBUG] Output sample values: 0.276 1.695 -0.225 0.326 0.201 
[GEN] Step 2 - Best token: 854 (score: 1.9, target_len: 8) [Top scores: 854:1.9 628:1.9 210:1.7 45:1.7 613:1.6 ]
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000014
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.275, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=0.275
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.116625
[DECODER] After pos encoding: 512/512 non-zero, sum=28.752745
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.372 1.468 0.396 -1.121 0.520 
[DEBUG] Output range: [-2.158, 2.030]
[DEBUG] Output sample values: 0.276 1.695 -0.225 0.326 0.201 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-0.673, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-7.608769
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=50.207680
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000014
[DEBUG] Encoder sample values: -0.031 1.526 0.100 -1.242 0.673 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.144, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=0.144
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=1.627366
[DECODER] After pos encoding: 640/640 non-zero, sum=33.687565
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -0.372 1.468 0.396 -1.121 0.520 
[DEBUG] Output range: [-2.158, 2.093]
[DEBUG] Output sample values: 0.276 1.695 -0.225 0.326 0.201 
 | Test: <sos> jam creo sta dicen pens

=== RESUMEN DE ENTRENAMIENTO ===
Pérdida inicial: 7.7871
Mejor pérdida: 7.5939
Mejora absoluta: 0.1933
Mejora porcentual: 2.4818%
¡Entrenamiento completado! Pérdida guardada en training_loss.txt

=== Pruebas de Traducción ===
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.716, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=8.098374
[ENCODER] After pos encoding: 384/384 non-zero, sum=27.316454
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.020 1.526 0.104 -1.234 0.653 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.181, range=[-0.102, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.181
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.043731
[DECODER] After pos encoding: 128/128 non-zero, sum=8.443730
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.363 1.468 0.401 -1.117 0.504 
[DEBUG] Output range: [-2.160, 2.031]
[DEBUG] Output sample values: 0.272 1.699 -0.222 0.328 0.198 
[GEN] Step 0 - Best token: 795 (score: 1.9, target_len: 2) [Top scores: 795:1.9 880:1.8 547:1.8 976:1.6 452:1.6 ]
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.716, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=8.098374
[ENCODER] After pos encoding: 384/384 non-zero, sum=27.316454
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000005
[DEBUG] Encoder sample values: -0.020 1.526 0.104 -1.234 0.653 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.262, range=[-0.105, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.262
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-2.963824
[DECODER] After pos encoding: 256/256 non-zero, sum=9.842197
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -0.363 1.468 0.401 -1.117 0.504 
[DEBUG] Output range: [-2.329, 2.030]
[DEBUG] Output sample values: 0.272 1.699 -0.222 0.328 0.198 
[GEN] Step 1 - Best token: 880 (score: 2.0, target_len: 2) [Top scores: 880:2.0 452:1.9 712:1.7 28:1.7 976:1.7 ]
ENG: <sos> hello <eos>
ESP: <sos> rojo dime <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.020, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.855444
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.915649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.018 1.517 0.102 -1.231 0.660 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.181, range=[-0.102, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.181
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.043731
[DECODER] After pos encoding: 128/128 non-zero, sum=8.443730
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000006
[DEBUG] Decoder sample values: -0.361 1.463 0.400 -1.114 0.508 
[DEBUG] Output range: [-2.158, 2.035]
[DEBUG] Output sample values: 0.272 1.697 -0.219 0.325 0.204 
[GEN] Step 0 - Best token: 795 (score: 1.9, target_len: 4) [Top scores: 795:1.9 880:1.8 547:1.8 976:1.6 452:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.020, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.855444
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.915649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.018 1.517 0.102 -1.231 0.660 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.262, range=[-0.105, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.262
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-2.963824
[DECODER] After pos encoding: 256/256 non-zero, sum=9.842197
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.361 1.463 0.400 -1.114 0.508 
[DEBUG] Output range: [-2.355, 2.073]
[DEBUG] Output sample values: 0.272 1.697 -0.219 0.325 0.204 
[GEN] Step 1 - Best token: 569 (score: 1.8, target_len: 4) [Top scores: 880:2.0 452:1.8 569:1.8 28:1.7 712:1.7 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.020, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.855444
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.915649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.018 1.517 0.102 -1.231 0.660 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-1.065, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-1.065
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-12.046109
[DECODER] After pos encoding: 384/384 non-zero, sum=7.171954
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: -0.361 1.463 0.400 -1.114 0.508 
[DEBUG] Output range: [-2.391, 2.070]
[DEBUG] Output sample values: 0.272 1.697 -0.218 0.325 0.204 
[GEN] Step 2 - Best token: 547 (score: 1.7, target_len: 4) [Top scores: 547:1.7 199:1.6 880:1.6 56:1.6 701:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.020, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=22.855444
[ENCODER] After pos encoding: 640/640 non-zero, sum=54.915649
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DEBUG] Encoder sample values: -0.018 1.517 0.102 -1.231 0.660 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-1.172, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=-1.172
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-13.257754
[DECODER] After pos encoding: 512/512 non-zero, sum=12.378365
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -0.360 1.463 0.400 -1.114 0.508 
[DEBUG] Output range: [-2.398, 2.066]
[DEBUG] Output sample values: 0.272 1.697 -0.218 0.325 0.205 
ENG: <sos> how are you <eos>
ESP: <sos> rojo primero jam a <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.623, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=7.044590
[ENCODER] After pos encoding: 512/512 non-zero, sum=32.680721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000010
[DEBUG] Encoder sample values: -0.021 1.524 0.104 -1.246 0.650 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.181, range=[-0.102, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.181
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.043731
[DECODER] After pos encoding: 128/128 non-zero, sum=8.443730
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.364 1.466 0.400 -1.126 0.502 
[DEBUG] Output range: [-2.163, 2.032]
[DEBUG] Output sample values: 0.272 1.699 -0.222 0.327 0.196 
[GEN] Step 0 - Best token: 547 (score: 1.8, target_len: 3) [Top scores: 795:1.9 880:1.8 547:1.8 976:1.6 452:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.623, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=7.044590
[ENCODER] After pos encoding: 512/512 non-zero, sum=32.680721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000010
[DEBUG] Encoder sample values: -0.021 1.524 0.104 -1.246 0.650 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=0.074, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=0.074
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=0.832081
[DECODER] After pos encoding: 256/256 non-zero, sum=13.638104
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.365 1.466 0.400 -1.126 0.502 
[DEBUG] Output range: [-2.163, 2.032]
[DEBUG] Output sample values: 0.272 1.699 -0.222 0.327 0.196 
[GEN] Step 1 - Best token: 880 (score: 1.8, target_len: 3) [Top scores: 880:1.8 795:1.7 255:1.7 569:1.6 28:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.623, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=7.044590
[ENCODER] After pos encoding: 512/512 non-zero, sum=32.680721
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000010
[DEBUG] Encoder sample values: -0.021 1.524 0.104 -1.246 0.650 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.314, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-3.552244
[DECODER] After pos encoding: 384/384 non-zero, sum=15.665820
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: -0.364 1.466 0.400 -1.126 0.501 
[DEBUG] Output range: [-2.163, 2.062]
[DEBUG] Output sample values: 0.272 1.699 -0.221 0.327 0.196 
[GEN] Step 2 - Best token: 948 (score: 1.9, target_len: 3) [Top scores: 948:1.9 610:1.7 780:1.7 43:1.6 50:1.5 ]
ENG: <sos> good morning <eos>
ESP: <sos> jam dime amable <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.341, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.855729
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.491854
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.023 1.522 0.104 -1.235 0.652 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.181, range=[-0.102, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.181
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.043731
[DECODER] After pos encoding: 128/128 non-zero, sum=8.443730
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.365 1.464 0.400 -1.117 0.503 
[DEBUG] Output range: [-2.162, 2.032]
[DEBUG] Output sample values: 0.273 1.700 -0.223 0.327 0.200 
[GEN] Step 0 - Best token: 795 (score: 1.9, target_len: 3) [Top scores: 795:1.9 880:1.8 547:1.8 976:1.6 452:1.6 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.341, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.855729
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.491854
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.023 1.522 0.104 -1.235 0.652 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.262, range=[-0.105, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.262
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-2.963824
[DECODER] After pos encoding: 256/256 non-zero, sum=9.842197
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.365 1.464 0.400 -1.117 0.503 
[DEBUG] Output range: [-2.350, 2.109]
[DEBUG] Output sample values: 0.273 1.700 -0.223 0.327 0.200 
[GEN] Step 1 - Best token: 880 (score: 2.0, target_len: 3) [Top scores: 880:2.0 452:1.8 28:1.8 622:1.7 569:1.7 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.341, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=3.855729
[ENCODER] After pos encoding: 512/512 non-zero, sum=29.491854
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: -0.023 1.522 0.104 -1.235 0.652 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.649, range=[-0.105, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.649
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-7.348149
[DECODER] After pos encoding: 384/384 non-zero, sum=11.869922
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -0.365 1.464 0.400 -1.117 0.503 
[DEBUG] Output range: [-2.358, 2.165]
[DEBUG] Output sample values: 0.273 1.701 -0.223 0.327 0.200 
[GEN] Step 2 - Best token: 594 (score: 1.9, target_len: 3) [Top scores: 594:1.9 38:1.6 547:1.5 416:1.5 456:1.5 ]
ENG: <sos> thank you <eos>
ESP: <sos> rojo dime vaya <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.540, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-6.112552
[ENCODER] After pos encoding: 640/640 non-zero, sum=25.947626
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.022 1.523 0.104 -1.234 0.656 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=0.181, range=[-0.102, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=0.181
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=2.043731
[DECODER] After pos encoding: 128/128 non-zero, sum=8.443730
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.364 1.466 0.400 -1.116 0.506 
[DEBUG] Output range: [-2.161, 2.034]
[DEBUG] Output sample values: 0.274 1.702 -0.223 0.327 0.203 
[GEN] Step 0 - Best token: 880 (score: 1.8, target_len: 4) [Top scores: 795:1.9 880:1.8 547:1.8 976:1.6 452:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.540, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-6.112552
[ENCODER] After pos encoding: 640/640 non-zero, sum=25.947626
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.022 1.523 0.104 -1.234 0.656 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=-0.207, range=[-0.102, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=-0.207
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=-2.340593
[DECODER] After pos encoding: 256/256 non-zero, sum=10.465439
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000007
[DEBUG] Decoder sample values: -0.364 1.466 0.400 -1.116 0.506 
[DEBUG] Output range: [-2.467, 2.034]
[DEBUG] Output sample values: 0.274 1.702 -0.223 0.327 0.203 
[GEN] Step 1 - Best token: 547 (score: 1.8, target_len: 4) [Top scores: 547:1.8 28:1.7 795:1.6 108:1.5 165:1.5 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.540, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-6.112552
[ENCODER] After pos encoding: 640/640 non-zero, sum=25.947626
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.022 1.523 0.104 -1.234 0.656 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.314, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=-0.314
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-3.552243
[DECODER] After pos encoding: 384/384 non-zero, sum=15.665833
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.364 1.466 0.400 -1.116 0.506 
[DEBUG] Output range: [-2.462, 2.307]
[DEBUG] Output sample values: 0.274 1.702 -0.223 0.327 0.203 
[GEN] Step 2 - Best token: 623 (score: 1.8, target_len: 4) [Top scores: 623:1.8 802:1.7 612:1.7 806:1.7 107:1.6 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.540, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-6.112552
[ENCODER] After pos encoding: 640/640 non-zero, sum=25.947626
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000007
[DEBUG] Encoder sample values: -0.022 1.523 0.104 -1.234 0.656 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=0.163, range=[-0.106, 0.108]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=0.163
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=1.849385
[DECODER] After pos encoding: 512/512 non-zero, sum=27.485519
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.364 1.466 0.400 -1.116 0.506 
[DEBUG] Output range: [-2.161, 2.310]
[DEBUG] Output sample values: 0.274 1.702 -0.223 0.327 0.203 
ENG: <sos> i love you <eos>
ESP: <sos> dime jam vacaciones gracias <eos>
---

sing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 628 (score: 3.0, target_len: 2) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=0.657, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=7.433064
[ENCODER] After pos encoding: 384/384 non-zero, sum=26.651138
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000013
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1548330112.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1548330112.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17517604864.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17517604864.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 10 (score: 3.0, target_len: 2) [Top scores: 17:3.0 10:3.0 7:3.0 1:1.5 628:-1.0 ]
ENG: <sos> hello <eos>
ESP: <sos> dicen en <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.395, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.096992
[ENCODER] After pos encoding: 640/640 non-zero, sum=59.157219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 17 (score: 3.0, target_len: 4) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.395, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.096992
[ENCODER] After pos encoding: 640/640 non-zero, sum=59.157219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1571922432.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1571922432.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17784543232.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17784543232.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 10 (score: 3.0, target_len: 4) [Top scores: 628:3.0 10:3.0 7:3.0 1:1.5 17:-1.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.395, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.096992
[ENCODER] After pos encoding: 640/640 non-zero, sum=59.157219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1550621696.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1550621696.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17543581696.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17543581696.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 628 (score: 3.0, target_len: 4) [Top scores: 628:3.0 7:3.0 1:1.5 17:0.0 10:-1.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=2.395, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=27.096992
[ENCODER] After pos encoding: 640/640 non-zero, sum=59.157219
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1503308544.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1503308544.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=17008384000.000000
[DECODER] After pos encoding: 512/512 non-zero, sum=17008384000.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
ENG: <sos> how are you <eos>
ESP: <sos> se en dicen que <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.118, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-1.336728
[ENCODER] After pos encoding: 512/512 non-zero, sum=24.299410
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 628 (score: 3.0, target_len: 3) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.118, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-1.336728
[ENCODER] After pos encoding: 512/512 non-zero, sum=24.299410
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1548330112.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1548330112.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17517604864.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17517604864.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 17 (score: 3.0, target_len: 3) [Top scores: 17:3.0 10:3.0 7:3.0 1:1.5 628:-1.0 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.118, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-1.336728
[ENCODER] After pos encoding: 512/512 non-zero, sum=24.299410
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1524609280.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1524609280.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17249409024.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17249409024.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 10 (score: 3.0, target_len: 3) [Top scores: 10:3.0 7:3.0 1:1.5 628:0.0 17:-1.0 ]
ENG: <sos> good morning <eos>
ESP: <sos> dicen se en <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.273, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=14.401515
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.037640
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 10 (score: 3.0, target_len: 3) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.273, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=14.401515
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.037640
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1574342528.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1574342528.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17811777536.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17811777536.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 17 (score: 3.0, target_len: 3) [Top scores: 628:3.0 17:3.0 7:3.0 1:1.5 10:-1.0 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1.273, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=14.401515
[ENCODER] After pos encoding: 512/512 non-zero, sum=40.037640
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000017
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1550621696.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1550621696.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17543581696.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17543581696.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 628 (score: 3.0, target_len: 3) [Top scores: 628:3.0 7:3.0 1:1.5 10:0.0 17:-1.0 ]
ENG: <sos> thank you <eos>
ESP: <sos> en se dicen <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.534, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=6.043063
[ENCODER] After pos encoding: 640/640 non-zero, sum=38.103271
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=1595643264.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=1595643264.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=18052739072.000000
[DECODER] After pos encoding: 128/128 non-zero, sum=18052739072.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/128 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 0 - Best token: 17 (score: 3.0, target_len: 4) [Top scores: 628:3.0 17:3.0 10:3.0 7:3.0 1:1.5 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.534, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=6.043063
[ENCODER] After pos encoding: 640/640 non-zero, sum=38.103271
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=1571922432.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=1571922432.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=17784543232.000000
[DECODER] After pos encoding: 256/256 non-zero, sum=17784543232.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/256 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 1 - Best token: 10 (score: 3.0, target_len: 4) [Top scores: 628:3.0 10:3.0 7:3.0 1:1.5 17:-1.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.534, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=6.043063
[ENCODER] After pos encoding: 640/640 non-zero, sum=38.103271
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=1550621696.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=1550621696.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=17543581696.000000
[DECODER] After pos encoding: 384/384 non-zero, sum=17543581696.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/384 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
[GEN] Step 2 - Best token: 628 (score: 3.0, target_len: 4) [Top scores: 628:3.0 7:3.0 1:1.5 17:0.0 10:-1.0 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.534, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=6.043063
[ENCODER] After pos encoding: 640/640 non-zero, sum=38.103271
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000020
[DEBUG] Encoder sample values: 1.105 -1.194 1.169 0.520 -1.153 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=1503308544.000, range=[-315462560.000, 3630480128.000]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=1503308544.000
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=17008384000.000000
[DECODER] After pos encoding: 512/512 non-zero, sum=17008384000.000000
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/512 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: 0.000 0.000 0.000 0.000 0.000 
[DEBUG] Output range: [-3.000, 3.000]
[DEBUG] Output sample values: -3.000 3.000 3.000 3.000 -3.000 
ENG: <sos> i love you <eos>
ESP: <sos> se en dicen que <eos>
---