Se han truncado las últimas 5000 líneas del flujo de salida.
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 0.613 0.341 0.754 1.023 0.025 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=6.745, range=[-0.676, 12.626]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=6.745
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=76.311989
[DECODER] After pos encoding: 768/768 non-zero, sum=114.802147
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000001
[DEBUG] Decoder sample values: 0.251 -0.562 3.603 0.062 0.303 
[DEBUG] Output range: [-2.064, 6.311]
[DEBUG] Output sample values: -0.971 4.621 6.310 5.821 3.409 
[LOSS] Gradient sum: 1.722
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.041, range=[-0.129, 0.013]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.006, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-0.067404
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=51.300976
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000012
[DEBUG] Encoder sample values: 0.602 0.328 0.777 0.993 0.004 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=9.185, range=[-0.677, 12.633]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=9.185
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=103.914932
[DECODER] After pos encoding: 896/896 non-zero, sum=148.841370
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000008
[DEBUG] Decoder sample values: 0.171 -0.537 4.306 -0.076 0.200 
[DEBUG] Output range: [-2.464, 6.681]
[DEBUG] Output sample values: -1.155 4.436 6.346 5.751 3.247 
[LOSS] Gradient sum: 1.721
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 7 tokens with lr=0.050
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.030, range=[-0.110, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.640, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=7.238690
[ENCODER] After pos encoding: 896/896 non-zero, sum=52.165020
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000011
[DEBUG] Encoder sample values: 0.601 0.319 0.765 1.018 -0.003 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=8.576, range=[-0.677, 12.638]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=8.576
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=97.026138
[DECODER] After pos encoding: 768/768 non-zero, sum=135.516449
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000007
[DEBUG] Decoder sample values: 0.103 -0.723 4.550 -0.551 -0.321 
[DEBUG] Output range: [-2.262, 6.547]
[DEBUG] Output sample values: -1.418 4.798 6.547 5.997 3.540 
[LOSS] Gradient sum: 1.700
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.039, range=[-0.125, 0.014]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.703, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-7.948286
[ENCODER] After pos encoding: 768/768 non-zero, sum=30.542007
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000013
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: 0.589 0.343 0.797 1.003 -0.002 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.761, range=[-0.678, 12.645]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.761
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=53.867268
[DECODER] After pos encoding: 1152/1152 non-zero, sum=111.683777
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.184 -0.127 5.073 -0.294 -0.231 
[DEBUG] Output range: [-2.562, 6.752]
[DEBUG] Output sample values: -1.135 4.455 6.310 6.031 3.775 
[LOSS] Gradient sum: 1.729
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.018, range=[-0.086, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.979, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11.075830
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=68.892265
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: 0.611 0.342 0.773 1.015 0.018 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=5.580, range=[-0.678, 12.649]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=5.580
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=63.126404
[DECODER] After pos encoding: 1024/1024 non-zero, sum=114.494949
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000016
[DEBUG] Decoder sample values: 0.241 -0.503 4.326 -0.108 0.235 
[DEBUG] Output range: [-2.444, 6.667]
[DEBUG] Output sample values: -0.815 4.623 6.282 5.805 3.547 
[LOSS] Gradient sum: 1.734
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.024, range=[-0.097, 0.009]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.008, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-11.400229
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=46.416195
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000018
[DEBUG] Encoder sample values: 0.597 0.334 0.785 0.993 0.011 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.595, range=[-0.679, 12.654]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.595
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=51.984085
[DECODER] After pos encoding: 1152/1152 non-zero, sum=109.800674
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000012
[DEBUG] Decoder sample values: -0.122 -0.597 5.067 -0.320 0.084 
[DEBUG] Output range: [-2.423, 6.785]
[DEBUG] Output sample values: -1.233 4.508 6.070 6.272 3.855 
[LOSS] Gradient sum: 1.730
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.018, range=[-0.089, 0.013]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.226, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=13.871498
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=78.141907
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000008
[DEBUG] Encoder sample values: 0.585 0.365 0.806 0.989 -0.005 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=5.741, range=[-0.679, 12.658]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=5.741
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=64.954170
[DECODER] After pos encoding: 1280/1280 non-zero, sum=129.224548
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.405 0.322 5.343 -0.701 -0.213 
[DEBUG] Output range: [-2.492, 6.668]
[DEBUG] Output sample values: -1.042 4.297 6.564 5.917 3.444 
[LOSS] Gradient sum: 1.721
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.014, range=[-0.074, 0.008]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.984, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=11.132812
[ENCODER] After pos encoding: 768/768 non-zero, sum=49.623062
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 0.610 0.342 0.782 1.001 -0.007 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=8.336, range=[-0.680, 12.662]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=8.336
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=94.306793
[DECODER] After pos encoding: 512/512 non-zero, sum=119.943001
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000005
[DEBUG] Decoder sample values: 0.089 -0.154 3.872 -0.326 0.138 
[DEBUG] Output range: [-2.351, 6.471]
[DEBUG] Output sample values: -1.027 4.615 6.128 6.016 3.302 
[LOSS] Gradient sum: 1.682
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 4 tokens with lr=0.050
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.075, range=[-0.199, 0.023]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.914, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-10.337485
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=66.858910
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000009
[DEBUG] Encoder sample values: 0.605 0.330 0.765 1.017 -0.008 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=4.459, range=[-0.681, 12.672]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=4.459
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=50.447079
[DECODER] After pos encoding: 1792/1792 non-zero, sum=140.593323
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1792/1792 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1792/1792 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 0.034 -0.643 7.511 -1.285 0.092 
[DEBUG] Output range: [-2.275, 6.689]
[DEBUG] Output sample values: -1.044 4.722 5.979 5.959 3.919 
[LOSS] Gradient sum: 1.765
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 14 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.003, range=[-0.058, 0.006]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-2.276, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-25.747986
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=44.982510
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: 0.608 0.341 0.762 1.001 0.037 
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=8.398, range=[-0.681, 12.675]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=8.398
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=95.007965
[DECODER] After pos encoding: 1536/1536 non-zero, sum=172.204544
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.621 -0.142 4.687 -0.271 0.545 
[DEBUG] Output range: [-2.177, 6.725]
[DEBUG] Output sample values: -1.256 4.961 6.003 6.248 3.810 
[LOSS] Gradient sum: 1.749
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 12 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.008, range=[-0.067, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.167, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=24.520205
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=88.790619
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.616 0.336 0.791 1.010 0.015 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=7.502, range=[-0.682, 12.678]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=7.502
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=84.873444
[DECODER] After pos encoding: 1152/1152 non-zero, sum=142.689758
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Decoder sample values: 0.269 -0.058 5.220 -0.241 0.400 
[DEBUG] Output range: [-2.740, 6.873]
[DEBUG] Output sample values: -1.006 4.724 5.888 6.041 3.348 
[LOSS] Gradient sum: 1.740
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.091, 0.011]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.280, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=25.794020
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=83.610405
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 0.606 0.337 0.786 1.000 0.016 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=8.725, range=[-0.682, 12.683]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=8.725
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=98.710686
[DECODER] After pos encoding: 1152/1152 non-zero, sum=156.526947
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000002
[DEBUG] Decoder sample values: -0.228 -0.003 5.440 -0.432 0.056 
[DEBUG] Output range: [-3.065, 6.575]
[DEBUG] Output sample values: -0.996 4.503 5.576 6.420 4.117 
[LOSS] Gradient sum: 1.740
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.093, 0.016]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
Epoca 147/150 - Loss: 4.5405

Época 148/150
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=1.442202
[ENCODER] After pos encoding: 768/768 non-zero, sum=39.932457
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000000
[DEBUG] Encoder sample values: 0.603 0.329 0.787 0.986 0.015 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=8.134, range=[-0.683, 12.687]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=8.134
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=92.023781
[DECODER] After pos encoding: 640/640 non-zero, sum=124.083847
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -0.281 -1.072 4.593 -1.541 -0.387 
[DEBUG] Output range: [-2.412, 7.322]
[DEBUG] Output sample values: -1.010 4.987 7.311 4.791 3.655 
[LOSS] Gradient sum: 1.658
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 639/640 non-zero, sum=-0.043, range=[-0.123, 0.006]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.563, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-6.370597
[ENCODER] After pos encoding: 896/896 non-zero, sum=38.555698
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 0.579 0.339 0.808 0.998 -0.001 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=8.522, range=[-0.683, 12.693]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=8.522
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=96.411171
[DECODER] After pos encoding: 640/640 non-zero, sum=128.471405
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.214 -0.220 4.462 -0.210 0.535 
[DEBUG] Output range: [-2.295, 6.721]
[DEBUG] Output sample values: -0.951 4.678 6.716 5.633 3.323 
[LOSS] Gradient sum: 1.684
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.050, range=[-0.144, 0.012]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.995, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-33.880093
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=23.936365
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000018
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: 0.590 0.334 0.769 0.977 0.026 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.685, range=[-0.684, 12.701]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.685
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=53.007862
[DECODER] After pos encoding: 1152/1152 non-zero, sum=110.824249
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000014
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000009
[DEBUG] Decoder sample values: 0.035 -0.373 4.654 -0.329 0.532 
[DEBUG] Output range: [-2.404, 6.829]
[DEBUG] Output sample values: -1.033 4.617 6.567 5.966 3.536 
[LOSS] Gradient sum: 1.724
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1150/1152 non-zero, sum=-0.018, range=[-0.083, 0.009]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.594, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-6.718196
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=57.552288
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000009
[DEBUG] Encoder sample values: 0.589 0.330 0.786 0.983 -0.000 
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=6.278, range=[-0.684, 12.705]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=6.278
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=71.032646
[DECODER] After pos encoding: 1536/1536 non-zero, sum=148.229172
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -0.567 -1.104 5.138 -0.816 -0.515 
[DEBUG] Output range: [-2.408, 6.848]
[DEBUG] Output sample values: -1.205 4.432 6.534 5.870 3.759 
[LOSS] Gradient sum: 1.745
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 12 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.007, range=[-0.062, 0.007]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.071, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.116378
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=39.251980
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[DEBUG] Encoder sample values: 0.614 0.341 0.754 1.023 0.025 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=6.785, range=[-0.685, 12.708]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=6.785
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=76.762383
[DECODER] After pos encoding: 768/768 non-zero, sum=115.252800
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: 0.256 -0.565 3.596 0.058 0.307 
[DEBUG] Output range: [-2.067, 6.352]
[DEBUG] Output sample values: -0.971 4.652 6.351 5.769 3.406 
[LOSS] Gradient sum: 1.722
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.041, range=[-0.128, 0.012]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.006, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-0.067404
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=51.300976
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 0.602 0.328 0.777 0.994 0.004 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=9.220, range=[-0.685, 12.714]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=9.220
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=104.317505
[DECODER] After pos encoding: 896/896 non-zero, sum=149.243851
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=0.000006
[DEBUG] Decoder sample values: 0.176 -0.540 4.301 -0.082 0.204 
[DEBUG] Output range: [-2.466, 6.663]
[DEBUG] Output sample values: -1.156 4.457 6.392 5.721 3.242 
[LOSS] Gradient sum: 1.720
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 7 tokens with lr=0.050
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.030, range=[-0.109, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.640, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=7.238690
[ENCODER] After pos encoding: 896/896 non-zero, sum=52.165020
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000005
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000003
[DEBUG] Encoder sample values: 0.602 0.319 0.765 1.019 -0.003 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=8.616, range=[-0.686, 12.720]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=8.616
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=97.476974
[DECODER] After pos encoding: 768/768 non-zero, sum=135.967209
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Decoder sample values: 0.108 -0.727 4.543 -0.559 -0.319 
[DEBUG] Output range: [-2.266, 6.548]
[DEBUG] Output sample values: -1.419 4.849 6.548 5.993 3.537 
[LOSS] Gradient sum: 1.701
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.039, range=[-0.125, 0.014]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.703, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-7.948286
[ENCODER] After pos encoding: 768/768 non-zero, sum=30.542007
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: 0.590 0.343 0.797 1.003 -0.002 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.801, range=[-0.687, 12.726]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.801
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=54.315357
[DECODER] After pos encoding: 1152/1152 non-zero, sum=112.131783
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000006
[DEBUG] Decoder sample values: -0.179 -0.131 5.063 -0.300 -0.226 
[DEBUG] Output range: [-2.564, 6.758]
[DEBUG] Output sample values: -1.136 4.516 6.305 6.042 3.772 
[LOSS] Gradient sum: 1.729
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.018, range=[-0.087, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.979, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11.075830
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=68.892265
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: 0.611 0.342 0.773 1.015 0.018 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=5.617, range=[-0.687, 12.730]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=5.617
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=63.550491
[DECODER] After pos encoding: 1024/1024 non-zero, sum=114.918839
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000010
[DEBUG] Decoder sample values: 0.246 -0.506 4.320 -0.114 0.239 
[DEBUG] Output range: [-2.447, 6.618]
[DEBUG] Output sample values: -0.815 4.674 6.293 5.798 3.545 
[LOSS] Gradient sum: 1.733
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1023/1024 non-zero, sum=-0.024, range=[-0.097, 0.009]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.008, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-11.400229
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=46.416195
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DEBUG] Encoder sample values: 0.597 0.334 0.785 0.993 0.012 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.631, range=[-0.688, 12.735]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.631
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=52.398422
[DECODER] After pos encoding: 1152/1152 non-zero, sum=110.214706
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000000
[DEBUG] Decoder sample values: -0.118 -0.600 5.061 -0.327 0.087 
[DEBUG] Output range: [-2.425, 6.810]
[DEBUG] Output sample values: -1.234 4.561 6.081 6.285 3.854 
[LOSS] Gradient sum: 1.730
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1151/1152 non-zero, sum=-0.018, range=[-0.089, 0.013]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.226, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=13.871498
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=78.141907
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000015
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 0.586 0.365 0.806 0.989 -0.005 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=5.774, range=[-0.688, 12.740]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=5.774
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=65.326538
[DECODER] After pos encoding: 1280/1280 non-zero, sum=129.596863
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.399 0.319 5.335 -0.709 -0.209 
[DEBUG] Output range: [-2.495, 6.696]
[DEBUG] Output sample values: -1.043 4.328 6.591 5.916 3.443 
[LOSS] Gradient sum: 1.719
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.014, range=[-0.074, 0.008]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.984, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=11.132812
[ENCODER] After pos encoding: 768/768 non-zero, sum=49.623062
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: 0.610 0.342 0.782 1.001 -0.007 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=8.374, range=[-0.689, 12.743]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=8.374
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=94.743759
[DECODER] After pos encoding: 512/512 non-zero, sum=120.379944
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000005
[DEBUG] Decoder sample values: 0.094 -0.156 3.866 -0.334 0.141 
[DEBUG] Output range: [-2.354, 6.493]
[DEBUG] Output sample values: -1.028 4.622 6.159 6.011 3.299 
[LOSS] Gradient sum: 1.680
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 4 tokens with lr=0.050
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.074, range=[-0.199, 0.023]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.914, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-10.337485
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=66.858910
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000016
[DEBUG] Encoder sample values: 0.606 0.330 0.764 1.017 -0.007 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=4.490, range=[-0.690, 12.753]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=4.490
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=50.795750
[DECODER] After pos encoding: 1792/1792 non-zero, sum=140.941940
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1792/1792 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1792/1792 non-zero, sum=0.000008
[DEBUG] Decoder sample values: 0.039 -0.648 7.496 -1.292 0.097 
[DEBUG] Output range: [-2.279, 6.666]
[DEBUG] Output sample values: -1.045 4.726 5.999 5.967 3.916 
[LOSS] Gradient sum: 1.765
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 14 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.003, range=[-0.058, 0.006]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-2.276, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-25.747986
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=44.982510
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000018
[DEBUG] Encoder sample values: 0.608 0.341 0.762 1.001 0.037 
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=8.435, range=[-0.690, 12.756]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=8.435
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=95.434151
[DECODER] After pos encoding: 1536/1536 non-zero, sum=172.630753
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=-0.000012
[DEBUG] Decoder sample values: 0.626 -0.146 4.678 -0.278 0.549 
[DEBUG] Output range: [-2.172, 6.717]
[DEBUG] Output sample values: -1.257 4.958 6.059 6.256 3.809 
[LOSS] Gradient sum: 1.748
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 12 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.008, range=[-0.067, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.167, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=24.520205
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=88.790619
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 0.617 0.336 0.791 1.010 0.015 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=7.541, range=[-0.691, 12.760]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=7.541
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=85.322380
[DECODER] After pos encoding: 1152/1152 non-zero, sum=143.138382
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[DEBUG] Decoder sample values: 0.274 -0.061 5.213 -0.248 0.404 
[DEBUG] Output range: [-2.738, 6.859]
[DEBUG] Output sample values: -1.007 4.704 5.908 6.051 3.353 
[LOSS] Gradient sum: 1.740
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.091, 0.011]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.280, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=25.794020
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=83.610405
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 0.607 0.337 0.786 1.000 0.017 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=8.762, range=[-0.691, 12.764]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=8.762
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=99.136223
[DECODER] After pos encoding: 1152/1152 non-zero, sum=156.952621
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000003
[DEBUG] Decoder sample values: -0.224 -0.006 5.431 -0.440 0.061 
[DEBUG] Output range: [-3.068, 6.564]
[DEBUG] Output sample values: -0.996 4.491 5.617 6.417 4.122 
[LOSS] Gradient sum: 1.739
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.093, 0.016]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
Epoca 148/150 - Loss: 4.3989

Época 149/150
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=1.442202
[ENCODER] After pos encoding: 768/768 non-zero, sum=39.932457
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 0.603 0.329 0.787 0.986 0.015 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=8.174, range=[-0.692, 12.769]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=8.174
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=92.483208
[DECODER] After pos encoding: 640/640 non-zero, sum=124.543350
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.277 -1.075 4.581 -1.546 -0.383 
[DEBUG] Output range: [-2.413, 7.290]
[DEBUG] Output sample values: -1.010 5.007 7.283 4.833 3.659 
[LOSS] Gradient sum: 1.660
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.043, range=[-0.124, 0.006]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.563, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-6.370597
[ENCODER] After pos encoding: 896/896 non-zero, sum=38.555698
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: 0.580 0.340 0.808 0.998 -0.001 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=8.562, range=[-0.692, 12.775]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=8.562
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=96.864243
[DECODER] After pos encoding: 640/640 non-zero, sum=128.924484
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000009
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000004
[DEBUG] Decoder sample values: -0.212 -0.222 4.457 -0.215 0.541 
[DEBUG] Output range: [-2.299, 6.722]
[DEBUG] Output sample values: -0.951 4.666 6.718 5.653 3.328 
[LOSS] Gradient sum: 1.684
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.050, range=[-0.144, 0.012]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.995, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-33.880093
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=23.936365
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: 0.590 0.335 0.769 0.977 0.026 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.725, range=[-0.693, 12.782]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.725
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=53.452549
[DECODER] After pos encoding: 1152/1152 non-zero, sum=111.269043
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000015
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.039 -0.376 4.649 -0.334 0.537 
[DEBUG] Output range: [-2.407, 6.801]
[DEBUG] Output sample values: -1.033 4.607 6.549 6.030 3.543 
[LOSS] Gradient sum: 1.724
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.018, range=[-0.083, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.594, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-6.718196
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=57.552288
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: 0.590 0.330 0.786 0.983 -0.000 
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=6.318, range=[-0.693, 12.786]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=6.318
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=71.481918
[DECODER] After pos encoding: 1536/1536 non-zero, sum=148.678268
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1536 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1536 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[LOSS] Gradient sum: 1.800
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 12 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.071, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.116378
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=39.251980
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 0.614 0.341 0.754 1.023 0.025 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=6.826, range=[-0.693, 12.790]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=6.826
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=77.230721
[DECODER] After pos encoding: 768/768 non-zero, sum=115.720840
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: 0.259 -0.568 3.589 0.052 0.311 
[DEBUG] Output range: [-2.070, 6.343]
[DEBUG] Output sample values: -0.972 4.643 6.342 5.855 3.412 
[LOSS] Gradient sum: 1.721
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.040, range=[-0.129, 0.013]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.006, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-0.067404
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=51.300976
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000012
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: 0.603 0.328 0.777 0.994 0.004 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=9.258, range=[-0.694, 12.797]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=9.258
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=104.737892
[DECODER] After pos encoding: 896/896 non-zero, sum=149.664169
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.180 -0.543 4.294 -0.087 0.209 
[DEBUG] Output range: [-2.467, 6.682]
[DEBUG] Output sample values: -1.158 4.468 6.388 5.754 3.249 
[LOSS] Gradient sum: 1.720
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 7 tokens with lr=0.050
[EMBEDDING] Gradient stats: 895/896 non-zero, sum=-0.030, range=[-0.110, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.640, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=7.238690
[ENCODER] After pos encoding: 896/896 non-zero, sum=52.165020
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.602 0.319 0.765 1.019 -0.003 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=8.657, range=[-0.694, 12.802]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=8.657
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=97.945251
[DECODER] After pos encoding: 768/768 non-zero, sum=136.435699
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 0.112 -0.729 4.535 -0.567 -0.316 
[DEBUG] Output range: [-2.271, 6.562]
[DEBUG] Output sample values: -1.421 4.840 6.562 6.014 3.544 
[LOSS] Gradient sum: 1.700
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 767/768 non-zero, sum=-0.038, range=[-0.125, 0.014]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.703, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-7.948286
[ENCODER] After pos encoding: 768/768 non-zero, sum=30.542007
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: 0.590 0.343 0.797 1.003 -0.002 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.842, range=[-0.695, 12.808]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.842
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=54.781132
[DECODER] After pos encoding: 1152/1152 non-zero, sum=112.597481
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Decoder sample values: -0.176 -0.135 5.052 -0.306 -0.222 
[DEBUG] Output range: [-2.567, 6.728]
[DEBUG] Output sample values: -1.137 4.518 6.316 6.032 3.777 
[LOSS] Gradient sum: 1.729
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.018, range=[-0.086, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.979, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11.075830
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=68.892265
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DEBUG] Encoder sample values: 0.611 0.342 0.773 1.015 0.018 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=5.656, range=[-0.696, 12.813]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=5.656
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=63.992214
[DECODER] After pos encoding: 1024/1024 non-zero, sum=115.360550
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=0.000016
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=0.000008
[DEBUG] Decoder sample values: 0.249 -0.509 4.312 -0.120 0.243 
[DEBUG] Output range: [-2.452, 6.634]
[DEBUG] Output sample values: -0.815 4.679 6.290 5.797 3.553 
[LOSS] Gradient sum: 1.734
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.024, range=[-0.097, 0.009]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.008, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-11.400229
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=46.416195
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.597 0.334 0.785 0.993 0.012 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.669, range=[-0.696, 12.817]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.669
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=52.828434
[DECODER] After pos encoding: 1152/1152 non-zero, sum=110.644997
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: -0.116 -0.605 5.053 -0.334 0.091 
[DEBUG] Output range: [-2.427, 6.803]
[DEBUG] Output sample values: -1.236 4.546 6.063 6.273 3.862 
[LOSS] Gradient sum: 1.731
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.018, range=[-0.089, 0.013]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.226, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=13.871498
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=78.141907
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000006
[DEBUG] Encoder sample values: 0.586 0.366 0.806 0.989 -0.005 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=5.809, range=[-0.697, 12.822]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=5.809
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=65.716942
[DECODER] After pos encoding: 1280/1280 non-zero, sum=129.987320
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000011
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: -0.396 0.315 5.325 -0.715 -0.204 
[DEBUG] Output range: [-2.499, 6.708]
[DEBUG] Output sample values: -1.043 4.310 6.591 5.894 3.428 
[LOSS] Gradient sum: 1.720
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.014, range=[-0.074, 0.008]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.984, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=11.132812
[ENCODER] After pos encoding: 768/768 non-zero, sum=49.623062
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 0.610 0.343 0.782 1.001 -0.007 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=8.414, range=[-0.697, 12.826]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=8.414
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=95.199074
[DECODER] After pos encoding: 512/512 non-zero, sum=120.835075
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: 0.096 -0.158 3.859 -0.341 0.144 
[DEBUG] Output range: [-2.355, 6.471]
[DEBUG] Output sample values: -1.029 4.605 6.133 6.009 3.287 
[LOSS] Gradient sum: 1.682
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 4 tokens with lr=0.050
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.074, range=[-0.199, 0.023]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.914, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-10.337485
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=66.858910
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=-0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000012
[DEBUG] Encoder sample values: 0.606 0.330 0.764 1.017 -0.007 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1791/1792 non-zero, sum=4.522, range=[-0.698, 12.836]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1791/1792 non-zero, sum=4.522
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=51.160870
[DECODER] After pos encoding: 1792/1792 non-zero, sum=141.307098
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1792/1792 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1792/1792 non-zero, sum=0.000006
[DEBUG] Decoder sample values: 0.041 -0.653 7.478 -1.297 0.101 
[DEBUG] Output range: [-2.284, 6.649]
[DEBUG] Output sample values: -1.046 4.691 6.001 5.949 3.901 
[LOSS] Gradient sum: 1.765
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 14 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1792/1792 non-zero, sum=-0.003, range=[-0.058, 0.006]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-2.276, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-25.747986
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=44.982510
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 0.608 0.341 0.762 1.001 0.037 
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=8.474, range=[-0.699, 12.839]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=8.474
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=95.877937
[DECODER] After pos encoding: 1536/1536 non-zero, sum=173.074188
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1536/1536 non-zero, sum=0.000010
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1536/1536 non-zero, sum=0.000001
[DEBUG] Decoder sample values: 0.627 -0.151 4.668 -0.284 0.553 
[DEBUG] Output range: [-2.165, 6.720]
[DEBUG] Output sample values: -1.257 4.869 6.054 6.273 3.801 
[LOSS] Gradient sum: 1.749
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 12 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.008, range=[-0.067, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.167, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=24.520205
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=88.790619
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000007
[DEBUG] Encoder sample values: 0.616 0.337 0.791 1.010 0.015 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=7.583, range=[-0.699, 12.842]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=7.583
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=85.788055
[DECODER] After pos encoding: 1152/1152 non-zero, sum=143.604462
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000007
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000011
[DEBUG] Decoder sample values: 0.276 -0.065 5.203 -0.256 0.408 
[DEBUG] Output range: [-2.735, 6.877]
[DEBUG] Output sample values: -1.007 4.636 5.907 6.066 3.339 
[LOSS] Gradient sum: 1.740
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.091, 0.011]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.280, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=25.794020
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=83.610405
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000029
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: 0.606 0.337 0.786 1.000 0.017 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=8.802, range=[-0.700, 12.846]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=8.802
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=99.580635
[DECODER] After pos encoding: 1152/1152 non-zero, sum=157.397125
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000016
[DEBUG] Decoder sample values: -0.223 -0.009 5.419 -0.448 0.065 
[DEBUG] Output range: [-3.072, 6.557]
[DEBUG] Output sample values: -0.996 4.422 5.613 6.414 4.110 
[LOSS] Gradient sum: 1.741
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.093, 0.016]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
Epoca 149/150 - Loss: 4.5324

Época 150/150
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=1.442202
[ENCODER] After pos encoding: 768/768 non-zero, sum=39.932457
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000005
[DEBUG] Encoder sample values: 0.603 0.329 0.787 0.986 0.015 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=8.217, range=[-0.700, 12.851]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=8.217
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=92.961823
[DECODER] After pos encoding: 640/640 non-zero, sum=125.022018
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=0.000008
[DEBUG] Decoder sample values: -0.274 -1.078 4.568 -1.550 -0.378 
[DEBUG] Output range: [-2.415, 7.316]
[DEBUG] Output sample values: -1.010 4.986 7.309 4.801 3.646 
[LOSS] Gradient sum: 1.659
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.043, range=[-0.123, 0.006]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=-0.563, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=-6.370597
[ENCODER] After pos encoding: 896/896 non-zero, sum=38.555698
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 0.580 0.340 0.808 0.997 -0.001 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=8.603, range=[-0.701, 12.857]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=8.603
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=97.335938
[DECODER] After pos encoding: 640/640 non-zero, sum=129.396164
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: -0.210 -0.226 4.450 -0.222 0.546 
[DEBUG] Output range: [-2.300, 6.761]
[DEBUG] Output sample values: -0.952 4.611 6.757 5.646 3.321 
[LOSS] Gradient sum: 1.683
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 5 tokens with lr=0.050
[EMBEDDING] Gradient stats: 640/640 non-zero, sum=-0.050, range=[-0.143, 0.012]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 5 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-2.995, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-33.880093
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=23.936365
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000011
[DEBUG] Encoder sample values: 0.590 0.335 0.769 0.977 0.027 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.766, range=[-0.701, 12.864]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.766
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=53.915943
[DECODER] After pos encoding: 1152/1152 non-zero, sum=111.732437
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 0.041 -0.380 4.641 -0.342 0.541 
[DEBUG] Output range: [-2.410, 6.837]
[DEBUG] Output sample values: -1.034 4.546 6.587 5.994 3.533 
[LOSS] Gradient sum: 1.724
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.018, range=[-0.082, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=-0.594, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=-6.718196
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=57.552288
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 0.589 0.331 0.786 0.983 0.000 
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=6.358, range=[-0.702, 12.868]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=6.358
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=71.935745
[DECODER] After pos encoding: 1536/1536 non-zero, sum=149.132202
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1536 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1536 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[LOSS] Gradient sum: 1.800
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 12 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-1.071, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-12.116378
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=39.251980
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000009
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000004
[DEBUG] Encoder sample values: 0.614 0.341 0.754 1.023 0.026 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=6.868, range=[-0.702, 12.872]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=6.868
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=77.698250
[DECODER] After pos encoding: 768/768 non-zero, sum=116.188446
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=-0.000008
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Decoder sample values: 0.261 -0.572 3.580 0.046 0.316 
[DEBUG] Output range: [-2.073, 6.387]
[DEBUG] Output sample values: -0.973 4.587 6.387 5.817 3.408 
[LOSS] Gradient sum: 1.720
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.040, range=[-0.128, 0.013]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=-0.006, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[ENCODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=-0.067404
[ENCODER] After pos encoding: 1024/1024 non-zero, sum=51.300976
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 0 output: 1024/1024 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1024/1024 non-zero
[ENCODER_LAYER] After self-attention: 1024/1024 non-zero
[ENCODER_LAYER] After norm1: 1024/1024 non-zero
[ENCODER_LAYER] After feedforward: 1024/1024 non-zero
[ENCODER_LAYER] Final output: 1024/1024 non-zero
[ENCODER] Layer 1 output: 1024/1024 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.603 0.329 0.777 0.994 0.005 
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=9.295, range=[-0.702, 12.879]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 896/896 non-zero, sum=9.295
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[DECODER] SCALED EMBEDS before add: 896/896 non-zero, sum=105.157799
[DECODER] After pos encoding: 896/896 non-zero, sum=150.084381
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 896/896 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 896/896 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: 0.182 -0.548 4.287 -0.094 0.213 
[DEBUG] Output range: [-2.468, 6.715]
[DEBUG] Output sample values: -1.159 4.418 6.420 5.730 3.244 
[LOSS] Gradient sum: 1.720
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 7 tokens with lr=0.050
[EMBEDDING] Gradient stats: 896/896 non-zero, sum=-0.030, range=[-0.109, 0.010]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 7 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=7, d_model=128
[EMBEDDING] 896/896 non-zero, sum=0.640, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 832/896 non-zero, sum=44.926334
[ENCODER] SCALED EMBEDS before add: 896/896 non-zero, sum=7.238690
[ENCODER] After pos encoding: 896/896 non-zero, sum=52.165020
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 0 output: 896/896 non-zero, sum=0.000010
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 896/896 non-zero
[ENCODER_LAYER] After self-attention: 896/896 non-zero
[ENCODER_LAYER] After norm1: 896/896 non-zero
[ENCODER_LAYER] After feedforward: 896/896 non-zero
[ENCODER_LAYER] Final output: 896/896 non-zero
[ENCODER] Layer 1 output: 896/896 non-zero, sum=-0.000002
[DEBUG] Encoder sample values: 0.602 0.319 0.765 1.019 -0.002 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=8.699, range=[-0.703, 12.884]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 768/768 non-zero, sum=8.699
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[DECODER] SCALED EMBEDS before add: 768/768 non-zero, sum=98.413483
[DECODER] After pos encoding: 768/768 non-zero, sum=136.903748
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 768/768 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 768/768 non-zero, sum=0.000007
[DEBUG] Decoder sample values: 0.115 -0.734 4.527 -0.576 -0.313 
[DEBUG] Output range: [-2.276, 6.609]
[DEBUG] Output sample values: -1.422 4.776 6.609 6.030 3.528 
[LOSS] Gradient sum: 1.698
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 6 tokens with lr=0.050
[EMBEDDING] Gradient stats: 768/768 non-zero, sum=-0.038, range=[-0.124, 0.015]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 6 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=-0.703, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=-7.948286
[ENCODER] After pos encoding: 768/768 non-zero, sum=30.542007
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.590 0.343 0.797 1.003 -0.001 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.883, range=[-0.704, 12.890]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.883
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=55.246677
[DECODER] After pos encoding: 1152/1152 non-zero, sum=113.063087
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1152 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[LOSS] Gradient sum: 1.799
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.042, range=[-0.100, 0.000]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=0.979, range=[-0.106, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=11.075830
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=68.892265
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000014
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 0.611 0.342 0.773 1.015 0.019 
[EMBEDDING] Forward pass - seq_len=8, d_model=128
[EMBEDDING] 1024/1024 non-zero, sum=5.697, range=[-0.704, 12.895]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1024/1024 non-zero, sum=5.697
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 960/1024 non-zero, sum=51.368427
[DECODER] SCALED EMBEDS before add: 1024/1024 non-zero, sum=64.458183
[DECODER] After pos encoding: 1024/1024 non-zero, sum=115.826515
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1024/1024 non-zero, sum=-0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1024/1024 non-zero, sum=-0.000010
[DEBUG] Decoder sample values: 0.250 -0.514 4.303 -0.127 0.248 
[DEBUG] Output range: [-2.457, 6.686]
[DEBUG] Output sample values: -0.816 4.632 6.334 5.810 3.548 
[LOSS] Gradient sum: 1.733
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 8 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1024/1024 non-zero, sum=-0.024, range=[-0.097, 0.009]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 8 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=-1.008, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=-11.400229
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=46.416195
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=0.000002
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000006
[DEBUG] Encoder sample values: 0.597 0.335 0.785 0.993 0.012 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=4.709, range=[-0.704, 12.900]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=4.709
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=53.281662
[DECODER] After pos encoding: 1152/1152 non-zero, sum=111.098152
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000006
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=-0.000007
[DEBUG] Decoder sample values: -0.114 -0.611 5.044 -0.342 0.096 
[DEBUG] Output range: [-2.429, 6.730]
[DEBUG] Output sample values: -1.238 4.492 6.127 6.283 3.855 
[LOSS] Gradient sum: 1.731
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.018, range=[-0.089, 0.013]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=1.226, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=13.871498
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=78.141907
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 0.586 0.366 0.805 0.989 -0.004 
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=5.845, range=[-0.705, 12.905]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1280/1280 non-zero, sum=5.845
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[DECODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=66.129517
[DECODER] After pos encoding: 1280/1280 non-zero, sum=130.399872
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1280/1280 non-zero, sum=0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000009
[DEBUG] Decoder sample values: -0.393 0.309 5.313 -0.723 -0.198 
[DEBUG] Output range: [-2.504, 6.767]
[DEBUG] Output sample values: -1.045 4.289 6.640 5.919 3.433 
[LOSS] Gradient sum: 1.720
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 10 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1280/1280 non-zero, sum=-0.014, range=[-0.073, 0.008]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 10 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.984, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=11.132812
[ENCODER] After pos encoding: 768/768 non-zero, sum=49.623062
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=0.000004
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=-0.000008
[DEBUG] Encoder sample values: 0.611 0.343 0.782 1.001 -0.007 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=8.457, range=[-0.705, 12.908]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=8.457
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=95.677841
[DECODER] After pos encoding: 512/512 non-zero, sum=121.313934
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000008
[DEBUG] Decoder sample values: 0.097 -0.162 3.851 -0.349 0.149 
[DEBUG] Output range: [-2.356, 6.545]
[DEBUG] Output sample values: -1.031 4.567 6.192 6.018 3.295 
[LOSS] Gradient sum: 1.680
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 4 tokens with lr=0.050
[EMBEDDING] Gradient stats: 512/512 non-zero, sum=-0.074, range=[-0.198, 0.023]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 4 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=-0.914, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[ENCODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=-10.337485
[ENCODER] After pos encoding: 1536/1536 non-zero, sum=66.858910
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 0 output: 1536/1536 non-zero, sum=0.000017
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1536/1536 non-zero
[ENCODER_LAYER] After self-attention: 1536/1536 non-zero
[ENCODER_LAYER] After norm1: 1536/1536 non-zero
[ENCODER_LAYER] After feedforward: 1536/1536 non-zero
[ENCODER_LAYER] Final output: 1536/1536 non-zero
[ENCODER] Layer 1 output: 1536/1536 non-zero, sum=0.000003
[DEBUG] Encoder sample values: 0.606 0.330 0.764 1.017 -0.007 
[EMBEDDING] Forward pass - seq_len=14, d_model=128
[EMBEDDING] 1792/1792 non-zero, sum=4.556, range=[-0.706, 12.918]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1792/1792 non-zero, sum=4.556
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1728/1792 non-zero, sum=90.146210
[DECODER] SCALED EMBEDS before add: 1792/1792 non-zero, sum=51.549606
[DECODER] After pos encoding: 1792/1792 non-zero, sum=141.695587
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1792/1792 non-zero, sum=0.000054
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1792/1792 non-zero, sum=0.000081
[DEBUG] Decoder sample values: -0.148 -1.206 0.053 -1.131 0.619 
[DEBUG] Output range: [-2.778, 7.332]
[DEBUG] Output sample values: -0.372 6.305 6.341 7.332 3.605 
[LOSS] Gradient sum: 1.703
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 14 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1790/1792 non-zero, sum=-0.002, range=[-0.058, 0.017]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 14 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=11, d_model=128
[EMBEDDING] 1408/1408 non-zero, sum=-2.276, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1344/1408 non-zero, sum=70.730721
[ENCODER] SCALED EMBEDS before add: 1408/1408 non-zero, sum=-25.747986
[ENCODER] After pos encoding: 1408/1408 non-zero, sum=44.982510
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 0 output: 1408/1408 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1408/1408 non-zero
[ENCODER_LAYER] After self-attention: 1408/1408 non-zero
[ENCODER_LAYER] After norm1: 1408/1408 non-zero
[ENCODER_LAYER] After feedforward: 1408/1408 non-zero
[ENCODER_LAYER] Final output: 1408/1408 non-zero
[ENCODER] Layer 1 output: 1408/1408 non-zero, sum=0.000011
[DEBUG] Encoder sample values: 0.608 0.342 0.762 1.001 0.038 
[EMBEDDING] Forward pass - seq_len=12, d_model=128
[EMBEDDING] 1536/1536 non-zero, sum=8.515, range=[-0.707, 12.921]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1536/1536 non-zero, sum=8.515
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1472/1536 non-zero, sum=77.196686
[DECODER] SCALED EMBEDS before add: 1536/1536 non-zero, sum=96.338783
[DECODER] After pos encoding: 1536/1536 non-zero, sum=173.535263
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 0/1536 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 0 produced all zeros!
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 0/1536 non-zero, sum=0.000000
[DECODER] CRITICAL: Decoder layer 1 produced all zeros!
[DEBUG] Decoder sample values: -nan -nan -nan -nan -nan 
[DEBUG] FIXED NaN/Inf in output, copying back
[DEBUG] Output range: [-nan, -nan]
[DEBUG] Output sample values: 0.000 0.000 0.000 0.000 0.000 
[WARNING] All output values are identical: 0.000
[LOSS] Gradient sum: 1.800
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 12 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1536/1536 non-zero, sum=-0.017, range=[-0.075, 0.000]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 12 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=10, d_model=128
[EMBEDDING] 1280/1280 non-zero, sum=2.167, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1216/1280 non-zero, sum=64.270538
[ENCODER] SCALED EMBEDS before add: 1280/1280 non-zero, sum=24.520205
[ENCODER] After pos encoding: 1280/1280 non-zero, sum=88.790619
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 0 output: 1280/1280 non-zero, sum=-0.000001
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1280/1280 non-zero
[ENCODER_LAYER] After self-attention: 1280/1280 non-zero
[ENCODER_LAYER] After norm1: 1280/1280 non-zero
[ENCODER_LAYER] After feedforward: 1280/1280 non-zero
[ENCODER_LAYER] Final output: 1280/1280 non-zero
[ENCODER] Layer 1 output: 1280/1280 non-zero, sum=-0.000016
[DEBUG] Encoder sample values: 0.617 0.337 0.791 1.010 0.016 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=7.627, range=[-0.707, 12.925]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=7.627
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=86.286049
[DECODER] After pos encoding: 1152/1152 non-zero, sum=144.102539
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000007
[DEBUG] Decoder sample values: 0.278 -0.070 5.191 -0.264 0.414 
[DEBUG] Output range: [-2.733, 6.882]
[DEBUG] Output sample values: -1.009 4.612 5.964 6.107 3.341 
[LOSS] Gradient sum: 1.739
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.090, 0.011]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=2.280, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[ENCODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=25.794020
[ENCODER] After pos encoding: 1152/1152 non-zero, sum=83.610405
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 0 output: 1152/1152 non-zero, sum=-0.000011
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 1152/1152 non-zero
[ENCODER_LAYER] After self-attention: 1152/1152 non-zero
[ENCODER_LAYER] After norm1: 1152/1152 non-zero
[ENCODER_LAYER] After feedforward: 1152/1152 non-zero
[ENCODER_LAYER] Final output: 1152/1152 non-zero
[ENCODER] Layer 1 output: 1152/1152 non-zero, sum=0.000005
[DEBUG] Encoder sample values: 0.607 0.338 0.786 1.000 0.017 
[EMBEDDING] Forward pass - seq_len=9, d_model=128
[EMBEDDING] 1152/1152 non-zero, sum=8.844, range=[-0.708, 12.929]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 1152/1152 non-zero, sum=8.844
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 1088/1152 non-zero, sum=57.816551
[DECODER] SCALED EMBEDS before add: 1152/1152 non-zero, sum=100.061592
[DECODER] After pos encoding: 1152/1152 non-zero, sum=157.878143
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 1152/1152 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 1152/1152 non-zero, sum=0.000010
[DEBUG] Decoder sample values: -0.221 -0.015 5.407 -0.455 0.071 
[DEBUG] Output range: [-3.076, 6.548]
[DEBUG] Output sample values: -0.997 4.404 5.667 6.409 4.116 
[LOSS] Gradient sum: 1.741
[BACKWARD] Starting backward pass...
[BACKWARD] Output projection backward completed
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Decoder layer 0 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 1 backward completed (with FeedForward)
[FEEDFORWARD] Real backward pass completed - gradients computed for W1, W2, b1, b2
[BACKWARD] Encoder layer 0 backward completed (with FeedForward)
[BACKWARD] Starting weight updates...
[LINEAR] Output projection - using 5x learning rate: 0.250
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[ATTENTION] Weights updated with lr=0.050
[FEEDFORWARD] Weights updated with lr=0.050
[EMBEDDING] Updating weights for 9 tokens with lr=0.050
[EMBEDDING] Gradient stats: 1152/1152 non-zero, sum=-0.019, range=[-0.093, 0.015]
[EMBEDDING] Sample weights after update: -0.07723506 0.09931811 -0.01555352 -0.06345906 -0.02098680 
[EMBEDDING] Weight update completed successfully
[UPDATE] Target embeddings updated for 9 tokens
[BACKWARD] Updated: output_projection, 2 decoder layers (with FF), 2 encoder layers (with FF)
[BACKWARD] Completed REAL backward pass with lr=0.05000000
Epoca 150/150 - Loss: 4.8673[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=1.442202
[ENCODER] After pos encoding: 768/768 non-zero, sum=39.932457
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 0.603 0.330 0.787 0.986 0.015 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=8.323, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=8.323
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=94.159996
[DECODER] After pos encoding: 128/128 non-zero, sum=100.560089
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=0.000001
[DEBUG] Decoder sample values: 0.167 -0.582 3.124 -0.114 0.397 
[DEBUG] Output range: [-2.059, 6.435]
[DEBUG] Output sample values: -0.908 4.667 6.435 5.804 3.365 
[GEN] Step 0 - Best token: 10 (score: 4.7, target_len: 5) [Top scores: 10:4.7 15:4.4 24:4.4 377:4.2 17:4.1 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=1.442202
[ENCODER] After pos encoding: 768/768 non-zero, sum=39.932457
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 0.603 0.330 0.787 0.986 0.015 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=9.004, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=9.004
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=101.871056
[DECODER] After pos encoding: 256/256 non-zero, sum=114.677208
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: 0.269 -0.558 3.422 -0.201 0.366 
[DEBUG] Output range: [-2.173, 6.419]
[DEBUG] Output sample values: -0.943 4.651 6.419 5.857 3.422 
[GEN] Step 1 - Best token: 24 (score: 4.2, target_len: 5) [Top scores: 24:4.2 28:4.1 377:4.1 19:4.1 15:4.0 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=1.442202
[ENCODER] After pos encoding: 768/768 non-zero, sum=39.932457
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 0.603 0.330 0.787 0.986 0.015 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=9.017, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=9.017
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=102.015549
[DECODER] After pos encoding: 384/384 non-zero, sum=121.233727
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 0.273 -0.402 3.832 -0.328 0.310 
[DEBUG] Output range: [-2.119, 6.367]
[DEBUG] Output sample values: -1.007 4.585 6.305 5.926 3.468 
[GEN] Step 2 - Best token: 15 (score: 4.6, target_len: 5) [Top scores: 15:4.6 377:4.1 59:4.1 17:4.1 303:3.8 ]
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=1.442202
[ENCODER] After pos encoding: 768/768 non-zero, sum=39.932457
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 0.603 0.330 0.787 0.986 0.015 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=8.522, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=8.522
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=96.419754
[DECODER] After pos encoding: 512/512 non-zero, sum=122.055992
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000001
[DEBUG] Decoder sample values: -0.255 -1.077 4.502 -1.565 -0.393 
[DEBUG] Output range: [-2.298, 7.396]
[DEBUG] Output sample values: -1.002 4.938 7.396 4.822 3.650 
[EMBEDDING] Forward pass - seq_len=6, d_model=128
[EMBEDDING] 768/768 non-zero, sum=0.127, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 704/768 non-zero, sum=38.490261
[ENCODER] SCALED EMBEDS before add: 768/768 non-zero, sum=1.442202
[ENCODER] After pos encoding: 768/768 non-zero, sum=39.932457
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 0 output: 768/768 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 768/768 non-zero
[ENCODER_LAYER] After self-attention: 768/768 non-zero
[ENCODER_LAYER] After norm1: 768/768 non-zero
[ENCODER_LAYER] After feedforward: 768/768 non-zero
[ENCODER_LAYER] Final output: 768/768 non-zero
[ENCODER] Layer 1 output: 768/768 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 0.603 0.330 0.787 0.986 0.015 
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=9.420, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 640/640 non-zero, sum=9.420
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[DECODER] SCALED EMBEDS before add: 640/640 non-zero, sum=106.573318
[DECODER] After pos encoding: 640/640 non-zero, sum=138.633667
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 640/640 non-zero, sum=-0.000004
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 640/640 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: -0.272 -1.081 4.554 -1.554 -0.372 
[DEBUG] Output range: [-2.325, 7.383]
[DEBUG] Output sample values: -1.011 4.939 7.383 4.830 3.649 
 | Test: <sos> en y un con d <eos>

¡Entrenamiento completado!

=== Pruebas de Traducción ===
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.448, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-5.072510
[ENCODER] After pos encoding: 384/384 non-zero, sum=14.145568
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 0.603 0.330 0.781 0.989 0.008 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=8.323, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=8.323
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=94.159996
[DECODER] After pos encoding: 128/128 non-zero, sum=100.560089
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000001
[DEBUG] Decoder sample values: 0.167 -0.582 3.120 -0.111 0.391 
[DEBUG] Output range: [-2.058, 6.438]
[DEBUG] Output sample values: -0.908 4.664 6.438 5.805 3.364 
[GEN] Step 0 - Best token: 10 (score: 4.7, target_len: 2) [Top scores: 10:4.7 15:4.4 24:4.4 377:4.2 17:4.1 ]
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=-0.448, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[ENCODER] SCALED EMBEDS before add: 384/384 non-zero, sum=-5.072510
[ENCODER] After pos encoding: 384/384 non-zero, sum=14.145568
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 0 output: 384/384 non-zero, sum=-0.000007
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 384/384 non-zero
[ENCODER_LAYER] After self-attention: 384/384 non-zero
[ENCODER_LAYER] After norm1: 384/384 non-zero
[ENCODER_LAYER] After feedforward: 384/384 non-zero
[ENCODER_LAYER] Final output: 384/384 non-zero
[ENCODER] Layer 1 output: 384/384 non-zero, sum=0.000004
[DEBUG] Encoder sample values: 0.603 0.330 0.781 0.989 0.008 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=9.004, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=9.004
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=101.871056
[DECODER] After pos encoding: 256/256 non-zero, sum=114.677208
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: 0.160 -0.586 3.272 -0.143 0.325 
[DEBUG] Output range: [-2.051, 6.477]
[DEBUG] Output sample values: -0.923 4.605 6.477 5.820 3.401 
[GEN] Step 1 - Best token: 9 (score: 4.5, target_len: 2) [Top scores: 9:4.5 24:4.4 59:4.3 4:4.2 554:4.0 ]
ENG: <sos> hello <eos>
ESP: <sos> en el <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.902, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.207749
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.267937
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.598 0.351 0.778 1.011 0.005 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=8.323, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=8.323
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=94.159996
[DECODER] After pos encoding: 128/128 non-zero, sum=100.560089
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: 0.165 -0.568 3.121 -0.097 0.392 
[DEBUG] Output range: [-2.056, 6.430]
[DEBUG] Output sample values: -0.903 4.671 6.430 5.801 3.358 
[GEN] Step 0 - Best token: 24 (score: 4.4, target_len: 4) [Top scores: 10:4.7 15:4.4 24:4.4 377:4.2 17:4.1 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.902, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.207749
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.267937
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.598 0.351 0.778 1.011 0.005 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=8.335, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=8.335
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=94.304489
[DECODER] After pos encoding: 256/256 non-zero, sum=107.110626
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: 0.091 -0.164 3.831 0.051 0.159 
[DEBUG] Output range: [-1.853, 6.173]
[DEBUG] Output sample values: -0.790 4.828 6.173 5.654 3.324 
[GEN] Step 1 - Best token: 15 (score: 4.5, target_len: 4) [Top scores: 10:4.5 15:4.5 17:4.2 59:3.9 110:3.8 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.902, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.207749
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.267937
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.598 0.351 0.778 1.011 0.005 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=7.841, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=7.841
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=88.708694
[DECODER] After pos encoding: 384/384 non-zero, sum=107.926872
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000005
[DEBUG] Decoder sample values: 0.010 -0.017 4.129 0.083 0.105 
[DEBUG] Output range: [-2.087, 6.221]
[DEBUG] Output sample values: -0.727 4.664 6.221 5.643 3.278 
[GEN] Step 2 - Best token: 10 (score: 4.3, target_len: 4) [Top scores: 10:4.3 19:4.2 1:4.2 28:4.1 110:4.1 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=0.902, range=[-0.106, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=10.207749
[ENCODER] After pos encoding: 640/640 non-zero, sum=42.267937
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000006
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.598 0.351 0.778 1.011 0.005 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=8.522, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=8.522
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=96.419754
[DECODER] After pos encoding: 512/512 non-zero, sum=122.055977
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Decoder sample values: 0.016 -0.022 4.131 0.085 0.102 
[DEBUG] Output range: [-2.067, 6.224]
[DEBUG] Output sample values: -0.734 4.664 6.224 5.647 3.278 
ENG: <sos> how are you <eos>
ESP: <sos> y un en ella <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.838, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.486076
[ENCODER] After pos encoding: 512/512 non-zero, sum=16.150043
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.604 0.332 0.791 1.000 0.012 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=8.323, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=8.323
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=94.159996
[DECODER] After pos encoding: 128/128 non-zero, sum=100.560089
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000003
[DEBUG] Decoder sample values: 0.167 -0.580 3.125 -0.104 0.394 
[DEBUG] Output range: [-2.056, 6.434]
[DEBUG] Output sample values: -0.909 4.668 6.434 5.804 3.364 
[GEN] Step 0 - Best token: 10 (score: 4.7, target_len: 3) [Top scores: 10:4.7 15:4.4 24:4.4 377:4.2 17:4.1 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.838, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.486076
[ENCODER] After pos encoding: 512/512 non-zero, sum=16.150043
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.604 0.332 0.791 1.000 0.012 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=9.004, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=9.004
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=101.871056
[DECODER] After pos encoding: 256/256 non-zero, sum=114.677208
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000005
[DEBUG] Decoder sample values: 0.019 -0.616 3.659 -0.030 0.308 
[DEBUG] Output range: [-2.180, 6.565]
[DEBUG] Output sample values: -0.898 4.583 6.565 5.864 3.432 
[GEN] Step 1 - Best token: 79 (score: 4.5, target_len: 3) [Top scores: 79:4.5 28:4.2 554:4.0 5:3.8 4:3.8 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.838, range=[-0.105, 0.105]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-9.486076
[ENCODER] After pos encoding: 512/512 non-zero, sum=16.150043
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000003
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.604 0.332 0.791 1.000 0.012 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=9.512, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=9.512
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=107.620895
[DECODER] After pos encoding: 384/384 non-zero, sum=126.839104
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000005
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000005
[DEBUG] Decoder sample values: 0.270 -0.355 4.107 0.057 0.094 
[DEBUG] Output range: [-2.106, 6.449]
[DEBUG] Output sample values: -1.247 4.718 6.177 5.949 3.654 
[GEN] Step 2 - Best token: 15 (score: 4.4, target_len: 3) [Top scores: 15:4.4 17:4.3 377:4.2 235:4.1 554:4.0 ]
ENG: <sos> good morning <eos>
ESP: <sos> en sus un <eos>
---
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-0.503279
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.132845
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.605 0.334 0.774 0.995 0.018 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=8.323, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=8.323
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=94.159996
[DECODER] After pos encoding: 128/128 non-zero, sum=100.560089
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000002
[DEBUG] Decoder sample values: 0.168 -0.580 3.114 -0.108 0.398 
[DEBUG] Output range: [-2.060, 6.436]
[DEBUG] Output sample values: -0.909 4.668 6.436 5.805 3.362 
[GEN] Step 0 - Best token: 10 (score: 4.7, target_len: 3) [Top scores: 10:4.7 15:4.4 24:4.4 377:4.2 17:4.1 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-0.503279
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.132845
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.605 0.334 0.774 0.995 0.018 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=9.004, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=9.004
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=101.871056
[DECODER] After pos encoding: 256/256 non-zero, sum=114.677208
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=-0.000003
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: 0.095 -0.400 3.763 -0.504 0.458 
[DEBUG] Output range: [-2.436, 6.574]
[DEBUG] Output sample values: -1.114 4.520 6.574 5.915 3.383 
[GEN] Step 1 - Best token: 235 (score: 4.1, target_len: 3) [Top scores: 24:4.6 235:4.1 15:4.0 110:4.0 17:4.0 ]
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=-0.044, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[ENCODER] SCALED EMBEDS before add: 512/512 non-zero, sum=-0.503279
[ENCODER] After pos encoding: 512/512 non-zero, sum=25.132845
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 0 output: 512/512 non-zero, sum=-0.000000
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 512/512 non-zero
[ENCODER_LAYER] After self-attention: 512/512 non-zero
[ENCODER_LAYER] After norm1: 512/512 non-zero
[ENCODER_LAYER] After feedforward: 512/512 non-zero
[ENCODER_LAYER] Final output: 512/512 non-zero
[ENCODER] Layer 1 output: 512/512 non-zero, sum=0.000002
[DEBUG] Encoder sample values: 0.605 0.334 0.774 0.995 0.018 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=8.228, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=8.228
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=93.084061
[DECODER] After pos encoding: 384/384 non-zero, sum=112.302231
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=0.000009
[DEBUG] Decoder sample values: 0.100 -0.398 3.768 -0.495 0.449 
[DEBUG] Output range: [-2.503, 6.573]
[DEBUG] Output sample values: -1.119 4.522 6.572 5.917 3.380 
[GEN] Step 2 - Best token: 24 (score: 4.5, target_len: 3) [Top scores: 24:4.5 15:4.4 17:4.1 59:4.0 377:4.0 ]
ENG: <sos> thank you <eos>
ESP: <sos> en mal y <eos>
---
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.918, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.382312
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.677876
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.607 0.337 0.766 1.005 0.012 
[EMBEDDING] Forward pass - seq_len=1, d_model=128
[EMBEDDING] 128/128 non-zero, sum=8.323, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 128/128 non-zero, sum=8.323
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 64/128 non-zero, sum=6.399996
[DECODER] SCALED EMBEDS before add: 128/128 non-zero, sum=94.159996
[DECODER] After pos encoding: 128/128 non-zero, sum=100.560089
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 128/128 non-zero, sum=-0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 128/128 non-zero, sum=-0.000000
[DEBUG] Decoder sample values: 0.170 -0.578 3.110 -0.103 0.393 
[DEBUG] Output range: [-2.061, 6.432]
[DEBUG] Output sample values: -0.907 4.665 6.432 5.809 3.363 
[GEN] Step 0 - Best token: 24 (score: 4.4, target_len: 4) [Top scores: 10:4.7 15:4.4 24:4.4 377:4.2 17:4.1 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.918, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.382312
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.677876
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.607 0.337 0.766 1.005 0.012 
[EMBEDDING] Forward pass - seq_len=2, d_model=128
[EMBEDDING] 256/256 non-zero, sum=8.335, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 256/256 non-zero, sum=8.335
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 192/256 non-zero, sum=12.806040
[DECODER] SCALED EMBEDS before add: 256/256 non-zero, sum=94.304489
[DECODER] After pos encoding: 256/256 non-zero, sum=107.110626
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 256/256 non-zero, sum=0.000001
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 256/256 non-zero, sum=0.000010
[DEBUG] Decoder sample values: 0.141 -0.554 3.162 -0.087 0.397 
[DEBUG] Output range: [-2.063, 6.430]
[DEBUG] Output sample values: -0.911 4.639 6.430 5.828 3.377 
[GEN] Step 1 - Best token: 10 (score: 4.7, target_len: 4) [Top scores: 10:4.7 15:4.5 377:4.2 17:4.1 59:4.1 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.918, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.382312
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.677876
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.607 0.337 0.766 1.005 0.012 
[EMBEDDING] Forward pass - seq_len=3, d_model=128
[EMBEDDING] 384/384 non-zero, sum=9.017, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 384/384 non-zero, sum=9.017
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 320/384 non-zero, sum=19.218086
[DECODER] SCALED EMBEDS before add: 384/384 non-zero, sum=102.015549
[DECODER] After pos encoding: 384/384 non-zero, sum=121.233734
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 384/384 non-zero, sum=0.000002
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 384/384 non-zero, sum=-0.000004
[DEBUG] Decoder sample values: 0.335 -0.595 3.658 -0.210 0.269 
[DEBUG] Output range: [-2.636, 6.569]
[DEBUG] Output sample values: -0.858 4.523 6.325 5.967 3.372 
[GEN] Step 2 - Best token: 17 (score: 4.2, target_len: 4) [Top scores: 17:4.2 235:4.1 15:4.1 28:4.0 19:3.9 ]
[EMBEDDING] Forward pass - seq_len=5, d_model=128
[EMBEDDING] 640/640 non-zero, sum=-0.918, range=[-0.105, 0.106]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[ENCODER] POS ENC before add: 576/640 non-zero, sum=32.060211
[ENCODER] SCALED EMBEDS before add: 640/640 non-zero, sum=-10.382312
[ENCODER] After pos encoding: 640/640 non-zero, sum=21.677876
[ENCODER] Processing layer 0
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 0 output: 640/640 non-zero, sum=-0.000008
[ENCODER] Processing layer 1
[ENCODER_LAYER] Starting layer with input stats: 640/640 non-zero
[ENCODER_LAYER] After self-attention: 640/640 non-zero
[ENCODER_LAYER] After norm1: 640/640 non-zero
[ENCODER_LAYER] After feedforward: 640/640 non-zero
[ENCODER_LAYER] Final output: 640/640 non-zero
[ENCODER] Layer 1 output: 640/640 non-zero, sum=0.000001
[DEBUG] Encoder sample values: 0.607 0.337 0.766 1.005 0.012 
[EMBEDDING] Forward pass - seq_len=4, d_model=128
[EMBEDDING] 512/512 non-zero, sum=9.379, range=[-0.709, 12.934]
[EMBEDDING] Forward pass completed - Output ready for encoder/decoder
[DECODER] Target embeddings stats: 512/512 non-zero, sum=9.379
[POS_ENC] Stats: 10/20 non-zero, sum=1.000, range=[0.100, 0.100]
[POS_ENC] First 10 values: 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 0.000000 0.100000 
[DECODER] POS ENC before add: 448/512 non-zero, sum=25.636196
[DECODER] SCALED EMBEDS before add: 512/512 non-zero, sum=106.106239
[DECODER] After pos encoding: 512/512 non-zero, sum=131.742462
[DECODER] Processing layer 0
[DECODER] Layer 0 output: 512/512 non-zero, sum=0.000000
[DECODER] Processing layer 1
[DECODER] Layer 1 output: 512/512 non-zero, sum=-0.000011
[DEBUG] Decoder sample values: 0.337 -0.591 3.669 -0.207 0.262 
[DEBUG] Output range: [-2.678, 6.582]
[DEBUG] Output sample values: -0.865 4.524 6.326 5.970 3.370 
ENG: <sos> i love you <eos>
ESP: <sos> y en se un <eos>
---